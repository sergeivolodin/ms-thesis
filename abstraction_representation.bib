@article{hamming1980unreasonable,
  title={The unreasonable effectiveness of mathematics},
  author={Hamming, Richard Wesley},
  journal={The American Mathematical Monthly},
  volume={87},
  number={2},
  pages={81--90},
  year={1980},
  publisher={Taylor \& Francis}
}

@article{Zambaldi2018,
abstract = {We introduce an approach for deep reinforcement learning (RL) that improves upon the efficiency, generalization capacity, and interpretability of conventional approaches through structured perception and relational reasoning. It uses self-attention to iteratively reason about the relations between entities in a scene and to guide a model-free policy. Our results show that in a novel navigation and planning task called Box-World, our agent finds interpretable solutions that improve upon baselines in terms of sample complexity, ability to generalize to more complex scenes than experienced during training, and overall performance. In the StarCraft II Learning Environment, our agent achieves state-of-the-art performance on six mini-games -- surpassing human grandmaster performance on four. By considering architectural inductive biases, our work opens new directions for overcoming important, but stubborn, challenges in deep RL.},
annote = {Path as a sequence of states, attention between states!},
archivePrefix = {arXiv},
arxivId = {1806.01830},
author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and Shanahan, Murray and Langston, Victoria and Pascanu, Razvan and Botvinick, Matthew and Vinyals, Oriol and Battaglia, Peter},
eprint = {1806.01830},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zambaldi et al. - 2018 - Relational Deep Reinforcement Learning.pdf:pdf},
number = {2},
pages = {1--15},
title = {{Relational Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1806.01830},
year = {2018}
}
@article{Bengio2017,
abstract = {A new prior is proposed for representation learning, which can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by the phenomenon of consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant. This provides a powerful constraint on the representation in that such low-dimensional thought vectors can correspond to statements about reality which are true, highly probable, or very useful for taking decisions. The fact that a few elements of the current state can be combined into such a predictive or useful statement is a strong constraint and deviates considerably from the maximum likelihood approaches to modelling data and how states unfold in the future based on an agent's actions. Instead of making predictions in the sensory (e.g. pixel) space, the consciousness prior allows the agent to make predictions in the abstract space, with only a few dimensions of that space being involved in each of these predictions. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in the form of facts and rules, although the conscious states may be richer than what can be expressed easily in the form of a sentence, a fact or a rule.},
archivePrefix = {arXiv},
arxivId = {1709.08568},
author = {Bengio, Yoshua},
eprint = {1709.08568},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio - 2017 - The Consciousness Prior(2).pdf:pdf},
pages = {1--7},
title = {{The Consciousness Prior}},
url = {http://arxiv.org/abs/1709.08568},
year = {2017}
}
@article{Tank2017,
abstract = {While most classical approaches to Granger causality detection repose upon linear time series assumptions, many interactions in neuroscience and economics applications are nonlinear. We develop an approach to nonlinear Granger causality detection using multilayer perceptrons where the input to the network is the past time lags of all series and the output is the future value of a single series. A sufficient condition for Granger non-causality in this setting is that all of the outgoing weights of the input data, the past lags of a series, to the first hidden layer are zero. For estimation, we utilize a group lasso penalty to shrink groups of input weights to zero. We also propose a hierarchical penalty for simultaneous Granger causality and lag estimation. We validate our approach on simulated data from both a sparse linear autoregressive model and the sparse and nonlinear Lorenz-96 model.},
archivePrefix = {arXiv},
arxivId = {1711.08160},
author = {Tank, Alex and Cover, Ian and Foti, Nicholas J. and Shojaie, Ali and Fox, Emily B.},
eprint = {1711.08160},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tank et al. - 2017 - An Interpretable and Sparse Neural Network Model for Nonlinear Granger Causality Discovery.pdf:pdf},
number = {Nips},
title = {{An Interpretable and Sparse Neural Network Model for Nonlinear Granger Causality Discovery}},
url = {http://arxiv.org/abs/1711.08160},
year = {2017}
}
@article{Mao2019,
abstract = {We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neuro-symbolic reasoning module that executes these programs on the latent scene representation. Analogical to human concept learning, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide the searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.},
annote = {concepts=vectors
neural operators f(v)=v1 (example: shape: obj -{\textgreater} shapes)
RL to train the symbolic part (finding closest from embeddings)},
archivePrefix = {arXiv},
arxivId = {1904.12584},
author = {Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum, Joshua B. and Wu, Jiajun},
eprint = {1904.12584},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mao et al. - 2019 - The neuro-symbolic concept learner Interpreting scenes, words, and sentences from natural supervision.pdf:pdf},
journal = {7th International Conference on Learning Representations, ICLR 2019},
pages = {1--28},
title = {{The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision}},
year = {2019}
}
@article{Marino2019,
annote = {using the agent to prove properties about the world

gridworlds. hypothesis=(precond, action seq)

Reward based on conditions},
author = {Marino, Kenneth and Fergus, Rob and Szlam, Arthur},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Marino, Fergus, Szlam - 2019 - Toward a Scientist Agent Learning to Verify Hypotheses.pdf:pdf},
title = {{Toward a Scientist Agent : Learning to Verify Hypotheses}},
year = {2019}
}
@techreport{Anderson1972,
author = {Anderson, P W},
booktitle = {New Series},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson - 1972 - More Is Different.pdf:pdf},
isbn = {177{\%}3A4047{\%}3C3},
number = {4047},
pages = {393--396},
title = {{More Is Different}},
volume = {177},
year = {1972}
}
@article{Babadi2014,
abstract = {In several sensory pathways, input stimuli project tosparsely active downstream populations that have more neurons than incoming axons. Here, we address the computational benefits of expansion and sparseness for clustered inputs, where different clusters represent behaviorally distinct stimuli and intracluster variability represents sensory or neuronal noise. Through analytical calculations and numerical simulations, we show that expansion implemented by feed-forward random synaptic weights amplifies variability in the incoming stimuli, and this noise enhancement increases with sparseness of the expanded representation. In addition, the low dimensionality of the input layer generates overlaps between the induced representations of different stimuli, limiting the benefit of expansion. Highly sparse expansive representations obtained through synapses that encode the clustered structure of the input reduce both intrastimulus variability and the excess overlaps between stimuli, enhancing the ability of downstream neurons to perform classification and recognition tasks. Implications for olfactory, cerebellar, and visual processing are discussed.},
author = {Babadi, Baktash and Sompolinsky, Haim},
doi = {10.1016/j.neuron.2014.07.035},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Babadi, Sompolinsky - 2014 - Sparseness and Expansion in Sensory Representations.pdf:pdf},
issn = {10974199},
journal = {Neuron},
month = {sep},
number = {5},
pages = {1213--1226},
publisher = {Cell Press},
title = {{Sparseness and Expansion in Sensory Representations}},
volume = {83},
year = {2014}
}
@article{Nautrup2020,
abstract = {To make progress in science, we often build abstract representations of physical systems that meaningfully encode information about the systems. The representations learnt by most current machine learning techniques reflect statistical structure present in the training data; however, these methods do not allow us to specify explicit and operationally meaningful requirements on the representation. Here, we present a neural network architecture based on the notion that agents dealing with different aspects of a physical system should be able to communicate relevant information as efficiently as possible to one another. This produces representations that separate different parameters which are useful for making statements about the physical system in different experimental settings. We present examples involving both classical and quantum physics. For instance, our architecture finds a compact representation of an arbitrary two-qubit system that separates local parameters from parameters describing quantum correlations. We further show that this method can be combined with reinforcement learning to enable representation learning within interactive scenarios where agents need to explore experimental settings to identify relevant variables.},
annote = {task is to assemble information},
archivePrefix = {arXiv},
arxivId = {2001.00593},
author = {Nautrup, Hendrik Poulsen and Metger, Tony and Iten, Raban and Jerbi, Sofiene and Trenkwalder, Lea M. and Wilming, Henrik and Briegel, Hans J. and Renner, Renato},
eprint = {2001.00593},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nautrup et al. - 2020 - Operationally meaningful representations of physical systems in neural networks.pdf:pdf},
month = {jan},
title = {{Operationally meaningful representations of physical systems in neural networks}},
url = {http://arxiv.org/abs/2001.00593},
year = {2020}
}
@techreport{Polyak,
abstract = {We focus on finding sparse and least-1-norm solutions for uncon-strained nonlinear optimal control problems. Such optimization problems are non-convex and non-smooth, nevertheless recent versions of Newton method for under-determined equations can be applied successively for such problems.},
archivePrefix = {arXiv},
arxivId = {1908.10150v1},
author = {Polyak, Boris and Tremba, Andrey},
eprint = {1908.10150v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Polyak, Tremba - Unknown - Sparse solutions of optimal control via Newton method for under-determined systems.pdf:pdf},
keywords = {1-norm,Newton method,Optimal control,Sparse control,Under-determined equations},
title = {{Sparse solutions of optimal control via Newton method for under-determined systems}}
}
@techreport{Mairal2009,
abstract = {Sparse coding-that is, modelling data vectors as sparse linear combinations of basis elements-is widely used in machine learning, neuroscience, signal processing, and statistics. This paper fo-cuses on learning the basis set, also called dictionary , to adapt it to specific data, an approach that has recently proven to be very effective for signal reconstruction and classification in the audio and image processing domains. This paper proposes a new online optimization algorithm for dictionary learning, based on stochastic approximations , which scales up gracefully to large datasets with millions of training samples. A proof of convergence is presented, along with experiments with natural images demonstrating that it leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets.},
author = {Mairal, Julien and {Bach FRANCISBACH}, Francis and Ponce, Jean and {Normale Sup{\'{e}}rieure}, Ecole and Sapiro, Guillermo},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mairal et al. - 2009 - Online Dictionary Learning for Sparse Coding.pdf:pdf},
title = {{Online Dictionary Learning for Sparse Coding}},
year = {2009}
}
@techreport{DasGupta,
abstract = {In this paper, we investigate the properties of L p norm (p ≤ 1) within a projection framework. We start with the KKT equations of the non-linear optimization problem and then use its key properties to arrive at an algorithm for L p norm projection on the non-negative simplex. We compare with L 1 projection which needs prior knowledge of the true norm, as well as hard thresholding based sparsification proposed in recent compressed sensing literature. We show performance improvements compared to these techniques across different vision applications.},
author = {{Das Gupta}, Mithun},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Das Gupta - Unknown - Non-Convex P-norm Projection for Robust Sparsity.pdf:pdf},
title = {{Non-Convex P-norm Projection for Robust Sparsity *}}
}
@techreport{Sarmad,
abstract = {We present RL-GAN-Net, where a reinforcement learning (RL) agent provides fast and robust control of a genera-tive adversarial network (GAN). Our framework is applied to point cloud shape completion that converts noisy, partial point cloud data into a high-fidelity completed shape by controlling the GAN. While a GAN is unstable and hard to train, we circumvent the problem by (1) training the GAN on the latent space representation whose dimension is reduced compared to the raw point cloud input and (2) using an RL agent to find the correct input to the GAN to generate the latent space representation of the shape that best fits the current input of incomplete point cloud. The suggested pipeline robustly completes point cloud with large missing regions. To the best of our knowledge, this is the first attempt to train an RL agent to control the GAN, which effectively learns the highly nonlinear mapping from the input noise of the GAN to the latent space of point cloud. The RL agent replaces the need for complex optimization and consequently makes our technique real time. Additionally, we demonstrate that our pipelines can be used to enhance the classification accuracy of point cloud with missing data.},
archivePrefix = {arXiv},
arxivId = {1904.12304v1},
author = {Sarmad, Muhammad and Korea, South and Lee, Hyunjoo Jenny and Kim, Young Min},
eprint = {1904.12304v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarmad et al. - Unknown - RL-GAN-Net A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion.pdf:pdf},
title = {{RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion}}
}
@techreport{Deng,
abstract = {There has been a gap between artificial intelligence and human intelligence. In this paper, we identify three key elements forming human intelligence, and suggest that abstraction learning combines these elements and is thus a way to bridge the gap. Prior researches in artificial intelligence either specify abstraction by human experts, or take abstraction as qualitative explanation for the model. This paper aims to learn abstraction directly. We tackle three main challenges: representation, objective function, and learning algorithm. Specifically, we propose a partition structure that contains pre-allocated abstraction neurons; we formulate abstraction learning as a constrained optimization problem, which integrates abstraction properties; we develop a network evolution algorithm to solve this problem. This complete framework is named ONE (Optimization via Network Evolution). In our experiments on MNIST, ONE shows elementary human-like intelligence, including low energy consumption, knowledge sharing, and lifelong learning.},
annote = {evolution to search for discrete edges},
archivePrefix = {arXiv},
arxivId = {1809.03956v1},
author = {Deng, Fei and Ren, Jinsheng and Chen, Feng},
eprint = {1809.03956v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng, Ren, Chen - Unknown - Abstraction Learning.pdf:pdf},
title = {{Abstraction Learning}}
}
@techreport{Javed,
abstract = {Predictive models-learned from observational data not covering the complete data distribution-can rely on spurious correlations in the data for making predictions. These correlations make the models brittle and hinder generalization. One solution for achieving strong generalization is to incorporate causal structures in the models; such structures constrain learning by ignoring correlations that contradict them. However, learning these structures is a hard problem in itself. Moreover, it's not clear how to incorporate the machinery of causality with online continual learning. In this work, we take an indirect approach to discovering causal models. Instead of searching for the true causal model directly, we propose an online algorithm that continually detects and removes spurious features. Our algorithm works on the idea that the correlation of a spurious feature with a target is not constant overtime. As a result, the weight associated with that feature is constantly changing. We show that by continually removing such features, our method converges to solutions that have strong generalization. Moreover, our method combined with random search can also discover non-spurious features from raw sensory data. Finally, our work highlights that the information present in the temporal structure of the problem-destroyed by shuffling the data-is essential for detecting spurious features online.},
annote = {correlation of a spurious feature with target over time is not constant -- assumption

!! Read again [David]},
archivePrefix = {arXiv},
arxivId = {2006.07461v1},
author = {Javed, Khurram and White, Martha and {Bengio MILA}, Yoshua},
eprint = {2006.07461v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Javed, White, Bengio MILA - Unknown - Learning Causal Models Online.pdf:pdf},
title = {{Learning Causal Models Online}}
}
@techreport{Johnson,
author = {Johnson, Michael Edward},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson - Unknown - Neural Annealing Toward a Neural Theory of Everything.pdf:pdf},
title = {{Neural Annealing: Toward a Neural Theory of Everything}}
}
@article{Chekroud2015,
abstract = {Major Depressive Disorder is a debilitating and increasingly prevalent psychiatric condition (Compton et al., 2006; Andersen et al., 2011). At present, its primary treatments are antidepressant medications and psychotherapy. Curiously, although the pharmacological effects of antidepressants manifest within hours, remission of clinical symptoms takes a number of weeks-if at all. Independently, support has grown for an idea-proposed as early as Helmholtz (von Helmholtz, 1924)-that the brain is a prediction machine, holding generative models1 for the purpose of inferring causes of sensory information (Dayan et al., 1995; Rao and Ballard, 1999; Knill and Pouget, 2004; Friston et al., 2006; Friston, 2010). If the brain does indeed represent a collection of beliefs about the causal structure of the world, then the depressed phenotype may emerge from a collection of depressive beliefs. These beliefs are modified gradually through successive combinations of expectations with observations. As a result, phenotypic remission ought to take some time as the brain's relevant statistical structures become less pessimistic.},
author = {Chekroud, Adam M.},
doi = {10.3389/fpsyg.2015.00153},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekroud - 2015 - Unifying treatments for depression an application of the Free Energy Principle.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {Antidepressants,Antidepressants efficacy,Computational psychiatry,Free-energy principle,Generative models,Major depressive disorder,Predictive coding},
month = {feb},
number = {FEB},
pages = {153},
publisher = {Frontiers Media S.A.},
title = {{Unifying treatments for depression: an application of the Free Energy Principle}},
url = {http://journal.frontiersin.org/Article/10.3389/fpsyg.2015.00153/abstract},
volume = {6},
year = {2015}
}
@techreport{Khetarpal2020,
abstract = {Reinforcement learning algorithms usually assume that all actions are always available to an agent. However, both people and animals understand the general link between the features of their environment and the actions that are feasible. Gibson (1977) coined the term "affordances" to describe the fact that certain states enable an agent to do certain actions, in the context of embodied agents. In this paper, we develop a theory of affor-dances for agents who learn and plan in Markov Decision Processes. Affordances play a dual role in this case. On one hand, they allow faster planning , by reducing the number of actions available in any given situation. On the other hand, they facilitate more efficient and precise learning of transition models from data, especially when such models require function approximation. We establish these properties through theoretical results as well as illustrative examples. We also propose an approach to learn affordances and use it to estimate transition models that are simpler and generalize better.},
archivePrefix = {arXiv},
arxivId = {2006.15085v1},
author = {Khetarpal, Khimya and Ahmed, Zafarali and Comanici, Gheorghe and Abel, David and Precup, Doina},
eprint = {2006.15085v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Khetarpal et al. - 2020 - What can I do here A Theory of Affordances in Reinforcement Learning.pdf:pdf},
title = {{What can I do here? A Theory of Affordances in Reinforcement Learning}},
year = {2020}
}
@techreport{Qin,
abstract = {Abductive and counterfactual reasoning, core abilities of everyday human cognition, require reasoning about what might have happened at time t, while conditioning on multiple contexts from the relative past and future. However, simultaneous incorporation of past and future contexts using generative language models (LMs) can be challenging, as they are trained either to condition only on the past context or to perform narrowly scoped text-infilling. In this paper, we propose DELOREAN, a new unsupervised decoding algorithm that can flexibly incorporate both the past and future contexts using only off-the-shelf, left-to-right language models and no supervision. The key intuition of our algorithm is incorporating the future through back-propagation, during which, we only update the internal representation of the output while fixing the model parameters. By alternating between forward and backward propagation, DELOREAN can decode the output representation that reflects both the left and right contexts. We demonstrate that our approach is general and applicable to two nonmonotonic reasoning tasks: abductive text generation and counterfactual story revision, where DELOREAN outperforms a range of unsupervised and some supervised methods, based on automatic and human evaluation. 1},
archivePrefix = {arXiv},
arxivId = {2010.05906v1},
author = {Qin, Lianhui and Shwartz, Vered and West, Peter and Bhagavatula, Chandra and Hwang, Jena D and {Le Bras}, Ronan and Bosselut, Antoine and Choi, Yejin and Allen, Paul G},
eprint = {2010.05906v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qin et al. - Unknown - Back to the Future Unsupervised Backprop-based Decoding for Counterfactual and Abductive Commonsense Reasoning.pdf:pdf},
title = {{Back to the Future: Unsupervised Backprop-based Decoding for Counterfactual and Abductive Commonsense Reasoning}},
url = {https://github.com/}
}
@techreport{Weinstein,
annote = {Can efficiently compute the whole LASSO path. Select hyper?

'where signals are sparse' = denoising

Basis pursuit

LARS-TD, LSTD algorithms -- SPARSE RL!

Making FEATURE VECTOR sparse (which features we use), NOT the model.},
author = {Weinstein, Alejandro J},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinstein - Unknown - INFERENCE AND LEARNING IN HIGH-DIMENSIONAL SPACES.pdf:pdf},
title = {{INFERENCE AND LEARNING IN HIGH-DIMENSIONAL SPACES}}
}
@inproceedings{Kiumarsi2019,
abstract = {This paper presents a resilient model-free reinforcement learning solution to linear quadratic regulator control of cyber-physical systems under sensor attacks. To guarantee resiliency to sensor attacks, a sparse least-squares optimization is introduced to solve the Bellman equation. While the Bellman equation does not involve any dynamics, it implicitly solves a Lyapunov equation which depends on the system dynamics. Thus, if the data are corrupted and do not follow the dynamics, that causes an error in the Bellman equation. Therefore, assuming a strong system observability, i.e., s-sparse observability, the proposed sparse optimization assures that the data from compromised sensors that lead to a sizable error in the Bellman equation have no effect in reconstructing the state of the system, and, thus on evaluation of the policy. That is, only sensory outputs that result in a small error in the Bellman equation affect the policy evaluation. Once the optimal control policy is found, it can be applied to the system, until a surprise signal depending on the Bellman error is activated to indicate a change caused by a new attack or a change in the system dynamics.},
author = {Kiumarsi, Bahare and Basar, Tamer},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
doi = {10.1109/CDC40024.2019.9028861},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kiumarsi, Basar - 2019 - Secure Linear Quadratic Regulator Using Sparse Model-Free Reinforcement Learning.pdf:pdf},
isbn = {9781728113982},
issn = {07431546},
keywords = {Linear quadratic regulator,Reinforcement Learning,Resilient control},
month = {dec},
pages = {3641--3647},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Secure Linear Quadratic Regulator Using Sparse Model-Free Reinforcement Learning}},
volume = {2019-Decem},
year = {2019}
}
@article{Martins2016,
abstract = {We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities. After deriving its properties, we show how its Jacobian can be efficiently computed, enabling its use in a network trained with backpropagation. Then, we propose a new smooth and convex loss function which is the sparsemax analogue of the logistic loss. We reveal an unexpected connection between this new loss and the Huber classification loss. We obtain promising empirical results in multi-label classification problems and in attention-based neural networks for natural language inference. For the latter, we achieve a similar performance as the traditional softmax, but with a selective, more compact, attention focus.},
archivePrefix = {arXiv},
arxivId = {1602.02068},
author = {Martins, Andr{\'{e}} F. T. and Astudillo, Ram{\'{o}}n Fernandez},
eprint = {1602.02068},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martins, Astudillo - 2016 - From Softmax to Sparsemax A Sparse Model of Attention and Multi-Label Classification.pdf:pdf},
journal = {33rd International Conference on Machine Learning, ICML 2016},
month = {feb},
pages = {2432--2443},
publisher = {International Machine Learning Society (IMLS)},
title = {{From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification}},
url = {http://arxiv.org/abs/1602.02068},
volume = {4},
year = {2016}
}
@article{Sharan2017,
abstract = {What learning algorithms can be run directly on compressively-sensed data? In this work, we consider the question of accurately and efficiently computing low-rank matrix or tensor factorizations given data compressed via random projections. We examine the approach of first performing factorization in the compressed domain, and then reconstructing the original high-dimensional factors from the recovered (compressed) factors. In both the matrix and tensor settings, we establish conditions under which this natural approach will provably recover the original factors. While it is well-known that random projections preserve a number of geometric properties of a dataset, our work can be viewed as showing that they can also preserve certain solutions of non-convex, NP-Hard problems like non-negative matrix factorization. We support these theoretical results with experiments on synthetic data and demonstrate the practical applicability of compressed factorization on real-world gene expression and EEG time series datasets.},
archivePrefix = {arXiv},
arxivId = {1706.08146},
author = {Sharan, Vatsal and Tai, Kai Sheng and Bailis, Peter and Valiant, Gregory},
eprint = {1706.08146},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharan et al. - 2017 - Compressed Factorization Fast and Accurate Low-Rank Factorization of Compressively-Sensed Data.pdf:pdf},
journal = {36th International Conference on Machine Learning, ICML 2019},
month = {jun},
pages = {10013--10030},
publisher = {International Machine Learning Society (IMLS)},
title = {{Compressed Factorization: Fast and Accurate Low-Rank Factorization of Compressively-Sensed Data}},
url = {http://arxiv.org/abs/1706.08146},
volume = {2019-June},
year = {2017}
}
@article{Evans2018,
abstract = {Artificial Neural Networks are powerful function approximators capable of modelling solutions to a wide variety of problems, both supervised and unsupervised. As their size and expressivity increases, so too does the variance of the model, yielding a nearly ubiquitous overfitting problem. Although mitigated by a variety of model regu-larisation methods, the common cure is to seek large amounts of training data'which is not necessarily easily obtained'that sufficiently approximates the data distribution of the domain we wish to test on. In contrast, logic programming methods such as Inductive Logic Programming offer an extremely data-efficient process by which models can be trained to reason on symbolic domains. However, these methods are unable to deal with the variety of domains neural networks can be applied to: they are not robust to noise in or mislabelling of inputs, and perhaps more importantly, cannot be applied to non-symbolic domains where the data is ambiguous, such as operating on raw pixels. In this paper, we propose a Differentiable Inductive Logic framework (?ILP), which can not only solve tasks which traditional ILP systems are suited for, but shows a robustness to noise and error in the training data which ILP cannot cope with. Furthermore, as it is trained by backpropagation against a likelihood objective, it can be hybridised by connecting it with neural networks over ambiguous data in order to be applied to domains which ILP cannot address, while providing data efficiency and generalisation beyond what neural networks on their own can achieve.},
archivePrefix = {arXiv},
arxivId = {1711.04574},
author = {Evans, Richard and Grefenstette, Edward},
doi = {10.1613/jair.5714},
eprint = {1711.04574},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Evans, Grefenstette - 2018 - Learning explanatory rules from noisy data.pdf:pdf},
isbn = {9780999241127},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {5598--5602},
title = {{Learning explanatory rules from noisy data}},
volume = {2018-July},
year = {2018}
}
@techreport{Kim,
abstract = {We introduce a variational approach to learning and inference of temporally hierarchical structure and representation for sequential data. We propose the Variational Temporal Abstraction (VTA), a hierarchical recurrent state space model that can infer the latent temporal structure and thus perform the stochastic state transition hierarchically. We also propose to apply this model to implement the jumpy imagination ability in imagination-augmented agent-learning in order to improve the efficiency of the imagination. In experiments, we demonstrate that our proposed method can model 2D and 3D visual sequence datasets with interpretable temporal structure discovery and that its application to jumpy imagination enables more efficient agent-learning in a 3D navigation task.},
author = {Kim, Taesup and Ahn, Sungjin and Bengio, Yoshua},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Ahn, Bengio - Unknown - Variational Temporal Abstraction.pdf:pdf},
title = {{Variational Temporal Abstraction}}
}
@techreport{Corcoll,
abstract = {Exploration and credit assignment under sparse rewards are still challenging problems. We argue that these challenges arise in part due to the intrinsic rigidity of operating at the level of actions. Actions can precisely define how to perform an activity but are ill-suited to describe what activity to perform. Instead, causal effects are inherently composable and temporally abstract, making them ideal for descriptive tasks. By leveraging a hierarchy of causal effects, this study aims to expedite the learning of task-specific behavior and aid exploration. Borrowing counterfac-tual and normality measures from causal literature, we disentangle controllable effects from effects caused by other dynamics of the environment. We propose CEHRL 1 , a hierarchical method that models the distribution of controllable effects using a Variational Autoencoder. This distribution is used by a high-level policy to 1) explore the environment via random effect exploration so that novel effects are continuously discovered and learned; and to 2) learn task-specific behavior by prioritizing the effects that maximize a given reward function. In comparison to exploring with random actions, experimental results show that random effect exploration is a more efficient mechanism, and that by assigning credit to few effects rather than many actions, CEHRL learns tasks more rapidly.},
archivePrefix = {arXiv},
arxivId = {2010.01351v1},
author = {Corcoll, Oriol and Vicente, Raul},
eprint = {2010.01351v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Corcoll, Vicente - Unknown - DISENTANGLING CAUSAL EFFECTS FOR HIERARCHICAL REINFORCEMENT LEARNING.pdf:pdf},
title = {{DISENTANGLING CAUSAL EFFECTS FOR HIERARCHICAL REINFORCEMENT LEARNING}}
}
@article{Guo2020,
abstract = {This work considers the question of how convenient access to copious data impacts our ability to learn causal effects and relations. In what ways is learning causality in the era of big data different from-or the same as-the traditional one? To answer this question, this survey provides a comprehensive and structured review of both traditional and frontier methods in learning causality and relations along with the connections between causality and machine learning. This work points out on a case-by-case basis how big data facilitates, complicates, or motivates each approach.},
archivePrefix = {arXiv},
arxivId = {1809.09337v4},
author = {Guo, Ruocheng and Cheng, L U and Hahn, P Richard and Liu, Huan and Cheng, Lu and Li, Jundong},
doi = {10.1145/3397269},
eprint = {1809.09337v4},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2020 - A Survey of Learning Causality with Data Problems and Methods.pdf:pdf},
keywords = {ACM Reference Format:,CCS Concepts: • Computing methodologies → Artifici,Probability and statistics,• Mathematics of computing → Probability and stati},
title = {{A Survey of Learning Causality with Data: Problems and Methods}},
url = {https://doi.org/10.1145/3397269},
year = {2020}
}
@techreport{Kamalaruban,
abstract = {One of the central challenges faced by a reinforcement learning (RL) agent is to effectively learn a (near-)optimal policy in environments with large state spaces having sparse and noisy feedback signals. In real-world applications, an expert with additional domain knowledge can help in speeding up the learning process via shaping the environment, i.e., making the environment more learner-friendly. A popular paradigm in literature is potential-based reward shaping, where the environment's reward function is augmented with additional local rewards using a potential function. However, the applicability of potential-based reward shaping is limited in settings where (i) the state space is very large, and it is challenging to compute an appropriate potential function, (ii) the feedback signals are noisy, and even with shaped rewards the agent could be trapped in local optima, and (iii) changing the rewards alone is not sufficient, and effective shaping requires changing the dynamics. We address these limitations of potential-based shaping methods and propose a novel framework of environment shaping using state abstraction. Our key idea is to compress the environment's large state space with noisy signals to an abstracted space, and to use this abstraction in creating smoother and more effective feedback signals for the agent. We study the theoretical underpinnings of our abstraction-based environment shaping, and show that the agent's policy learnt in the shaped environment preserves near-optimal behavior in the original environment.},
archivePrefix = {arXiv},
arxivId = {2006.13160v1},
author = {Kamalaruban, Parameswaran},
eprint = {2006.13160v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kamalaruban - Unknown - Environment Shaping in Reinforcement Learning using State Abstraction.pdf:pdf},
keywords = {EPFL Adish Singla MPI-SWS,EPFL Rati Devidze MPI-SWS Volkan Cevher LIONS,LIONS},
title = {{Environment Shaping in Reinforcement Learning using State Abstraction}}
}
@techreport{Kurutach,
abstract = {In recent years, deep generative models have been shown to 'imagine' convincing high-dimensional observations such as images, audio, and even video, learning directly from raw data. In this work, we ask how to imagine goal-directed visual plans-a plausible sequence of observations that transition a dynamical system from its current configuration to a desired goal state, which can later be used as a reference trajectory for control. We focus on systems with high-dimensional observations, such as images, and propose an approach that naturally combines representation learning and planning. Our framework learns a generative model of sequential observations, where the generative process is induced by a transition in a low-dimensional planning model, and an additional noise. By maximizing the mutual information between the generated observations and the transition in the planning model, we obtain a low-dimensional representation that best explains the causal nature of the data. We structure the planning model to be compatible with efficient planning algorithms, and we propose several such models based on either discrete or continuous states. Finally, to generate a visual plan, we project the current and goal observations onto their respective states in the planning model, plan a trajectory, and then use the generative model to transform the trajectory to a sequence of observations. We demonstrate our method on imagining plausible visual plans of rope manipulation 3 .},
annote = {discriminate real from fake pairs

latent space model},
author = {Kurutach, Thanard and Tamar, Aviv and Yang, Ge and Russell, Stuart and Abbeel, Pieter},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurutach et al. - Unknown - Learning Plannable Representations with Causal InfoGAN.pdf:pdf},
title = {{Learning Plannable Representations with Causal InfoGAN}},
url = {http://github.com/thanard/causal-infogan.}
}
@techreport{Kalainathan,
abstract = {Ecole doctorale n • 580 Sciences et technologies de l'information et de la communication (STIC) Sp{\'{e}}cialit{\'{e}}Sp´Sp{\'{e}}cialitSp{\'{e}}cialit´Sp{\'{e}}cialit{\'{e}} de doctorat : Informatique Th{\`{e}}seTh`Th{\`{e}}se pr{\'{e}}sent{\'{e}}epr´pr{\'{e}}sentpr{\'{e}}sent´pr{\'{e}}sent{\'{e}}e et soutenu{\`{e}} a Gif-Sur-Yvette, le 17 D ´ ecembre 2019, par DIVIYAN KALAINATHAN},
author = {Kalainathan, Diviyan},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalainathan - Unknown - Generative Neural networks to infer Causal Mechanisms Algorithms and applications.pdf:pdf},
title = {{Generative Neural networks to infer Causal Mechanisms: Algorithms and applications}},
url = {https://hal.inria.fr/tel-02435986}
}
@techreport{Odena2018,
abstract = {Recent work (Pennington et al., 2017) suggests that controlling the entire distribution of Jacobian singular values is an important design consideration in deep learning. Motivated by this, we study the distribution of singular values of the Jacobian of the generator in Generative Adversarial Networks (GANs). We find that this Jacobian generally becomes ill-conditioned at the beginning of training and that the average (with z ∼ p(z)) conditioning of the generator is highly predic-tive of two other ad-hoc metrics for measuring the "quality" of trained GANs: the Inception Score and the Frechet Inception Distance (FID). We test the hypothesis that this relationship is causal by proposing a "regularization" technique (called Jacobian Clamping) that softly penalizes the condition number of the generator Jacobian. Jacobian Clamping improves the mean Inception Score and the mean FID for GANs trained on several datasets and greatly reduces inter-run variance of the aforementioned scores, addressing (at least partially) one of the main criticisms of GANs.},
archivePrefix = {arXiv},
arxivId = {1802.08768v2},
author = {Odena, Augustus and Buckman, Jacob and Olsson, Catherine and Brown, Tom B and Olah, Christopher and Raffel, Colin and Goodfellow, Ian},
eprint = {1802.08768v2},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Odena et al. - 2018 - Is Generator Conditioning Causally Related to GAN Performance.pdf:pdf},
title = {{Is Generator Conditioning Causally Related to GAN Performance?}},
year = {2018}
}
@techreport{Yoon,
abstract = {A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction-which allow finer control over network dynamics-are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the flexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we find that the proposed framework consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability.},
annote = {using a discriminator in latent space},
author = {Yoon, Jinsung and Jarrett, Daniel and {Van Der Schaar}, Mihaela},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yoon, Jarrett, Van Der Schaar - Unknown - Time-series Generative Adversarial Networks.pdf:pdf},
title = {{Time-series Generative Adversarial Networks}}
}
@techreport{Xu,
abstract = {We introduce COT-GAN, an adversarial algorithm to train implicit generative models optimized for producing sequential data. The loss function of this algorithm is formulated using ideas from Causal Optimal Transport (COT), which combines classic optimal transport methods with an additional temporal causality constraint. Remarkably, we find that this causality condition provides a natural framework to parameterize the cost function that is learned by the discriminator as a robust (worst-case) distance, and an ideal mechanism for learning time dependent data distributions. Following Genevay et al. (2018), we also include an entropic penal-ization term which allows for the use of the Sinkhorn algorithm when computing the optimal transport cost. Our experiments show effectiveness and stability of COT-GAN when generating both low-and high-dimensional time series data. The success of the algorithm also relies on a new, improved version of the Sinkhorn divergence which demonstrates less bias in learning.},
annote = {modelling time series},
archivePrefix = {arXiv},
arxivId = {2006.08571v2},
author = {Xu, Tianlin and Wenliang, Li K and {Munn Google}, Michael and Acciaio, Beatrice},
eprint = {2006.08571v2},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - Unknown - COT-GAN GENERATING SEQUENTIAL DATA VIA CAUSAL OPTIMAL TRANSPORT.pdf:pdf},
title = {{COT-GAN: GENERATING SEQUENTIAL DATA VIA CAUSAL OPTIMAL TRANSPORT}}
}
@techreport{Kocaoglu2017,
abstract = {We propose an adversarial training procedure for learning a causal implicit generative model for a given causal graph. We show that adversarial training can be used to learn a generative model with true observational and interventional distributions if the generator architecture is consistent with the given causal graph. We consider the application of generating faces based on given binary labels where the dependency structure between the labels is preserved with a causal graph. This problem can be seen as learning a causal implicit generative model for the image and labels. We devise a two-stage procedure for this problem. First we train a causal implicit generative model over binary labels using a neural network consistent with a causal graph as the generator. We empirically show that Wasserstein GAN can be used to output discrete labels. Later we propose two new conditional GAN architectures, which we call CausalGAN and CausalBEGAN. We show that the optimal generator of the CausalGAN, given the labels, samples from the image distributions conditioned on these labels. The conditional GAN combined with a trained causal implicit generative model for the labels is then an implicit causal generative network over the labels and the generated image. We show that the proposed architectures can be used to sample from observational and interventional image distributions, even for interventions which do not naturally occur in the dataset.},
archivePrefix = {arXiv},
arxivId = {1709.02023v2},
author = {Kocaoglu, Murat and Snyder, Christopher and Dimakis, Alexandros G and Vishwanath, Sriram},
eprint = {1709.02023v2},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocaoglu et al. - 2017 - CausalGAN Learning Causal Implicit Generative Models with Adversarial Training.pdf:pdf},
title = {{CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training}},
year = {2017}
}
@article{Sitzmann2020,
abstract = {Implicitly defined, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible benefits over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with fine detail, and fail to represent a signal's spatial and temporal derivatives, despite the fact that these are essential to many physical signals defined implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or Sirens, are ideally suited for representing complex natural signals and their derivatives. We analyze Siren activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how Sirens can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine Sirens with hypernetworks to learn priors over the space of Siren functions.},
annote = {sine activation function, map (x, y) -{\textgreater} pixel value},
archivePrefix = {arXiv},
arxivId = {2006.09661},
author = {Sitzmann, Vincent and Martel, Julien N. P. and Bergman, Alexander W. and Lindell, David B. and Wetzstein, Gordon},
eprint = {2006.09661},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sitzmann et al. - 2020 - Implicit Neural Representations with Periodic Activation Functions.pdf:pdf},
month = {jun},
title = {{Implicit Neural Representations with Periodic Activation Functions}},
url = {http://arxiv.org/abs/2006.09661},
year = {2020}
}
@article{Bengio2012,
abstract = {We propose a theory that relates difficulty of learning in deep architectures to culture and language. It is articulated around the following hypotheses: (1) learning in an individual human brain is hampered by the presence of effective local minima; (2) this optimization difficulty is particularly important when it comes to learning higher-level abstractions, i.e., concepts that cover a vast and highly-nonlinear span of sensory configurations; (3) such high-level abstractions are best represented in brains by the composition of many levels of representation, i.e., by deep architectures; (4) a human brain can learn such high-level abstractions if guided by the signals produced by other humans, which act as hints or indirect supervision for these high-level abstractions; and (5), language and the recombination and optimization of mental concepts provide an efficient evolutionary recombination operator, and this gives rise to rapid search in the space of communicable ideas that help humans build up better high-level internal representations of their world. These hypotheses put together imply that human culture and the evolution of ideas have been crucial to counter an optimization difficulty: this optimization difficulty would otherwise make it very difficult for human brains to capture high-level knowledge of the world. The theory is grounded in experimental observations of the difficulties of training deep artificial neural networks. Plausible consequences of this theory for the efficiency of cultural evolutions are sketched.},
annote = {Culture as non-convexity escape mechanism

training signal: predict what the teacher does -{\textgreater} loss for representation

animal training term 'shaping' {\~{}} curriculum

dividing and recombination of both, max(eyes gene) max(... gene) max (... gene)},
archivePrefix = {arXiv},
arxivId = {1203.2990},
author = {Bengio, Yoshua},
eprint = {1203.2990},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio - 2012 - Evolving Culture vs Local Minima.pdf:pdf},
pages = {1--28},
title = {{Evolving Culture vs Local Minima}},
url = {http://arxiv.org/abs/1203.2990},
volume = {2006},
year = {2012}
}
@article{Wong2020,
abstract = {We introduce computational causal inference as an interdisciplinary field across causal inference, algorithms design and numerical computing. The field aims to develop software specializing in causal inference that can analyze massive datasets with a variety of causal effects, in a performant, general, and robust way. The focus on software improves research agility, and enables causal inference to be easily integrated into large engineering systems. In particular, we use computational causal inference to deepen the relationship between causal inference, online experimentation, and algorithmic decision making. This paper describes the new field, the demand, opportunities for scalability, open challenges, and begins the discussion for how the community can unite to solve challenges for scaling causal inference and decision making.},
annote = {difference in means as main metric?},
archivePrefix = {arXiv},
arxivId = {2007.10979},
author = {Wong, Jeffrey C.},
eprint = {2007.10979},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wong - 2020 - Computational Causal Inference(2).pdf:pdf},
title = {{Computational Causal Inference}},
url = {http://arxiv.org/abs/2007.10979},
year = {2020}
}
@techreport{Lipton,
abstract = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but inter-pretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for in-terpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim inter-pretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretabil-ity, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
archivePrefix = {arXiv},
arxivId = {1606.03490v3},
author = {Lipton, Zachary C},
eprint = {1606.03490v3},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lipton - Unknown - The Mythos of Model Interpretability.pdf:pdf},
title = {{The Mythos of Model Interpretability}}
}
@techreport{Hyvarinen2019,
abstract = {Nonlinear ICA is a fundamental problem for unsupervised representation learning, emphasizing the capacity to recover the underlying latent variables generating the data (i.e., identifiability). Recently, the very first iden-tifiability proofs for nonlinear ICA have been proposed, leveraging the temporal structure of the independent components. Here, we propose a general framework for nonlinear ICA, which, as a special case, can make use of temporal structure. It is based on augmenting the data by an auxiliary variable, such as the time index, the history of the time series , or any other available information. We propose to learn nonlinear ICA by discriminating between true augmented data, or data in which the auxiliary variable has been ran-domized. This enables the framework to be implemented algorithmically through logistic regression, possibly in a neural network. We provide a comprehensive proof of the identifi-ability of the model as well as the consistency of our estimation method. The approach not only provides a general theoretical framework combining and generalizing previously proposed nonlinear ICA models and algorithms, but also brings practical advantages.},
archivePrefix = {arXiv},
arxivId = {1805.08651v3},
author = {Hyv{\"{a}}rinen, Aapo and Sasaki, Hiroaki and Turner, Richard E},
eprint = {1805.08651v3},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hyv{\"{a}}rinen, Sasaki, Turner - 2019 - Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning.pdf:pdf},
title = {{Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning}},
year = {2019}
}
@techreport{Bachman,
abstract = {We investigate attention as the active pursuit of useful information. This contrasts with attention as a mechanism for the attenuation of irrelevant information. We also consider the role of short-term memory, whose use is critical to any model incapable of simultaneously perceiving all information on which its output depends. We present several simple synthetic tasks, which become considerably more interesting when we impose strong constraints on how a model can interact with its input, and on how long it can take to produce its output. We develop a model with a different structure from those seen in previous work, and we train it using stochastic variational inference with a learned proposal distribution.},
archivePrefix = {arXiv},
arxivId = {1510.08949v1},
author = {Bachman, Philip and Krueger, David and Precup, Doina},
eprint = {1510.08949v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bachman, Krueger, Precup - Unknown - Testing Visual Attention in Dynamic Environments.pdf:pdf},
title = {{Testing Visual Attention in Dynamic Environments}}
}
@article{Ehsan2018,
abstract = {We introduce AI rationalization, an approach for generating explanations of autonomous system behavior as if a human had performed the behavior. We describe a rationalization technique that uses neural machine translation to translate internal state-action representations of an autonomous agent into natural language. We evaluate our technique in the Frogger game environment, training an autonomous game playing agent to rationalize its action choices using natural language. A natural language training corpus is collected from human players thinking out loud as they play the game. We motivate the use of rationalization as an approach to explanation generation and show the results of two experiments evaluating the effectiveness of rationalization. Results of these evaluations show that neural machine translation is able to accurately generate rationalizations that describe agent behavior, and that rationalizations are more satisfying to humans than other alternative methods of explanation.},
archivePrefix = {arXiv},
arxivId = {1702.07826},
author = {Ehsan, Upol and Harrison, Brent and Chan, Larry and Riedl, Mark O.},
doi = {10.1145/3278721.3278736},
eprint = {1702.07826},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ehsan et al. - 2018 - Rationalization A Neural Machine Translation Approach to Generating Natural Language Explanations.pdf:pdf},
isbn = {9781450360128},
journal = {AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
keywords = {ai rationalization,artificial intelligence,explainable ai,interpretability,machine learning,transparency,user perception},
pages = {81--87},
title = {{Rationalization: A Neural Machine Translation Approach to Generating Natural Language Explanations}},
year = {2018}
}
@article{Dinh2015,
abstract = {We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the determinant of the Jacobian and inverse Jacobian is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
archivePrefix = {arXiv},
arxivId = {1410.8516},
author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
eprint = {1410.8516},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Krueger, Bengio - 2015 - NICE Non-linear independent components estimation.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Workshop Track Proceedings},
number = {2},
pages = {1--13},
title = {{NICE: Non-linear independent components estimation}},
volume = {1},
year = {2015}
}
@article{Oisy2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1905.01591v1},
author = {Oisy, N},
eprint = {arXiv:1905.01591v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oisy - 2019 - L Earning G Raph N Eural N Etworks.pdf:pdf},
number = {1},
pages = {1--5},
title = {{L Earning G Raph N Eural N Etworks}},
year = {2019}
}
@techreport{Gelada,
abstract = {Many reinforcement learning (RL) tasks provide the agent with high-dimensional observations that can be simplified into low-dimensional continuous states. To formalize this process, we introduce the concept of a DeepMDP, a parameterized latent space model that is trained via the minimization of two tractable losses: prediction of rewards and prediction of the distribution over next latent states. We show that the optimization of these objectives guarantees (1) the quality of the latent space as a representation of the state space and (2) the quality of the DeepMDP as a model of the environment. We connect these results to prior work in the bisimulation literature, and explore the use of a variety of metrics. Our theoretical findings are substantiated by the experimental result that a trained DeepMDP recovers the latent structure underlying high-dimensional observations on a synthetic environment. Finally, we show that learning a DeepMDP as an auxiliary task in the Atari 2600 domain leads to large performance improvements over model-free RL.},
archivePrefix = {arXiv},
arxivId = {1906.02736v1},
author = {Gelada, Carles and Kumar, Saurabh and Buckman, Jacob and Nachum, Ofir and Bellemare, Marc G},
eprint = {1906.02736v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelada et al. - Unknown - DeepMDP Learning Continuous Latent Space Models for Representation Learning.pdf:pdf},
title = {{DeepMDP: Learning Continuous Latent Space Models for Representation Learning}}
}
@techreport{Mitrovic,
abstract = {Self-supervised learning has emerged as a strategy to reduce the reliance on costly supervised signal by pretraining representations only using unlabeled data. These methods combine heuristic proxy classification tasks with data augmentations and have achieved significant success, but our theoretical understanding of this success remains limited. In this paper we analyze self-supervised representation learning using a causal framework. We show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. Based on this, we propose a novel self-supervised objective, Representation Learning via Invariant Causal Mechanisms (RELIC), that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. Further, using causality we generalize contrastive learning, a particular kind of self-supervised method, and provide an alternative theoretical explanation for the success of these methods. Empirically, RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet, while also significantly outperforming these methods on Atari achieving above human-level performance on 51 out of 57 games.},
archivePrefix = {arXiv},
arxivId = {2010.07922v1},
author = {Mitrovic, Jovana and Mcwilliams, Brian and Walker, Jacob and Buesing, Lars and Blundell, Charles},
eprint = {2010.07922v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitrovic et al. - Unknown - REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS.pdf:pdf},
isbn = {2010.07922v1},
title = {{REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS}}
}
@article{Tamkin2020,
abstract = {Many recent methods for unsupervised representation learning involve training models to be invariant to different "views," or transformed versions of an input. However, designing these views requires considerable human expertise and experimentation, hindering widespread adoption of unsupervised representation learning methods across domains and modalities. To address this, we propose viewmaker networks: generative models that learn to produce input-dependent views for contrastive learning. We train this network jointly with an encoder network to produce adversarial {\$}\backslashell{\_}p{\$} perturbations for an input, which yields challenging yet useful views without extensive human tuning. Our learned views, when applied to CIFAR-10, enable comparable transfer accuracy to the the well-studied augmentations used for the SimCLR model. Our views significantly outperforming baseline augmentations in speech (+9{\%} absolute) and wearable sensor (+17{\%} absolute) domains. We also show how viewmaker views can be combined with handcrafted views to improve robustness to common image corruptions. Our method demonstrates that learned views are a promising way to reduce the amount of expertise and effort needed for unsupervised learning, potentially extending its benefits to a much wider set of domains.},
archivePrefix = {arXiv},
arxivId = {2010.07432},
author = {Tamkin, Alex and Wu, Mike and Goodman, Noah},
eprint = {2010.07432},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamkin, Wu, Goodman - 2020 - Viewmaker Networks Learning Views for Unsupervised Representation Learning.pdf:pdf},
month = {oct},
title = {{Viewmaker Networks: Learning Views for Unsupervised Representation Learning}},
url = {http://arxiv.org/abs/2010.07432},
year = {2020}
}
@article{Javed2019,
abstract = {A continual learning agent should be able to build on top of existing knowledge to learn on new data quickly while minimizing forgetting. Current intelligent systems based on neural network function approximators arguably do the opposite—they are highly prone to forgetting and rarely trained to facilitate future learning. One reason for this poor behavior is that they learn from a representation that is not explicitly trained for these two goals. In this paper, we propose MRCL, an objective to explicitly learn representations that accelerate future learning and are robust to forgetting under online updates in continual learning. The idea is to optimize the representation such that online updates minimize error on all samples with little forgetting. We show that it is possible to learn representations that are more effective for online updating and that sparsity naturally emerges in these representations. Moreover, our method is complementary to existing continual learning strategies, like MER, which can learn more effectively from representations learned by our objective. Finally, we demonstrate that a basic online updating strategy with our learned representation is competitive with rehearsal based methods for continual learning. We release an implementation of our method at https://github.com/khurramjaved96/mrcl.},
archivePrefix = {arXiv},
arxivId = {1905.12588},
author = {Javed, Khurram and White, Martha},
eprint = {1905.12588},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Javed, White - 2019 - Meta-Learning Representations for Continual Learning.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--15},
title = {{Meta-Learning Representations for Continual Learning}},
year = {2019}
}
@article{,
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2020 - Learning Online-Aware Representations using Neural Networks.pdf:pdf},
title = {{Learning Online-Aware Representations using Neural Networks}},
year = {2020}
}
@techreport{Genewein,
abstract = {Probability trees are one of the simplest models of causal generative processes. They possess clean semantics and-unlike causal Bayesian networks-they can represent context-specific causal dependencies, which are necessary for e.g. causal induction. Yet, they have received little attention from the AI and ML community. Here we present concrete algorithms for causal reasoning in discrete probability trees that cover the entire causal hierarchy (association, intervention, and coun-terfactuals), and operate on arbitrary propositional and causal events. Our work expands the domain of causal reasoning to a very general class of discrete stochastic processes.},
archivePrefix = {arXiv},
arxivId = {2010.12237v2},
author = {Genewein, Tim and Mcgrath, Tom and Del{\'{e}}tang, Gr{\'{e}}goire and Mikulik, Vladimir and Martic, Miljan and Legg, Shane and Ortega, Pedro A},
eprint = {2010.12237v2},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Genewein et al. - Unknown - Algorithms for Causal Reasoning in Probability Trees.pdf:pdf},
isbn = {2010.12237v2},
title = {{Algorithms for Causal Reasoning in Probability Trees}},
url = {https://github.com/deepmind/deepmind-research/tree/master/causal{\_}reasoning}
}
@article{Combettes2019,
abstract = {Matching pursuit algorithms are an important class of algorithms in signal processing and machine learning. We present a blended matching pursuit algorithm, combining coordinate descent-like steps with stronger gradient descent steps, for minimizing a smooth convex function over a linear space spanned by a set of atoms. We derive sublinear to linear convergence rates according to the smoothness and sharpness orders of the function and demonstrate computational superiority of our approach. In particular, we derive linear rates for a large class of non-strongly convex functions, and we demonstrate in experiments that our algorithm enjoys very fast rates of convergence and wall-clock speed while maintaining a sparsity of iterates very comparable to that of the (much slower) orthogonal matching pursuit.},
archivePrefix = {arXiv},
arxivId = {1904.12335},
author = {Combettes, Cyrille W. and Pokutta, Sebastian},
eprint = {1904.12335},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Combettes, Pokutta - 2019 - Blended Matching Pursuit.pdf:pdf},
journal = {arXiv},
number = {1},
pages = {1--11},
title = {{Blended Matching Pursuit}},
year = {2019}
}
@article{Sulam2020,
abstract = {Parsimonious representations are ubiquitous in modeling and processing information. Motivated by the recent Multi-Layer Convolutional Sparse Coding (ML-CSC) model, we herein generalize the traditional Basis Pursuit problem to a multi-layer setting, introducing similar sparse enforcing penalties at different representation layers in a symbiotic relation between synthesis and analysis sparse priors. We explore different iterative methods to solve this new problem in practice, and we propose a new Multi-Layer Iterative Soft Thresholding Algorithm (ML-ISTA), as well as a fast version (ML-FISTA). We show that these nested first order algorithms converge, in the sense that the function value of near-fixed points can get arbitrarily close to the solution of the original problem. We further show how these algorithms effectively implement particular recurrent convolutional neural networks (CNNs) that generalize feed-forward ones without introducing any parameters. We present and analyze different architectures resulting from unfolding the iterations of the proposed pursuit algorithms, including a new Learned ML-ISTA, providing a principled way to construct deep recurrent CNNs. Unlike other similar constructions, these architectures unfold a global pursuit holistically for the entire network. We demonstrate the emerging constructions in a supervised learning setting, consistently improving the performance of classical CNNs while maintaining the number of parameters constant.},
archivePrefix = {arXiv},
arxivId = {1806.00701},
author = {Sulam, Jeremias and Aberdam, Aviad and Beck, Amir and Elad, Michael},
doi = {10.1109/TPAMI.2019.2904255},
eprint = {1806.00701},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sulam et al. - 2020 - On Multi-Layer Basis Pursuit, Efficient Algorithms and Convolutional Neural Networks.pdf:pdf},
issn = {19393539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Multi-layer convolutional sparse coding,iterative shrinkage algorithms,network unfolding,recurrent neural networks},
number = {8},
pages = {1968--1980},
pmid = {30869611},
title = {{On Multi-Layer Basis Pursuit, Efficient Algorithms and Convolutional Neural Networks}},
volume = {42},
year = {2020}
}
@article{Vincent2002,
abstract = {Matching Pursuit algorithms learn a function that is a weighted sum of basis functions, by sequentially appending functions to an initially empty basis, to approximate a target function in the least-squares sense. We show how matching pursuit can be extended to use non-squared error loss functions, and how it can be used to build kernel-based solutions to machine learning problems, while keeping control of the sparsity of the solution. We present a version of the algorithm that makes an optimal choice of both the next basis and the weights of all the previously chosen bases. Finally, links to boosting algorithms and RBF training procedures, as well as an extensive experimental comparison with SVMs for classification are given, showing comparable results with typically much sparser models.},
author = {Vincent, Pascal and Bengio, Yoshua},
doi = {10.1023/A:1013955821559},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vincent, Bengio - 2002 - Kernel matching pursuit.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Boosting,Kernel methods,Matching pursuit,Radial basis functions,Sparse approximation,Support vector machines},
number = {1-3},
pages = {165--187},
title = {{Kernel matching pursuit}},
volume = {48},
year = {2002}
}
@article{,
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2019 - The Neural Basis of Predictive Pursuit Short title.pdf:pdf},
title = {{The Neural Basis of Predictive Pursuit Short title}},
year = {2019}
}
@article{Yuan2018,
abstract = {Extreme learning machine (ELM) is a popular learning algorithm for single hidden layer feedforward networks (SLFNs). It was originally proposed with the inspiration from biological learning and has attracted massive attentions due to its adaptability to various tasks with a fast learning ability and efficient computation cost. As an effective sparse representation method, orthogonal matching pursuit (OMP) method can be embedded into ELM to overcome the singularity problem and improve the stability. Usually OMP recovers a sparse vector by minimizing a least squares (LS) loss, which is efficient for Gaussian distributed data, but may suffer performance deterioration in presence of non-Gaussian data. To address this problem, a robust matching pursuit method based on a novel kernel risk-sensitive loss (in short KRSLMP) is first proposed in this paper. The KRSLMP is then applied to ELM to solve the sparse output weight vector, and the new method named the KRSLMP-ELM is developed for SLFN learning. Experimental results on synthetic and real-world data sets confirm the effectiveness and superiority of the proposed method.},
author = {Yuan, Zejian and Wang, Xin and Cao, Jiuwen and Zhao, Haiquan and Chen, Badong},
doi = {10.1155/2018/4563040},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan et al. - 2018 - Robust Matching Pursuit Extreme Learning Machines.pdf:pdf},
issn = {10589244},
journal = {Scientific Programming},
pages = {11--13},
title = {{Robust Matching Pursuit Extreme Learning Machines}},
volume = {2018},
year = {2018}
}
@article{Barcelo2020,
abstract = {In spite of several claims stating that some models are more interpretable than others -- e.g., "linear models are more interpretable than deep neural networks" -- we still lack a principled notion of interpretability to formally compare among different classes of models. We make a step towards such a notion by studying whether folklore interpretability claims have a correlate in terms of computational complexity theory. We focus on local post-hoc explainability queries that, intuitively, attempt to answer why individual inputs are classified in a certain way by a given model. In a nutshell, we say that a class {\$}\backslashmathcal{\{}C{\}}{\_}1{\$} of models is more interpretable than another class {\$}\backslashmathcal{\{}C{\}}{\_}2{\$}, if the computational complexity of answering post-hoc queries for models in {\$}\backslashmathcal{\{}C{\}}{\_}2{\$} is higher than for those in {\$}\backslashmathcal{\{}C{\}}{\_}1{\$}. We prove that this notion provides a good theoretical counterpart to current beliefs on the interpretability of models; in particular, we show that under our definition and assuming standard complexity-theoretical assumptions (such as P{\$}\backslashneq{\$}NP), both linear and tree-based models are strictly more interpretable than neural networks. Our complexity analysis, however, does not provide a clear-cut difference between linear and tree-based models, as we obtain different results depending on the particular post-hoc explanations considered. Finally, by applying a finer complexity analysis based on parameterized complexity, we are able to prove a theoretical result suggesting that shallow neural networks are more interpretable than deeper ones.},
archivePrefix = {arXiv},
arxivId = {2010.12265},
author = {Barcel{\'{o}}, Pablo and Monet, Mika{\"{e}}l and P{\'{e}}rez, Jorge and Subercaseaux, Bernardo},
eprint = {2010.12265},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barcel{\'{o}} et al. - 2020 - Model Interpretability through the Lens of Computational Complexity.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Model Interpretability through the Lens of Computational Complexity}},
url = {http://arxiv.org/abs/2010.12265},
year = {2020}
}
@article{Volodin2020,
abstract = {Causal models could increase interpretability, robustness to distributional shift and sample efficiency of RL agents. In this vein, we address the question of learning a causal model of an RL environment. This problem is known to be difficult due to spurious correlations. We overcome this difficulty by rewarding an RL agent for designing and executing interventions to discover the true model. We compare rewarding the agent for disproving uncertain edges in the causal graph, rewarding the agent for activating a certain node, or rewarding the agent for increasing the causal graph loss. We show that our methods result in a better causal graph than one generated by following the random policy, or a policy trained on the environment's reward. We find that rewarding for the causal graph loss works the best.},
archivePrefix = {arXiv},
arxivId = {2002.05217},
author = {Volodin, Sergei and Wichers, Nevan and Nixon, Jeremy},
eprint = {2002.05217},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Volodin, Wichers, Nixon - 2020 - Resolving spurious correlations in causal models of environments via interventions.pdf:pdf},
journal = {arXiv},
title = {{Resolving spurious correlations in causal models of environments via interventions}},
year = {2020}
}
@article{Wang2020,
abstract = {A fundamental problem in the high-dimensional regression is to understand the tradeoff between type I and type II errors or, equivalently, false discovery rate (FDR) and power in variable selection. To address this important problem, we offer the first complete tradeoff diagram that distinguishes all pairs of FDR and power that can be asymptotically realized by the Lasso with some choice of its penalty parameter from the remaining pairs, in a regime of linear sparsity under random designs. The tradeoff between the FDR and power characterized by our diagram holds no matter how strong the signals are. In particular, our results improve on the earlier Lasso tradeoff diagram of [19] by recognizing two simple but fundamental constraints on the pairs of FDR and power. The improvement is more substantial when the regression problem is above the Donoho–Tanner phase transition. Finally, we present extensive simulation studies to confirm the sharpness of the complete Lasso tradeoff diagram.},
archivePrefix = {arXiv},
arxivId = {2007.11078},
author = {Wang, Hua and Yang, Yachong and Bu, Zhiqi and Su, Weijie J.},
eprint = {2007.11078},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - The Complete Lasso Tradeoff Diagram.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{The Complete Lasso Tradeoff Diagram}},
year = {2020}
}
@article{Ying2020,
author = {Ying, Jiaxi and Palomar, Daniel P and Analytics, Data and Bay, Clear Water and Kong, Hong},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ying et al. - 2020 - Nonconvex Sparse Graph Learning under Laplacian Constrained Graphical Model.pdf:pdf},
number = {NeurIPS},
pages = {1--13},
title = {{Nonconvex Sparse Graph Learning under Laplacian Constrained Graphical Model}},
year = {2020}
}
@article{Fallah2020,
author = {Fallah, Kion and Willats, Adam A and Liu, Ninghao and Rozell, Christopher J},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fallah et al. - 2020 - Learning sparse codes from compressed representations with biologically plausible local wiring constraints.pdf:pdf},
number = {NeurIPS},
title = {{Learning sparse codes from compressed representations with biologically plausible local wiring constraints}},
year = {2020}
}
@article{Brouillard2020,
abstract = {Discovering causal relationships in data is a challenging task that involves solving a combinatorial problem for which the solution is not always identifiable. A new line of work reformulates the combinatorial problem as a continuous constrained optimization one, enabling the use of different powerful optimization techniques. However, methods based on this idea do not yet make use of interventional data, which can significantly alleviate identifiability issues. In this work, we propose a neural network-based method for this task that can leverage interventional data. We illustrate the flexibility of the continuous-constrained framework by taking advantage of expressive neural architectures such as normalizing flows. We show that our approach compares favorably to the state of the art in a variety of settings, including perfect and imperfect interventions for which the targeted nodes may even be unknown.},
archivePrefix = {arXiv},
arxivId = {2007.01754},
author = {Brouillard, Philippe and Lachapelle, S{\'{e}}bastien and Lacoste, Alexandre and Lacoste-Julien, Simon and Drouin, Alexandre},
eprint = {2007.01754},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brouillard et al. - 2020 - Differentiable Causal Discovery from Interventional Data.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Differentiable Causal Discovery from Interventional Data}},
year = {2020}
}
@techreport{Jang,
abstract = {Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax esti-mator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification.},
archivePrefix = {arXiv},
arxivId = {1611.01144v5},
author = {Jang, Eric and Brain, Google and Gu, Shixiang and Poole, Ben},
eprint = {1611.01144v5},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jang et al. - Unknown - CATEGORICAL REPARAMETERIZATION WITH GUMBEL-SOFTMAX.pdf:pdf},
title = {{CATEGORICAL REPARAMETERIZATION WITH GUMBEL-SOFTMAX}}
}
@techreport{Kingma,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differ-entiability conditions, even works in the intractable case. Our contributions is twofold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114v10},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114v10},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Welling - Unknown - Auto-Encoding Variational Bayes(2).pdf:pdf},
title = {{Auto-Encoding Variational Bayes}}
}
@article{Schrittwieser2019,
abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},
archivePrefix = {arXiv},
arxivId = {1911.08265},
author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
eprint = {1911.08265},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schrittwieser et al. - 2019 - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.pdf:pdf},
journal = {arXiv},
month = {nov},
publisher = {arXiv},
title = {{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}},
url = {http://arxiv.org/abs/1911.08265},
year = {2019}
}
@article{Marschall2019,
abstract = {To which extent can successful machine learning inform our understanding of biological learning? One popular avenue of inquiry in recent years has been to directly map such algorithms into a realistic circuit implementation. Here we focus on learning in recurrent networks and investigate a range of learning algorithms. Our approach decomposes them into their computational building blocks and discusses their abstract potential as biological operations. This alternative strategy provides a "lazy" but principled way of evaluating ML ideas in terms of their biological plausibility. The phenomenal success of neurally inspired machine learning (ML) algorithms has captured the imagination of many neuroscientists hoping to understand the principles of learning in the brain. This led to renewed efforts to find biologically realistic approximations to the backpropagation algorithm, the key to efficient credit assignment in feedforward networks [1, 2, 3, 4, 5]. Relatively little work covers the-arguably more realistic-scenario of learning in recurrent networks and temporal credit assignment [6]. The canonical machine learning solution, backpropagation through time (BPTT, [7]), poses more severe challenges when attempting to map it to biology. In particular, BPTT is temporally nonlocal; that is, each weight update depends on network activity across multiple time points. This problem could be addressed by using online alternatives to BPTT such as Real-Time Recurrent Learning (RTRL, [8]). Unfortunately, RTRL has an O(n 3) memory requirement (for n neurons) and it is hard to imagine any biological structure for storing this many real-valued variables. The cubic complexity is a problem not only for biology, but also for machine learning and has precluded the use of RTRL in applications. Nonetheless, the practical need for efficient online learning has revived the RTRL idea, leading to several new algorithms [9, 10, 11, 12, 13], which all reduce memory complexity to O(n 2), but differ in the nature of their approximations [14]. Our goal here is to investigate to what extent these ideas could be implemented in a biological circuit. One could take each algorithm individually and try to model in detail a biophysical implementation, {\`{a}} la [1, 2, 3, 4, 5]. However, it's unlikely that any single ML solution maps one-to-one onto neural circuitry. Instead, a more useful exercise would be to identify core computational building blocks that are strictly necessary for solving temporal credit assignment, which are more likely to have a direct biological analogue. To this end, we put forward a principled framework for evaluating biological plausibility in terms of the mathematical operations required-hence our "lazy" analysis. We examine several online algorithms within this framework, identifying potential issues common across algorithms, for example the need to physically represent the Jacobian of the network dynamics. We propose some novel solutions to this and other issues and in the process articulate biological mechanisms that could facilitate these solutions. Finally, we empirically validate that these biologically realistic approximations still solve temporal credit assignment, in two simple synthetic tasks. Plausibility criteria for recurrent learning. Consider a recurrent network of n units, with voltages v (t) = WˆrWˆr (t−1) , wher{\^{e}} r (t) is the concatenation of recurrent and external inputs, with an additional constant input for the bias term, ˆ r (t−1) = [r (t−1) ; x (t) ; 1] ∈ R m (m = n + n in + 1) and trainable weights organized as W = [W rec , W in , b rec ] ∈ R n×m. For a closer match to neural circuits, the firing rates update in continuous time, via r (t) = (1 − $\alpha$)r (t−1) + $\alpha$$\phi$(v (t)), using a point-wise neural activation function $\phi$ : R n → R n (e.g. tanh) and the network's inverse time constant $\alpha$ ∈ (0, 1]. The network output y (t) = softmax(W out r (t) + b out) ∈ R nout is computed by output weights/bias W out ∈ R nout×n , b out ∈ R nout and compared with the training label y * (t) to produce an instantaneous loss L (t). BPTT and RTRL each provide a method for calculating the gradient of each instantaneous loss ∂L (t) /∂W ij , to be used for gradient descent. BPTT unrolls the network over time and performs backpropagation as if on a feedforward network: ∂L (t) ∂W ij = t ≤t c (t) t s=t +1 J (s) i $\alpha$$\phi$ (v (t) i)ˆ r (t −1) j , (1) 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.},
author = {Marschall, Owen and Cho, Kyunghyun and Savin, Cristina},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Marschall, Cho, Savin - 2019 - Evaluating biological plausibility of learning algorithms the lazy way.pdf:pdf},
number = {1},
pages = {1--5},
title = {{Evaluating biological plausibility of learning algorithms the lazy way}},
volume = {10003},
year = {2019}
}
@article{,
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2020 - Hippocampal neurons construct a map of an abstract value space.pdf:pdf},
title = {{Hippocampal neurons construct a map of an abstract value space}},
year = {2020}
}
@article{Gomez2006,
author = {G{\'{o}}mez, R and Bootzin, R and Nadel, L},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}mez, Bootzin, Nadel - 2006 - N Aps P Romote a Bstraction in L Anguage -L Earning I Nfants.pdf:pdf},
pages = {358},
title = {{N Aps P Romote a Bstraction in L Anguage -L Earning I Nfants}},
year = {2006}
}
@article{Uria2020,
author = {Uria, Benigno and Ibarz, Borja and Banino, Andrea and Zambaldi, Vinicius and Kumaran, Dharshan},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Uria et al. - 2020 - The Spatial Memory Pipeline a model of egocentric to allocentric understanding in mammalian brains.pdf:pdf},
pages = {1--52},
title = {{The Spatial Memory Pipeline : a model of egocentric to allocentric understanding in mammalian brains}},
year = {2020}
}
@article{Momennejad2020,
abstract = {Memory and planning rely on learning the structure of relationships among experiences. Compact representations of these structures guide flexible behavior in humans and animals. A century after ‘latent learning' experiments summarized by Tolman, the larger puzzle of cognitive maps remains elusive: how does the brain learn and generalize relational structures? This review focuses on a reinforcement learning (RL) approach to learning compact representations of the structure of states. We review evidence showing that capturing structures as predictive representations updated via replay offers a neurally plausible account of human behavior and the neural representations of predictive cognitive maps. We highlight multi-scale successor representations, prioritized replay, and policy-dependence. These advances call for new directions in studying the entanglement of learning and memory with prediction and planning.},
author = {Momennejad, Ida},
doi = {10.1016/j.cobeha.2020.02.017},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Momennejad - 2020 - Learning Structures Predictive Representations, Replay, and Generalization.pdf:pdf},
issn = {23521546},
journal = {Current Opinion in Behavioral Sciences},
pages = {155--166},
publisher = {Elsevier Ltd},
title = {{Learning Structures: Predictive Representations, Replay, and Generalization}},
url = {https://doi.org/10.1016/j.cobeha.2020.02.017},
volume = {32},
year = {2020}
}
@article{Sutton2015,
abstract = {Learning, planning, and representing knowledge at multiple levels of temporal abstraction are key, longstanding challenges for AI. In this paper we consider how these challenges can be addressed within the mathematical framework of reinforcement learning and Markov decision processes (MDPs). We extend the usual notion of action in this framework to include options—closed-loop policies for taking action over a period of time. Examples of options include picking up an object, going to lunch, and traveling to a distant city, as well as primitive actions such as muscle twitches and joint torques. Overall, we show that options enable temporally abstract knowledge and action to be included in the reinforcement learning framework in a natural and general way. In particular, we show that options may be used interchangeably with primitive actions in planning methods such as dynamic programming and in learning methods such as Q-learning. Formally, a set of options defined over an MDP constitutes a semi-Markov decision process (SMDP), and the theory ofSMDPs provides the foundation for the theory of options. However, the most interesting issues concern the interplay between the underlying MDP and the SMDP and are thus beyond SMDP theory. We present results for three such cases: (1) we show that the results of planning with options can be used during execution to interrupt options and thereby perform even better than planned, (2) we introduce new intra-option methods that are able to learn about an option from fragments of its execution, and (3) we propose a notion of subgoal that can be used to improve the options themselves. All of these results have precursors in the existing literature; the contribution of this paper is to establish them in a simpler and more general setting with fewer changes to the existing reinforcement learning framework. In particular, we show that these results can be obtained without committing to (or ruling out) any particular approach to state abstraction, hierarchy, function approximation, or the macro- utility problem.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Sutton, Richard S.; and Precup, Doina; and Singh, Satinder},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton, Precup, Singh - 2015 - Between MDPs and Semi-MDPs A Framework for Temporal Abstraction in RL.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Statewide Agricultural Land Use Baseline 2015},
keywords = {icle},
number = {1},
pages = {181--211},
pmid = {25246403},
title = {{Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in RL}},
volume = {1},
year = {2015}
}
@article{Schmidhuber2009,
abstract = {I argue that data becomes temporarily interesting by itself to some self-improving, but computationally limited, subjective observer once he learns to predict or compress the data in a better way, thus making it subjectively simpler and more beautiful. Curiosity is the desire to create or discover more non-random, non-arbitrary, regular data that is novel and surprising not in the traditional sense of Boltzmann and Shannon but in the sense that it allows for compression progress because its regularity was not yet known. This drive maximizes interestingness, the first derivative of subjective beauty or compressibility, that is, the steepness of the learning curve. It motivates exploring infants, pure mathematicians, composers, artists, dancers, comedians, yourself, and (since 1990) artificial systems. {\textcopyright} 2009 Springer Berlin Heidelberg.},
archivePrefix = {arXiv},
arxivId = {0812.4360},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1007/978-3-642-02565-5_4},
eprint = {0812.4360},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2009 - Driven by compression progress A simple principle explains essential aspects of subjective beauty, novelty, surpris.pdf:pdf},
isbn = {3642025641},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {April 2009},
pages = {48--76},
title = {{Driven by compression progress: A simple principle explains essential aspects of subjective beauty, novelty, surprise, interestingness, attention, curiosity, creativity, art, science, music, jokes}},
volume = {5499 LNAI},
year = {2009}
}
@article{Hudson2018,
abstract = {We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9{\%} accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.},
archivePrefix = {arXiv},
arxivId = {1803.03067},
author = {Hudson, Drew A. and Manning, Christopher D.},
eprint = {1803.03067},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hudson, Manning - 2018 - Compositional attention networks for machine reasoning.pdf:pdf},
journal = {arXiv},
pages = {1--20},
title = {{Compositional attention networks for machine reasoning}},
year = {2018}
}
@article{Stooke2020,
abstract = {In an effort to overcome limitations of reward-driven feature learning in deep reinforcement learning (RL) from images, we propose decoupling representation learning from policy learning. To this end, we introduce a new unsupervised learning (UL) task, called Augmented Temporal Contrast (ATC), which trains a convolutional encoder to associate pairs of observations separated by a short time difference, under image augmentations and using a contrastive loss. In online RL experiments, we show that training the encoder exclusively using ATC matches or outperforms end-to-end RL in most environments. Additionally, we benchmark several leading UL algorithms by pre-training encoders on expert demonstrations and using them, with weights frozen, in RL agents; we find that agents using ATC-trained encoders outperform all others. We also train multi-task encoders on data from multiple environments and show generalization to different downstream RL tasks. Finally, we ablate components of ATC, and introduce a new data augmentation to enable replay of (compressed) latent images from pre-trained encoders when RL requires augmentation. Our experiments span visually diverse RL benchmarks in DeepMind Control, DeepMind Lab, and Atari, and our complete code is available at https://github.com/astooke/rlpyt/tree/master/rlpyt/ul.},
archivePrefix = {arXiv},
arxivId = {2009.08319},
author = {Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
eprint = {2009.08319},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stooke et al. - 2020 - Decoupling Representation Learning from Reinforcement Learning.pdf:pdf},
title = {{Decoupling Representation Learning from Reinforcement Learning}},
url = {http://arxiv.org/abs/2009.08319},
year = {2020}
}
@article{Maire2020,
abstract = {We create a framework for bootstrapping visual representation learning from a primitive visual grouping capability. We operationalize grouping via a contour detector that partitions an image into regions, followed by merging of those regions into a tree hierarchy. A small supervised dataset suffices for training this grouping primitive. Across a large unlabeled dataset, we apply this learned primitive to automatically predict hierarchical region structure. These predictions serve as guidance for self-supervised contrastive feature learning: we task a deep network with producing per-pixel embeddings whose pairwise distances respect the region hierarchy. Experiments demonstrate that our approach can serve as state-of-the-art generic pre-training, benefiting downstream tasks. We additionally explore applications to semantic region search and video-based object instance tracking.},
archivePrefix = {arXiv},
arxivId = {arXiv:2012.03044v1},
author = {Maire, Michael},
eprint = {arXiv:2012.03044v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Maire - 2020 - Self-Supervised Visual Representation Learning from Hierarchical Grouping.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Self-Supervised Visual Representation Learning from Hierarchical Grouping}},
year = {2020}
}
@article{Anonymous2021,
abstract = {Thanks to the tractability of their likelihood, some deep generative models show promise for seemingly straightforward but important applications like anomaly detection, uncertainty estimation, and active learning. However, the likelihood values empirically attributed to anomalies conflict with the expectations these proposed applications suggest. In this paper, we take a closer look at the behavior of distribution densities and show that these quantities carry less meaningful information than previously thought, beyond estimation issues or the curse of dimensionality. We conclude that the use of these likelihoods for out-of-distribution detection relies on strong and implicit hypotheses, and highlight the necessity of explicitly formulating these assumptions for reliable anomaly detection.},
archivePrefix = {arXiv},
arxivId = {arXiv:2012.03808v1},
author = {Anonymous},
eprint = {arXiv:2012.03808v1},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anonymous - 2021 - Perfect density models cannot guarantee anomaly detection.pdf:pdf},
journal = {Submitted to International Conference on Learning Representations},
pages = {1--12},
title = {{Perfect density models cannot guarantee anomaly detection}},
url = {https://openreview.net/forum?id=MkrAyYVmt7b},
year = {2021}
}
@article{Kunin2020,
abstract = {Predicting the dynamics of neural network parameters during training is one of the key challenges in building a theoretical foundation for deep learning. A central obstacle is that the motion of a network in high-dimensional parameter space undergoes discrete finite steps along complex stochastic gradients derived from real-world datasets. We circumvent this obstacle through a unifying theoretical framework based on intrinsic symmetries embedded in a network's architecture that are present for any dataset. We show that any such symmetry imposes stringent geometric constraints on gradients and Hessians, leading to an associated conservation law in the continuous-time limit of stochastic gradient descent (SGD), akin to Noether's theorem in physics. We further show that finite learning rates used in practice can actually break these symmetry induced conservation laws. We apply tools from finite difference methods to derive modified gradient flow, a differential equation that better approximates the numerical trajectory taken by SGD at finite learning rates. We combine modified gradient flow with our framework of symmetries to derive exact integral expressions for the dynamics of certain parameter combinations. We empirically validate our analytic predictions for learning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting symmetry, our work demonstrates that we can analytically describe the learning dynamics of various parameter combinations at finite learning rates and batch sizes for state of the art architectures trained on any dataset.},
archivePrefix = {arXiv},
arxivId = {2012.04728},
author = {Kunin, Daniel and Sagastuy-Brena, Javier and Ganguli, Surya and Yamins, Daniel L. K. and Tanaka, Hidenori},
eprint = {2012.04728},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kunin et al. - 2020 - Neural Mechanics Symmetry and Broken Conservation Laws in Deep Learning Dynamics.pdf:pdf},
title = {{Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics}},
url = {http://arxiv.org/abs/2012.04728},
year = {2020}
}
@article{Zhou2018,
abstract = {—Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
archivePrefix = {arXiv},
arxivId = {1812.08434},
author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
eprint = {1812.08434},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2018 - Graph Neural Networks A Review of Methods and Applications.pdf:pdf},
journal = {arXiv},
keywords = {Deep Learning,,Graph Neural Network},
pages = {1--22},
title = {{Graph Neural Networks: A Review of Methods and Applications}},
year = {2018}
}
@article{Zhang2019a,
abstract = {Understanding deep neural networks has been a major research objective in recent years with notable theoretical progress. A focal point of those studies stems from the success of excessively large networks which defy the classical wisdom of uniform convergence and learnability. We study empirically the layer-wise functional structure of overparameterized deep models. We provide evidence for the heterogeneous characteristic of layers. To do so, we introduce the notion of robustness to post-training re-initialization and re-randomization. We show that the layers can be categorized as either "ambient" or "critical". Resetting the ambient layers to their initial values has no negative consequence, and in many cases they barely change throughout training. On the contrary, resetting the critical layers completely destroys the predictor and the performance drops to chanceh. Our study provides further evidence that mere parameter counting or norm accounting is too coarse in studying generalization of deep models, and flatness or robustness analysis of the models needs to respect the network architectures.},
archivePrefix = {arXiv},
arxivId = {1902.01996},
author = {Zhang, Chiyuan and Bengio, Samy and Singer, Yoram},
eprint = {1902.01996},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Bengio, Singer - 2019 - Are all layers created equal.pdf:pdf},
journal = {arXiv},
pages = {1--18},
title = {{Are all layers created equal?}},
year = {2019}
}
@article{Veerapaneni2019,
abstract = {This paper tests the hypothesis that modeling a scene in terms of entities and their local interactions, as opposed to modeling the scene globally, provides a significant benefit in generalizing to physical tasks in a combinatorial space the learner has not encountered before. We present object-centric perception, prediction, and planning (OP3), which to the best of our knowledge is the first fully probabilistic entity-centric dynamic latent variable framework for model-based reinforcement learning that acquires entity representations from raw visual observations without supervision and uses them to predict and plan. OP3 enforces entity-abstraction -- symmetric processing of each entity representation with the same locally-scoped function -- which enables it to scale to model different numbers and configurations of objects from those in training. Our approach to solving the key technical challenge of grounding these entity representations to actual objects in the environment is to frame this variable binding problem as an inference problem, and we develop an interactive inference algorithm that uses temporal continuity and interactive feedback to bind information about object properties to the entity variables. On block-stacking tasks, OP3 generalizes to novel block configurations and more objects than observed during training, outperforming an oracle model that assumes access to object supervision and achieving two to three times better accuracy than a state-of-the-art video prediction model that does not exhibit entity abstraction.},
archivePrefix = {arXiv},
arxivId = {1910.12827},
author = {Veerapaneni, Rishi and Co-Reyes, John D. and Chang, Michael and Janner, Michael and Finn, Chelsea and Wu, Jiajun and Tenenbaum, Joshua B. and Levine, Sergey},
eprint = {1910.12827},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Veerapaneni et al. - 2019 - Entity Abstraction in Visual Model-Based Reinforcement Learning.pdf:pdf},
keywords = {compositionality,model-based reinforcement learning,objects},
number = {CoRL},
pages = {1--19},
title = {{Entity Abstraction in Visual Model-Based Reinforcement Learning}},
url = {http://arxiv.org/abs/1910.12827},
year = {2019}
}
@article{Wortsman2020,
abstract = {We present the Supermasks in Superposition (SupSup) model, capable of sequentially learning thousands of tasks without catastrophic forgetting. Our approach uses a randomly initialized, fixed base network and for each task finds a subnetwork (supermask) that achieves good performance. If task identity is given at test time, the correct subnetwork can be retrieved with minimal memory usage. If not provided, SupSup can infer the task using gradient-based optimization to find a linear superposition of learned supermasks which minimizes the output entropy. In practice we find that a single gradient step is often sufficient to identify the correct mask, even among 2500 tasks. We also showcase two promising extensions. First, SupSup models can be trained entirely without task identity information, as they may detect when they are uncertain about new data and allocate an additional supermask for the new training distribution. Finally the entire, growing set of supermasks can be stored in a constant-sized reservoir by implicitly storing them as attractors in a fixed-sized Hopfield network.},
archivePrefix = {arXiv},
arxivId = {2006.14769},
author = {Wortsman, Mitchell and Ramanujan, Vivek and Liu, Rosanne and Kembhavi, Aniruddha and Rastegari, Mohammad and Yosinski, Jason and Farhadi, Ali},
eprint = {2006.14769},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wortsman et al. - 2020 - Supermasks in Superposition.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Supermasks in Superposition}},
year = {2020}
}
@article{Mohammadi2020,
abstract = {The effective application of representation learning to real-world problems requires both techniques for learning useful representations, and also robust ways to evaluate properties of representations. Recent work in disentangled representation learning has shown that unsupervised representation learning approaches rely on fully supervised disentanglement metrics, which assume access to labels for ground-truth factors of variation. In many real-world cases ground-truth factors are expensive to collect, or difficult to model, such as for perception. Here we empirically show that a weakly-supervised downstream task based on odd-one-out observations is suitable for model selection by observing high correlation on a difficult downstream abstract visual reasoning task. We also show that a bespoke metric-learning VAE model which performs highly on this task also out-performs other standard unsupervised and a weakly-supervised disentanglement model across several metrics.},
archivePrefix = {arXiv},
arxivId = {2012.07966},
author = {Mohammadi, Salman and Uhrenholt, Anders Kirk and Jensen, Bj{\o}rn Sand},
eprint = {2012.07966},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohammadi, Uhrenholt, Jensen - 2020 - Odd-One-Out Representation Learning.pdf:pdf},
title = {{Odd-One-Out Representation Learning}},
url = {http://arxiv.org/abs/2012.07966},
year = {2020}
}
@article{Ding2020,
abstract = {Neural networks have achieved success in a wide array of perceptual tasks, but it is often stated that they are incapable of solving tasks that require higher-level reasoning. Two new task domains, CLEVRER and CATER, have recently been developed to focus on reasoning, as opposed to perception, in the context of spatio-temporal interactions between objects. Initial experiments on these domains found that neuro-symbolic approaches, which couple a logic engine and language parser with a neural perceptual front-end, substantially outperform fully-learned distributed networks, a finding that was taken to support the above thesis. Here, we show on the contrary that a fully-learned neural network with the right inductive biases can perform substantially better than all previous neural-symbolic models on both of these tasks, particularly on questions that most emphasize reasoning over perception. Our model makes critical use of both self-attention and learned "soft" object-centric representations, as well as BERT-style semi-supervised predictive losses. These flexible biases allow our model to surpass the previous neuro-symbolic state-of-the-art using less than 60{\%} of available labelled data. Together, these results refute the neuro-symbolic thesis laid out by previous work involving these datasets, and they provide evidence that neural networks can indeed learn to reason effectively about the causal, dynamic structure of physical events.},
archivePrefix = {arXiv},
arxivId = {2012.08508},
author = {Ding, David and Hill, Felix and Santoro, Adam and Botvinick, Matt},
eprint = {2012.08508},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - 2020 - Object-based attention for spatio-temporal reasoning Outperforming neuro-symbolic models with flexible distributed.pdf:pdf},
title = {{Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architectures}},
url = {http://arxiv.org/abs/2012.08508},
year = {2020}
}
@article{VanRullen2020,
abstract = {Recent advances in deep learning have allowed Artificial Intelligence (AI) to reach near human-level performance in many sensory, perceptual, linguistic or cognitive tasks. There is a growing need, however, for novel, brain-inspired cognitive architectures. The Global Workspace theory refers to a large-scale system integrating and distributing information among networks of specialized modules to create higher-level forms of cognition and awareness. We argue that the time is ripe to consider explicit implementations of this theory using deep learning techniques. We propose a roadmap based on unsupervised neural translation between multiple latent spaces (neural networks trained for distinct tasks, on distinct sensory inputs and/or modalities) to create a unique, amodal global latent workspace (GLW). Potential functional advantages of GLW are reviewed.},
archivePrefix = {arXiv},
arxivId = {2012.10390},
author = {VanRullen, Rufin and Kanai, Ryota},
eprint = {2012.10390},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/VanRullen, Kanai - 2020 - Deep Learning and the Global Workspace Theory.pdf:pdf},
pages = {1--16},
title = {{Deep Learning and the Global Workspace Theory}},
url = {http://arxiv.org/abs/2012.10390},
year = {2020}
}
@article{Cortese2020,
author = {Cortese, Aurelio and Yamamoto, Asuka and Hashemzadeh, Maryam and Sepulveda, Pradyumna and Kawato, Mitsuo and Martino, Benedetto De},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cortese et al. - 2020 - Value Shapes Abstraction During Learning.pdf:pdf},
journal = {PsyArXiv},
keywords = {abstraction,fmri,hippocampus,multivoxel neurofeedback,neural reinforcement,reinforcement learning,sensory features,vmpfc},
pages = {1--36},
title = {{Value Shapes Abstraction During Learning}},
year = {2020}
}
@article{Sariyildiz2020,
abstract = {Measuring concept generalization, i.e., the extent to which models trained on a set of (seen) visual concepts can be used to recognize a new set of (unseen) concepts, is a popular way of evaluating visual representations, especially when they are learned with self-supervised learning. Nonetheless, the choice of which unseen concepts to use is usually made arbitrarily, and independently from the seen concepts used to train representations, thus ignoring any semantic relationships between the two. In this paper, we argue that semantic relationships between seen and unseen concepts affect generalization performance and propose ImageNet-CoG, a novel benchmark on the ImageNet dataset that enables measuring concept generalization in a principled way. Our benchmark leverages expert knowledge that comes from WordNet in order to define a sequence of unseen ImageNet concept sets that are semantically more and more distant from the ImageNet-1K subset, a ubiquitous training set. This allows us to benchmark visual representations learned on ImageNet-1K out-of-the box: we analyse a number of such models from supervised, semi-supervised and self-supervised approaches under the prism of concept generalization, and show how our benchmark is able to uncover a number of interesting insights. We will provide resources for the benchmark at https://europe.naverlabs.com/cog-benchmark.},
archivePrefix = {arXiv},
arxivId = {2012.05649},
author = {Sariyildiz, Mert Bulent and Kalantidis, Yannis and Larlus, Diane and Alahari, Karteek},
eprint = {2012.05649},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sariyildiz et al. - 2020 - Concept Generalization in Visual Representation Learning.pdf:pdf},
title = {{Concept Generalization in Visual Representation Learning}},
url = {http://arxiv.org/abs/2012.05649},
year = {2020}
}
@article{Li2020,
abstract = {Low-dimension graph embeddings have proved extremely useful in various downstream tasks in large graphs, e.g., link-related content recommendation and node classification tasks, etc. Most existing embedding approaches take nodes as the basic unit for information aggregation, e.g., node perception fields in GNN or con-textual nodes in random walks. The main drawback raised by such node-view is its lack of support for expressing the compound relationships between nodes, which results in the loss of a certain degree of graph information during embedding. To this end, this paper pro-poses PairE(Pair Embedding), a solution to use "pair", a higher level unit than a "node" as the core for graph embeddings. Accordingly, a multi-self-supervised auto-encoder is designed to fulfill two pretext tasks, to reconstruct the feature distribution for respective pairs and their surrounding context. PairE has three major advantages: 1) Informative, embedding beyond node-view are capable to preserve richer information of the graph; 2) Simple, the solutions provided by PairE are time-saving, storage-efficient, and require the fewer hyper-parameters; 3) High adaptability, with the introduced translator operator to map pair embeddings to the node embeddings, PairE can be effectively used in both the link-based and the node-based graph analysis. Experiment results show that PairE consistently outperforms the state of baselines in all four downstream tasks, especially with significant edges in the link-prediction and multi-label node classification tasks.},
archivePrefix = {arXiv},
arxivId = {2012.06113},
author = {Li, You and Luo, Binli and Gui, Ning},
eprint = {2012.06113},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Luo, Gui - 2020 - Pair-view Unsupervised Graph Representation Learning.pdf:pdf},
title = {{Pair-view Unsupervised Graph Representation Learning}},
url = {http://arxiv.org/abs/2012.06113},
year = {2020}
}
@article{Song2020,
abstract = {Syntactic structure of a sentence text is correlated with the prosodic structure of the speech that is crucial for improving the prosody and naturalness of a text-to-speech (TTS) system. Nowadays TTS systems usually try to incorporate syntactic structure information with manually designed features based on expert knowledge. In this paper, we propose a syntactic representation learning method based on syntactic parse tree traversal to automatically utilize the syntactic structure information. Two constituent label sequences are linearized through left-first and right-first traversals from constituent parse tree. Syntactic representations are then extracted at word level from each constituent label sequence by a corresponding uni-directional gated recurrent unit (GRU) network. Meanwhile, nuclear-norm maximization loss is introduced to enhance the discriminability and diversity of the embeddings of constituent labels. Upsampled syntactic representations and phoneme embeddings are concatenated to serve as the encoder input of Tacotron2. Experimental results demonstrate the effectiveness of our proposed approach, with mean opinion score (MOS) increasing from 3.70 to 3.82 and ABX preference exceeding by 17{\%} compared with the baseline. In addition, for sentences with multiple syntactic parse trees, prosodic differences can be clearly perceived from the synthesized speeches.},
archivePrefix = {arXiv},
arxivId = {2012.06971},
author = {Song, Changhe and Li, Jingbei and Zhou, Yixuan and Wu, Zhiyong and Meng, Helen},
eprint = {2012.06971},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2020 - Syntactic representation learning for neural network based TTS with syntactic parse tree traversal.pdf:pdf},
pages = {2--6},
title = {{Syntactic representation learning for neural network based TTS with syntactic parse tree traversal}},
url = {http://arxiv.org/abs/2012.06971},
year = {2020}
}
@article{Abramson2020,
abstract = {A common vision from science fiction is that robots will one day inhabit our physical spaces, sense the world as we do, assist our physical labours, and communicate with us through natural language. Here we study how to design artificial agents that can interact naturally with humans using the simplification of a virtual environment. This setting nevertheless integrates a number of the central challenges of artificial intelligence (AI) research: complex visual perception and goal-directed physical control, grounded language comprehension and production, and multi-agent social interaction. To build agents that can robustly interact with humans, we would ideally train them while they interact with humans. However, this is presently impractical. Therefore, we approximate the role of the human with another learned agent, and use ideas from inverse reinforcement learning to reduce the disparities between human-human and agent-agent interactive behaviour. Rigorously evaluating our agents poses a great challenge, so we develop a variety of behavioural tests, including evaluation by humans who watch videos of agents or interact directly with them. These evaluations convincingly demonstrate that interactive training and auxiliary losses improve agent behaviour beyond what is achieved by supervised learning of actions alone. Further, we demonstrate that agent capabilities generalise beyond literal experiences in the dataset. Finally, we train evaluation models whose ratings of agents agree well with human judgement, thus permitting the evaluation of new agent models without additional effort. Taken together, our results in this virtual environment provide evidence that large-scale human behavioural imitation is a promising tool to create intelligent, interactive agents, and the challenge of reliably evaluating such agents is possible to surmount.},
archivePrefix = {arXiv},
arxivId = {2012.05672},
author = {Abramson, Josh and Ahuja, Arun and Brussee, Arthur and Carnevale, Federico and Cassin, Mary and Clark, Stephen and Dudzik, Andrew and Georgiev, Petko and Guy, Aurelia and Harley, Tim and Hill, Felix and Hung, Alden and Kenton, Zachary and Landon, Jessica and Lillicrap, Timothy and Mathewson, Kory and Muldal, Alistair and Santoro, Adam and Savinov, Nikolay and Varma, Vikrant and Wayne, Greg and Wong, Nathaniel and Yan, Chen and Zhu, Rui},
eprint = {2012.05672},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramson et al. - 2020 - Imitating Interactive Intelligence.pdf:pdf},
pages = {1--96},
title = {{Imitating Interactive Intelligence}},
url = {http://arxiv.org/abs/2012.05672},
year = {2020}
}
@article{Dong2020a,
abstract = {Traditional change detection (CD) methods operate in the simple image domain or hand-crafted features, which has less robustness to the inconsistencies (e.g., brightness and noise distribution, etc.) between bitemporal satellite images. Recently, deep learning techniques have reported compelling performance on robust feature learning. However, generating accurate semantic supervision that reveals real change information in satellite images still remains challenging, especially for manual annotation. To solve this problem, we propose a novel self-supervised representation learning method based on temporal prediction for remote sensing image CD. The main idea of our algorithm is to transform two satellite images into more consistent feature representations through a self-supervised mechanism without semantic supervision and any additional computations. Based on the transformed feature representations, a better difference image (DI) can be obtained, which reduces the propagated error of DI on the final detection result. In the self-supervised mechanism, the network is asked to identify different sample patches between two temporal images, namely, temporal prediction. By designing the network for the temporal prediction task to imitate the discriminator of generative adversarial networks, the distribution-aware feature representations are automatically captured and the result with powerful robustness can be acquired. Experimental results on real remote sensing data sets show the effectiveness and superiority of our method, improving the detection precision up to 0.94-35.49{\%}.},
author = {Dong, Huihui and Ma, Wenping and Wu, Yue and Zhang, Jun and Jiao, Licheng},
doi = {10.3390/rs12111868},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong et al. - 2020 - Self-supervised representation learning for remote sensing image change detection based on temporal prediction.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Deep belief networks,Generative adversarial networks,Remote sensing images,Self-supervised representation learning,Unsupervised change detection},
number = {11},
pages = {1--38},
title = {{Self-supervised representation learning for remote sensing image change detection based on temporal prediction}},
volume = {12},
year = {2020}
}
@article{Sun2020,
abstract = {The brain codes continuous spatial, temporal and sensory changes in daily experience. Recent studies suggest that the brain also tracks experience as segmented subdivisions (events), but the neural basis for encoding events remains unclear. Here, we designed a maze for mice, composed of four materially indistinguishable lap events, and identify hippocampal CA1 neurons whose activity are modulated not only by spatial location but also lap number. These ‘event-specific rate remapping' (ESR) cells remain lap-specific even when the maze length is unpredictably altered within trials, which suggests that ESR cells treat lap events as fundamental units. The activity pattern of ESR cells is reused to represent lap events when the maze geometry is altered from square to circle, which suggests that it helps transfer knowledge between experiences. ESR activity is separately manipulable from spatial activity, and may therefore constitute an independent hippocampal code: an ‘event code' dedicated to organizing experience by events as discrete and transferable units.},
author = {Sun, Chen and Yang, Wannan and Martin, Jared and Tonegawa, Susumu},
doi = {10.1038/s41593-020-0614-x},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2020 - Hippocampal neurons represent events as transferable units of experience(2).pdf:pdf},
issn = {15461726},
journal = {Nature Neuroscience},
number = {5},
pages = {651--663},
pmid = {32251386},
publisher = {Springer US},
title = {{Hippocampal neurons represent events as transferable units of experience}},
url = {http://dx.doi.org/10.1038/s41593-020-0614-x},
volume = {23},
year = {2020}
}
@article{Wilson2020,
abstract = {The key distinguishing property of a Bayesian approach is marginalization, rather than using a single setting of weights. Bayesian marginalization can particularly improve the accuracy and calibration of modern deep neural networks, which are typically underspecified by the data, and can represent many compelling but different solutions. We show that deep ensembles provide an effective mechanism for approximate Bayesian marginalization, and propose a related approach that further improves the predictive distribution by marginalizing within basins of attraction, without significant overhead. We also investigate the prior over functions implied by a vague distribution over neural network weights, explaining the generalization properties of such models from a probabilistic perspective. From this perspective, we explain results that have been presented as mysterious and distinct to neural network generalization, such as the ability to fit images with random labels, and show that these results can be reproduced with Gaussian processes. We also show that Bayesian model averaging alleviates double descent, resulting in monotonic performance improvements with increased flexibility. Finally, we provide a Bayesian perspective on tempering for calibrating predictive distributions.},
archivePrefix = {arXiv},
arxivId = {2002.08791},
author = {Wilson, Andrew Gordon and Izmailov, Pavel},
eprint = {2002.08791},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilson, Izmailov - 2020 - Bayesian deep learning and a probabilistic perspective of generalization.pdf:pdf},
journal = {arXiv},
number = {3},
title = {{Bayesian deep learning and a probabilistic perspective of generalization}},
year = {2020}
}
@book{VanOpheusden2020,
abstract = {The fate of scientific hypotheses often relies on the ability of a computational model to explain the data, quantified in modern statistical approaches by the likelihood function. The log-likelihood is the key element for parameter estimation and model evaluation. However, the log-likelihood of complex models in fields such as computational biology and neuroscience is often intractable to compute analytically or numerically. In those cases, researchers can often only estimate the log-likelihood by comparing observed data with synthetic observations generated by model simulations. Standard techniques to approximate the likelihood via simulation either use summary statistics of the data or are at risk of producing severe biases in the estimate. Here, we explore another method, inverse binomial sampling (IBS), which can estimate the log-likelihood of an entire data set efficiently and without bias. For each observation, IBS draws samples from the simulator model until one matches the observation. The log-likelihood estimate is then a function of the number of samples drawn. The variance of this estimator is uniformly bounded, achieves the minimum variance for an unbiased estimator, and we can compute calibrated estimates of the variance. We provide theoretical arguments in favor of IBS and an empirical assessment of the method for maximum-likelihood estimation with simulation-based models. As case studies, we take three model-fitting problems of increasing complexity from computational and cognitive neuroscience. In all problems, IBS generally produces lower error in the estimated parameters and maximum log-likelihood values than alternative sampling methods with the same average number of samples. Our results demonstrate the potential of IBS as a practical, robust, and easy to implement method for log-likelihood evaluation when exact techniques are not available.},
archivePrefix = {arXiv},
arxivId = {2001.03985},
author = {van Opheusden, Bas and Acerbi, Luigi and Ma, Wei Ji},
booktitle = {arXiv},
doi = {10.1371/journal.pcbi.1008483},
eprint = {2001.03985},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van Opheusden, Acerbi, Ma - 2020 - Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial Sampling.pdf:pdf},
isbn = {1111111111},
keywords = {Likelihood-free inference,Maximum-likelihood estimation,Simulation model},
pages = {1--32},
title = {{Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial Sampling}},
url = {http://dx.doi.org/10.1371/journal.pcbi.1008483},
year = {2020}
}
@article{Lampinen2020,
abstract = {An important aspect of intelligence is the ability to adapt to a novel task without any direct experience (zero-shot), based on its relationship to previous tasks. Humans can exhibit this cognitive flexibility. By contrast, deep-learning models that achieve superhuman performance in specific tasks generally fail to adapt to even slight task alterations. To address this, we propose a general computational framework for adapting to novel tasks based on their relationship to prior tasks. We begin by learning vector representations of tasks. To adapt to new tasks, we propose meta-mappings, higher-order tasks that transform basic task representations. We demonstrate this framework across a wide variety of tasks and computational paradigms, ranging from regression to image classification and reinforcement learning. We compare to both human adaptability, and language-based approaches to zero-shot learning. Across these domains, meta-mapping is successful, often achieving 80-90{\%} performance, without any data, on a novel task that directly contradicts its prior experience. We further show that using meta-mapping as a starting point can dramatically accelerate later learning on a new task, and reduce learning time and cumulative error substantially. Our results provide insight into a possible computational basis of intelligent adaptability, and offer a possible framework for modeling cognitive flexibility and building more flexible artificial intelligence.},
archivePrefix = {arXiv},
arxivId = {arXiv:2005.04318v3},
author = {Lampinen, Andrew K. and McClelland, James L.},
eprint = {arXiv:2005.04318v3},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lampinen, McClelland - 2020 - Transforming task representations to allow deep learning models to perform novel tasks.pdf:pdf},
journal = {arXiv},
title = {{Transforming task representations to allow deep learning models to perform novel tasks}},
year = {2020}
}
@article{Heyes2018,
abstract = {Cognitive gadgets are distinctively human neurocognitive mechanisms - such as imitation, mindreading, and language - that have been shaped by cultural rather than genetic evolution. New gadgets emerge, not by genetic mutation, but by innovations in cognitive development; they are specialised cognitive mechanisms built by general cognitive mechanisms using information from the sociocultural environment. Innovations are passed on to subsequent generations, not by DNA replication, but through social learning: people with a new cognitive mechanism pass it on to others through social interaction. And some of the new mechanisms, like literacy, have spread through human populations, while others have died out, because the holders had more students, not just more babies. The cognitive gadgets hypothesis is developed through four case studies, drawing on evidence from comparative and developmental psychology, experimental psychology and cognitive neuroscience. The framework employed, cultural evolutionary psychology, a descendant of evolutionary psychology and cultural evolutionary theory, addresses parallel issues across the cognitive and behavioural sciences. In common with evo-devo and the extended evolutionary synthesis, cultural evolutionary psychology underlines the importance of developmental processes and environmental factors in the emergence of human cognition. In common with computational approaches (deep learning, predictive coding, hierarchical reinforcement learning, causal modelling) it emphasises the power of general-purpose mechanisms of learning. However, cultural evolutionary psychology also challenges use of the behavioural gambit in economics and behavioral ecology, and rejects the view that human minds are composed of 'innate modules' or 'cognitive instincts'.},
author = {Heyes, Cecilia},
doi = {10.1017/S0140525X18002145},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Heyes - 2018 - Pr{\'{e}}cis of Cognitive Gadgets The Cultural Evolution of Thinking.pdf:pdf},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
keywords = {cultural evolution,domain-specific/domain-general,evolutionary psychology,innateness,social construction,teleosemantics},
title = {{Pr{\'{e}}cis of Cognitive Gadgets: The Cultural Evolution of Thinking}},
volume = {42},
year = {2018}
}
@article{Blass2018,
abstract = {A signed probability distribution may extend a given traditional probability from observable events to all events. We formalize and illustrate this approach. We also illustrate its limitation. We argue that the right question is not what negative probabilities are but what they are for.},
archivePrefix = {arXiv},
arxivId = {2009.10552},
author = {Blass, Andreas and Gurevich, Yuri},
eprint = {2009.10552},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Blass, Gurevich - 2018 - Negative probabilities, II what they are and what they are for.pdf:pdf},
journal = {arXiv},
pages = {1--24},
title = {{Negative probabilities, II what they are and what they are for}},
year = {2018}
}
@article{Li2018,
abstract = {Neural network training relies on our ability to find “good” minimizers of highly non-convex loss functions. It is well-known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and well-chosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effect on the underlying loss landscape, are not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple “filter normalization” method that helps us visualize loss function curvature and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.},
archivePrefix = {arXiv},
arxivId = {1712.09913},
author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
eprint = {1712.09913},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2018 - Visualizing the loss landscape of neural nets.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips 2018},
pages = {6389--6399},
title = {{Visualizing the loss landscape of neural nets}},
volume = {2018-Decem},
year = {2018}
}
@article{Ma2019,
abstract = {Many real-life decision making situations allow further relevant information to be acquired at a specific cost, for example, in assessing the health status of a patient we may decide to take additional measurements such as diagnostic tests or imaging scans before making a final assessment. Acquiring more relevant information enables better decision making, but may be costly. How can we trade off the desire to make good decisions by acquiring further information with the cost of performing that acquisition? To this end, we propose a principled framework, named EDDI (Efficient Dynamic Discovery of high-value Information), based on the theory of Bayesian experimental design. In KDDI, we propose a novel partial variational autoencoder (Partial VAE) to predict missing data entries problematically given any subset of the observed ones, and combine it with an acquisition function that maximizes expected information gain on a set of target variables. We show cost reduction at the same decision quality and improved decision quality at the same cost in multiple machine learning benchmarks and two real-world health-care applications.},
archivePrefix = {arXiv},
arxivId = {1809.11142},
author = {Ma, Chao and Tschiatschek, Sebastian and Palla, Konstantina and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel and Nowozin, Sebastian and Zhang, Cheng},
eprint = {1809.11142},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2019 - EdDI Efficient dynamic discovery of high-value information with partial VAE.pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
pages = {7483--7504},
title = {{EdDI: Efficient dynamic discovery of high-value information with partial VAE}},
volume = {2019-June},
year = {2019}
}
@article{Zhang2020a,
abstract = {We present a causal view on the robustness of neural networks against input manipulations, which applies not only to traditional classification tasks but also to general measurement data. Based on this view, we design a deep causal manipulation augmented model (deep CAMA) which explicitly models possible manipulations on certain causes leading to changes in the observed effect. We further develop data augmentation and test-time fine-tuning methods to improve deep CAMA's robustness. When compared with discriminative deep neural networks, our proposed model shows superior robustness against unseen manipulations. As a by-product, our model achieves disentangled representation which separates the representation of manipulations from those of other latent causes.},
archivePrefix = {arXiv},
arxivId = {2005.01095},
author = {Zhang, Cheng and Zhang, Kun and Li, Yingzhen},
eprint = {2005.01095},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhang, Li - 2020 - A Causal View on Robustness of Neural Networks.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--21},
title = {{A Causal View on Robustness of Neural Networks}},
year = {2020}
}
@article{Gong2019,
abstract = {In this paper we introduce the ice-start problem, i.e., the challenge of deploying machine learning models when only little or no training data is initially available, and acquiring each feature element of data is associated with costs. This setting is representative for the real-world machine learning applications. For instance, in the health-care domain, when training an AI system for predicting patient metrics from lab tests, obtaining every single measurement comes with a high cost. Active learning, where only the label is associated with a cost does not apply to such problem, because performing all possible lab tests to acquire a new training datum would be costly, as well as unnecessary due to redundancy. We propose Icebreaker, a principled framework to approach the ice-start problem. Icebreaker uses a full Bayesian Deep Latent Gaussian Model (BELGAM) with a novel inference method. Our proposed method combines recent advances in amortized inference and stochastic gradient MCMC to enable fast and accurate posterior inference. By utilizing BELGAM's ability to fully quantify model uncertainty, we also propose two information acquisition functions for imputation and active prediction problems. We demonstrate that BELGAM performs significantly better than the previous VAE (Variational autoencoder) based models, when the data set size is small, using both machine learning benchmarks and real-world recommender systems and health-care applications. Moreover, based on BELGAM, Icebreaker further improves the performance and demonstrate the ability to use minimum amount of the training data to obtain the highest test time performance.},
archivePrefix = {arXiv},
arxivId = {1908.04537},
author = {Gong, Wenbo and Tschiatschek, Sebastian and Turner, Richard and Nowozin, Sebastian and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel and Zhang, Cheng},
eprint = {1908.04537},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gong et al. - 2019 - Icebreaker Element-wise active information acquisition with bayesian deep latent gaussian model.pdf:pdf},
journal = {arXiv},
title = {{Icebreaker: Element-wise active information acquisition with bayesian deep latent gaussian model}},
year = {2019}
}
@article{Gershman2019,
abstract = {The free energy principle has been proposed as a unifying account of brain function. It is closely related, and in some cases subsumes, earlier unifying ideas such as Bayesian inference, predictive coding, and active learning. This article clarifies these connections, teasing apart distinctive and shared predictions.},
archivePrefix = {arXiv},
arxivId = {1901.07945},
author = {Gershman, Samuel J.},
eprint = {1901.07945},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gershman - 2019 - What does the free energy principle tell us about the brain.pdf:pdf},
journal = {arXiv},
keywords = {Bayesian brain,Decision theory,Predictive coding,Variational inference},
pages = {1--10},
title = {{What does the free energy principle tell us about the brain?}},
year = {2019}
}
@article{Li2016,
abstract = {This short paper extends the free-energy derivations of variational inference, loopy belief propagation and expectation propagation (EP) to a wider range of approximate inference methods including power EP, distributed EP, and black-box alpha-divergence minimisation. The framework provides a very flexible framework for the design of variational algorithms that can mix versions of any of the aforemen-tioned algorithms inside a single coherent algorithm. The framework is general, extending to latent variable models, for example.},
author = {Li, Yingzhen and Turner, Richard E},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Turner - 2016 - A Unifying Approximate Inference Framework from Variational Free Energy Relaxation.pdf:pdf},
pages = {1--11},
title = {{A Unifying Approximate Inference Framework from Variational Free Energy Relaxation}},
year = {2016}
}
@article{Look2020,
abstract = {In this paper, we introduce an efficient backpropagation scheme for non-constrained implicit functions. These functions are parametrized by a set of learnable weights and may optionally depend on some input; making them perfectly suitable as learnable layer in a neural network. We demonstrate our scheme on different applications: (i) neural ODEs with the implicit Euler method, and (ii) system identification in model predictive control.},
archivePrefix = {arXiv},
arxivId = {2010.07078},
author = {Look, Andreas and Doneva, Simona and Kandemir, Melih and Gemulla, Rainer and Peters, Jan},
eprint = {2010.07078},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Look et al. - 2020 - Differentiable Implicit Layers.pdf:pdf},
pages = {1--12},
title = {{Differentiable Implicit Layers}},
url = {http://arxiv.org/abs/2010.07078},
year = {2020}
}
@article{Jahrens2019,
abstract = {Relational Networks (RN) as introduced by Santoro et al. in 2017 have demonstrated strong relational reasoning capabilities with a rather shallow architecture. Its single-layer design, however, only considers pairs of information objects, making it unsuitable for problems requiring reasoning across a higher number of facts. To overcome this limitation, we propose a multi-layer relation network architecture which enables successive refinements of relational information through multiple layers. We show that the increased depth allows for more complex relational reasoning by applying it to the bAbI 20 QA dataset, solving all 20 tasks with joint training and surpassing the state-of-the-art results.},
author = {Jahrens, Marius and Martinetz, Thomas},
doi = {10.1145/3309772.3309782},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jahrens, Martinetz - 2019 - Multi-layer Relation Networks for relational reasoning.pdf:pdf},
isbn = {9781450360852},
journal = {ACM International Conference Proceeding Series},
title = {{Multi-layer Relation Networks for relational reasoning}},
year = {2019}
}
@article{Zhang2020,
abstract = {One of the common ways children learn is by mimicking adults. Imitation learning focuses on learning policies with suitable performance from demonstrations generated by an expert, with an unspecified performance measure, and unobserved reward signal. Popular methods for imitation learning start by either directly mimicking the behavior policy of an expert (behavior cloning) or by learning a reward function that prioritizes observed expert trajectories (inverse reinforcement learning). However, these methods rely on the assumption that covariates used by the expert to determine her/his actions are fully observed. In this paper, we relax this assumption and study imitation learning when sensory inputs of the learner and the expert differ. First, we provide a non-parametric, graphical criterion that is complete (both necessary and sufficient) for determining the feasibility of imitation from the combinations of demonstration data and qualitative assumptions about the underlying environment, represented in the form of a causal model. We then show that when such a criterion does not hold, imitation could still be feasible by exploiting quantitative knowledge of the expert trajectories. Finally, we develop an efficient procedure for learning the imitating policy from experts' trajectories.},
author = {Zhang, Junzhe and Kumor, Daniel and Bareinboim, Elias},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Kumor, Bareinboim - 2020 - Causal Imitation Learning with Unobserved Confounders.pdf:pdf},
journal = {NeurIPS 34th},
number = {NeurIPS},
pages = {1--12},
title = {{Causal Imitation Learning with Unobserved Confounders}},
volume = {33},
year = {2020}
}
@article{Zheng2019,
abstract = {Abstraction reasoning is a long-standing challenge in artificial intelligence. Recent studies suggest that many of the deep architectures that have triumphed over other domains failed to work well in abstract reasoning. In this paper, we first illustrate that one of the main challenges in such a reasoning task is the presence of distracting features, which requires the learning algorithm to leverage counter-evidence and to reject any of the false hypotheses in order to learn the true patterns. We later show that carefully designed learning trajectory over different categories of training data can effectively boost learning performance by mitigating the im-pacts of distracting features. Inspired by this fact, we propose feature robust ab-stract reasoning (FRAR) model, which consists of a reinforcement learning based teacher network to determine the sequence of training and a student network for predictions. Experimental results demonstrated strong improvements over baseline algorithms and we are able to beat the state-of-the-art models by 18.7{\%} in the RAVEN dataset and 13.3{\%} in the PGM dataset.},
archivePrefix = {arXiv},
arxivId = {1912.00569},
author = {Zheng, Kecheng and Zha, Zheng Jun and Wei, Wei},
eprint = {1912.00569},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zheng, Zha, Wei - 2019 - Abstract reasoning with distracting features.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--12},
title = {{Abstract reasoning with distracting features}},
year = {2019}
}
@article{Hofstadter1994,
abstract = {describe Copycat, a nondeterministic model of analogy making aiming at psychological realism / the authors maintain that the hybrid middle ground in cognitive modeling occupied by Copycat is, at present, the most useful level at which to attempt to understand the fluidity of concepts and perception that is so clearly apparent in human analogy making / argue that nondeterminism is necessary for flexible cognition, and claim that their architecture, being essentially a model of fluid concepts and mental pressures, has validity beyond analogy making (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
author = {Hofstadter, Douglas and Mitchell, Melanie},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hofstadter, Mitchell - 1994 - The copycat project A model of mental fluidity and analogy-making.pdf:pdf},
journal = {Advances in connectionist and neural computation theory},
number = {31-112},
pages = {29--30},
title = {{The copycat project: A model of mental fluidity and analogy-making}},
volume = {2},
year = {1994}
}
@article{Authors2001,
archivePrefix = {arXiv},
arxivId = {1807.04225},
author = {Authors, Anonymous},
eprint = {1807.04225},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Authors - 2001 - David G.T. Barrett.pdf:pdf},
issn = {1938-7228},
number = {Icml},
title = {{David G.T. Barrett}},
year = {2001}
}
@article{Barrett2018,
abstract = {Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation 'regimes' in which the training and test data differ in clearlydefined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with a structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model's ability to generalise improves markedly if it is trained to predict symbolic explanations for its answers. Altogether, we introduce and explore ways to both measure and induce stronger abstract reasoning in neural networks. Our freely-available dataset should motivate further progress in this direction.},
archivePrefix = {arXiv},
arxivId = {1807.04225},
author = {Barrett, David G.T. and Hill, Felix and Santoro, Adam and Morcos, Ari S. and Lillicrap, Timothy},
eprint = {1807.04225},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrett et al. - 2018 - Measuring abstract reasoning in neural networks.pdf:pdf},
isbn = {9781510867963},
journal = {35th International Conference on Machine Learning, ICML 2018},
pages = {7118--7127},
title = {{Measuring abstract reasoning in neural networks}},
volume = {10},
year = {2018}
}
@article{Steenbrugge2018,
abstract = {In this work we explore the generalization characteristics of unsupervised representation learning by leveraging disentangled VAE's to learn a useful latent space on a set of relational reasoning problems derived from Raven Progressive Matrices. We show that the latent representations, learned by unsupervised training using the right objective function, significantly outperform the same architectures trained with purely supervised learning, especially when it comes to generalization.},
archivePrefix = {arXiv},
arxivId = {1811.04784},
author = {Steenbrugge, Xander and Leroux, Sam and Verbelen, Tim and Dhoedt, Bart},
eprint = {1811.04784},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steenbrugge et al. - 2018 - Improving generalization for abstract reasoning tasks using disentangled feature representations.pdf:pdf},
journal = {arXiv},
number = {Nips 2018},
pages = {1--8},
title = {{Improving generalization for abstract reasoning tasks using disentangled feature representations}},
year = {2018}
}
@article{Lee2019,
abstract = {We design and conduct a simple experiment to study whether neural networks can perform several steps of approximate reasoning in a fixed dimensional latent space. The set of rewrites (i.e. transformations) that can be successfully performed on a statement represents essential semantic features of the statement. We can compress this information by embedding the formula in a vector space, such that the vector associated with a statement can be used to predict whether a statement can be rewritten by other theorems. Predicting the embedding of a formula generated by some rewrite rule is naturally viewed as approximate reasoning in the latent space. In order to measure the effectiveness of this reasoning, we perform approximate deduction sequences in the latent space and use the resulting embedding to inform the semantic features of the corresponding formal statement (which is obtained by performing the corresponding rewrite sequence using real formulas). Our experiments show that graph neural networks can make non-trivial predictions about the rewrite-success of statements, even when they propagate predicted latent representations for several steps. Since our corpus of mathematical formulas includes a wide variety of mathematical disciplines, this experiment is a strong indicator for the feasibility of deduction in latent space in general.},
archivePrefix = {arXiv},
arxivId = {1909.11851},
author = {Lee, Dennis and Szegedy, Christian and Rabe, Markus N. and Loos, Sarah M. and Bansal, Kshitij},
eprint = {1909.11851},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2019 - Mathematical reasoning in latent space.pdf:pdf},
journal = {arXiv},
pages = {1--10},
title = {{Mathematical reasoning in latent space}},
year = {2019}
}
@article{Chollet2019,
abstract = {To make deliberate progress towards more intelligent and more human-like artificial systems, we need to be following an appropriate feedback signal: we need to be able to define and evaluate intelligence in a way that enables comparisons between two systems, as well as comparisons with humans. Over the past hundred years, there has been an abundance of attempts to define and measure intelligence, across both the fields of psychology and AI. We summarize and critically assess these definitions and evaluation approaches, while making apparent the two historical conceptions of intelligence that have implicitly guided them. We note that in practice, the contemporary AI community still gravitates towards benchmarking intelligence by comparing the skill exhibited by AIs and humans at specific tasks, such as board games and video games. We argue that solely measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience: unlimited priors or unlimited training data allow experimenters to “buy” arbitrary levels of skills for a system, in a way that masks the system's own generalization power. We then articulate a new formal definition of intelligence based on Algorithmic Information Theory, describing intelligence as skill-acquisition efficiency and highlighting the concepts of scope, generalization difficulty, priors, and experience, as critical pieces to be accounted for in characterizing intelligent systems. Using this definition, we propose a set of guidelines for what a general AI benchmark should look like. Finally, we present a new benchmark closely following these guidelines, the Abstraction and Reasoning Corpus (ARC), built upon an explicit set of priors designed to be as close as possible to innate human priors. We argue that ARC can be used to measure a human-like form of general fluid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.},
archivePrefix = {arXiv},
arxivId = {1911.01547},
author = {Chollet, Fran{\c{c}}ois},
eprint = {1911.01547},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chollet - 2019 - On the Measure of Intelligence.pdf:pdf},
journal = {arXiv},
pages = {1--64},
title = {{On the Measure of Intelligence}},
year = {2019}
}
@article{Maddison2017,
abstract = {The reparameterization trick enables optimizing large scale stochastic computation graphs via gradient descent. The essence of the trick is to refactor each stochastic node into a differentiable function of its parameters and a random variable with fixed distribution. After refactoring, the gradients of the loss propagated by the chain rule through the graph are low variance unbiased estimators of the gradients of the expected loss. While many continuous random variables have such reparameterizations, discrete random variables lack useful reparameterizations due to the discontinuous nature of discrete states. In this work we introduce CONCRETE random variables-CONtinuous relaxations of disCRETE random variables. The Concrete distribution is a new family of distributions with closed form densities and a simple reparameterization. Whenever a discrete stochastic node of a computation graph can be refactored into a one-hot bit representation that is treated continuously, Concrete stochastic nodes can be used with automatic differentiation to produce low-variance biased gradients of objectives (including objectives that depend on the log-probability of latent stochastic nodes) on the corresponding discrete graph. We demonstrate the effectiveness of Concrete relaxations on density estimation and structured prediction tasks using neural networks.},
archivePrefix = {arXiv},
arxivId = {1611.00712},
author = {Maddison, Chris J. and Mnih, Andriy and Teh, Yee Whye},
eprint = {1611.00712},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Maddison, Mnih, Teh - 2017 - The concrete distribution A continuous relaxation of discrete random variables.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
pages = {1--20},
title = {{The concrete distribution: A continuous relaxation of discrete random variables}},
year = {2017}
}
@article{VanDenOord2018,
abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
archivePrefix = {arXiv},
arxivId = {1807.03748},
author = {{Van Den Oord}, Aaron and Li, Yazhe and Vinyals, Oriol},
eprint = {1807.03748},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Den Oord, Li, Vinyals - 2018 - Representation learning with contrastive predictive coding.pdf:pdf},
journal = {arXiv},
title = {{Representation learning with contrastive predictive coding}},
year = {2018}
}
@article{Gilmer2017,
abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
archivePrefix = {arXiv},
arxivId = {1704.01212},
author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
eprint = {1704.01212},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilmer et al. - 2017 - Neural message passing for quantum chemistry.pdf:pdf},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
pages = {2053--2070},
title = {{Neural message passing for quantum chemistry}},
volume = {3},
year = {2017}
}
@article{Feinman2020,
abstract = {Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.},
archivePrefix = {arXiv},
arxivId = {2003.08978},
author = {Feinman, Reuben and Lake, Brenden M.},
eprint = {2003.08978},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Feinman, Lake - 2020 - Generating new concepts with hybrid neuro-symbolic models.pdf:pdf},
journal = {arXiv},
keywords = {Causality,Compositionality,Generative models,Neural networks},
title = {{Generating new concepts with hybrid neuro-symbolic models}},
year = {2020}
}
@article{Velickovic2020,
abstract = {Graph neural networks (GNNs) are typically applied to static graphs that are assumed to be known upfront. This static input structure is often informed purely by insight of the machine learning practitioner, and might not be optimal for the actual task the GNN is solving. In absence of reliable domain expertise, one might resort to inferring the latent graph structure, which is often difficult due to the vast search space of possible graphs. Here we introduce Pointer Graph Networks (PGNs) which augment sets or graphs with additional inferred edges for improved model expressivity. PGNs allow each node to dynamically point to another node, followed by message passing over these pointers. The sparsity of this adaptable graph structure makes learning tractable while still being sufficiently expressive to simulate complex algorithms. Critically, the pointing mechanism is directly supervised to model long-term sequences of operations on classical data structures, incorporating useful structural inductive biases from theoretical computer science. Qualitatively, we demonstrate that PGNs can learn parallelisable variants of pointer-based data structures, namely disjoint set unions and link/cut trees. PGNs generalise out-of-distribution to 5× larger test inputs on dynamic graph connectivity tasks, outperforming unrestricted GNNs and Deep Sets.},
archivePrefix = {arXiv},
arxivId = {2006.06380},
author = {Veli{\v{c}}kovi{\'{c}}, Petar and Buesing, Lars and Overlan, Matthew C. and Pascanu, Razvan and Vinyals, Oriol and Blundell, Charles},
eprint = {2006.06380},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Veli{\v{c}}kovi{\'{c}} et al. - 2020 - Pointer Graph Networks.pdf:pdf},
journal = {arXiv},
title = {{Pointer Graph Networks}},
year = {2020}
}
@article{Paulus2020,
abstract = {The Gumbel-Max trick is the basis of many relaxed gradient estimators. These estimators are easy to implement and low variance, but the goal of scaling them comprehensively to large combinatorial distributions is still outstanding. Working within the perturbation model framework, we introduce stochastic softmax tricks, which generalize the Gumbel-Softmax trick to combinatorial spaces. Our framework is a unified perspective on existing relaxed estimators for perturbation models, and it contains many novel relaxations. We design structured relaxations for subset selection, spanning trees, arborescences, and others. When compared to less structured baselines, we find that stochastic softmax tricks can be used to train latent variable models that perform better and discover more latent structure.},
archivePrefix = {arXiv},
arxivId = {2006.08063},
author = {Paulus, Max B. and Choi, Dami and Tarlow, Daniel and Krause, Andreas and Maddison, Chris J.},
eprint = {2006.08063},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulus et al. - 2020 - Gradient Estimation with Stochastic Softmax Tricks.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Gradient Estimation with Stochastic Softmax Tricks}},
year = {2020}
}
@article{Maron2020,
abstract = {Learning from unordered sets is a fundamental learning setup, which is attracting increasing attention. Research in this area has focused on the case where elements of the set are represented by feature vectors, and far less emphasis has been given to the common case where set elements themselves adhere to certain symmetries. That case is relevant to numerous applications, from deblurring image bursts to multi-view 3D shape recognition and reconstruction. In this paper, we present a principled approach to learning sets of general symmetric elements. We first characterize the space of linear layers that are equivariant both to element reordering and to the inherent symmetries of elements, like translation in the case of images. We further show that networks that are composed of these layers, called Deep Sets for Symmetric elements layers (DSS), are universal approximators of both invariant and equivariant functions. DSS layers are also straightforward to implement. Finally, we show that they improve over existing set-learning architectures in a series of experiments with images, graphs and point-clouds.},
archivePrefix = {arXiv},
arxivId = {2002.08599},
author = {Maron, Haggai and Litany, Or and Chechik, Gal and Fetaya, Ethan},
eprint = {2002.08599},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Maron et al. - 2020 - On learning sets of symmetric elements.pdf:pdf},
journal = {arXiv},
title = {{On learning sets of symmetric elements}},
year = {2020}
}
@article{Bai2020,
abstract = {We propose a new class of implicit networks, the multiscale deep equilibrium model (MDEQ), suited to large-scale and highly hierarchical pattern recognition domains. An MDEQ directly solves for and backpropagates through the equilibrium points of multiple feature resolutions simultaneously, using implicit differentiation to avoid storing intermediate states (and thus requiring only O(1) memory consumption). These simultaneously-learned multi-resolution features allow us to train a single model on a diverse set of tasks and loss functions, such as using a single MDEQ to perform both image classification and semantic segmentation. We illustrate the effectiveness of this approach on two large-scale vision tasks: ImageNet classification and semantic segmentation on high-resolution images from the Cityscapes dataset. In both settings, MDEQs are able to match or exceed the performance of recent competitive computer vision models: the first time such performance and scale have been achieved by an implicit deep learning approach. The code and pre-trained models are at https://github.com/locuslab/mdeq.},
archivePrefix = {arXiv},
arxivId = {2006.08656},
author = {Bai, Shaojie and Koltun, Vladlen and Kolter, J. Zico},
eprint = {2006.08656},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai, Koltun, Kolter - 2020 - Multiscale deep equilibrium models.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Multiscale deep equilibrium models}},
year = {2020}
}
@article{Hahne2019,
abstract = {Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction. However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35{\%} of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.},
archivePrefix = {arXiv},
arxivId = {1911.05990},
author = {Hahne, Lukas and L{\"{u}}ddecke, Timo and W{\"{o}}rg{\"{o}}tter, Florentin and Kappel, David},
eprint = {1911.05990},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hahne et al. - 2019 - Attention on abstract visual reasoning.pdf:pdf},
journal = {arXiv},
pages = {1--15},
title = {{Attention on abstract visual reasoning}},
year = {2019}
}
@article{Hu2020,
abstract = {reasoning refers to the ability to analyze information, discover rules at an intangible level, and solve problems in innovative ways. Raven's Progressive Matrices (RPM) test is typically used to examine the capability of abstract reasoning. In the test, the subject is asked to identify the correct choice from the answer set to fill the missing panel at the bottom right of RPM (e.g., a 3×3 matrix), following the underlying rules inside the matrix. Recent studies, taking advantage of Convolutional Neural Networks (CNNs), have achieved encouraging progress to accomplish the RPM test problems. Unfortunately, simply relying on the relation extraction at the matrix level, they fail to recognize the complex attribute patterns inside or across rows/columns of RPM. To address this problem, in this paper we propose a Hierarchical Rule Induction Network (HriNet), by intimating human induction strategies. HriNet extracts multiple granularity rule embeddings at different levels and integrates them through a gated embedding fusion module. We further introduce a rule similarity metric based on the embeddings, so that HriNet can not only be trained using a tuplet loss but also infer the best answer according to the similarity score. To comprehensively evaluate HriNet, we first fix the defects contained in the very recent RAVEN dataset and generate a new one named Balanced-RAVEN. Then extensive experiments are conducted on the large-scale dataset PGM and our Balanced-RAVEN, the results of which show that HriNet outperforms the state-of-the-art models by a large margin.},
archivePrefix = {arXiv},
arxivId = {2002.06838},
author = {Hu, Sheng and Ma, Yuqing and Liu, Xianglong and Wei, Yanlu and Bai, Shihao},
eprint = {2002.06838},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2020 - Hierarchical rule induction network for abstract visual reasoning.pdf:pdf},
journal = {arXiv},
title = {{Hierarchical rule induction network for abstract visual reasoning}},
year = {2020}
}
@article{Zhang2019,
abstract = {“Thinking in pictures,” [1] i.e., spatial-temporal reasoning, effortless and instantaneous for humans, is believed to be a significant ability to perform logical induction and a crucial factor in the intellectual history of technology development. Modern Artificial Intelligence (AI), fueled by massive datasets, deeper models, and mighty computation, has come to a stage where (super-)human-level performances are observed in certain specific tasks. However, current AI's ability in “thinking in pictures” is still far lacking behind. In this work, we study how to improve machines' reasoning ability on one challenging task of this kind: Raven's Progressive Matrices (RPM). Specifically, we borrow the very idea of “contrast effects” from the field of psychology, cognition, and education to design and train a permutation-invariant model. Inspired by cognitive studies, we equip our model with a simple inference module that is jointly trained with the perception backbone. Combining all the elements, we propose the Contrastive Perceptual Inference network (CoPINet) and empirically demonstrate that CoPINet sets the new state-of-the-art for permutation-invariant models on two major datasets. We conclude that spatial-temporal reasoning depends on envisaging the possibilities consistent with the relations between objects and can be solved from pixel-level inputs.},
archivePrefix = {arXiv},
arxivId = {1912.00086},
author = {Zhang, Chi and Jia, Baoxiong and Gao, Feng and Zhu, Yixin and Lu, Hongjing and Zhu, Song Chun},
eprint = {1912.00086},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Learning perceptual inference by contrasting.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--13},
title = {{Learning perceptual inference by contrasting}},
year = {2019}
}
@article{Lample2019,
abstract = {Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.},
archivePrefix = {arXiv},
arxivId = {1912.01412},
author = {Lample, Guillaume and Charton, Fran{\c{c}}ois},
eprint = {1912.01412},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lample, Charton - 2019 - Deep Learning for Symbolic Mathematics.pdf:pdf},
journal = {arXiv},
pages = {1--24},
title = {{Deep Learning for Symbolic Mathematics}},
year = {2019}
}
@article{Luneau2020,
abstract = {We consider generalized linear models in regimes where the number of nonzero components of the signal and accessible data points are sublinear with respect to the size of the signal. We prove a variational formula for the asymptotic mutual information per sample when the system size grows to infinity. This result allows us to heuristically derive an expression for the minimum mean-square error (MMSE) of the Bayesian estimator. We then find that, for discrete signals and suitable vanishing scalings of the sparsity and sampling rate, the MMSE displays an all-or-nothing phenomenon, namely, the MMSE sharply jumps from its maximum value to zero at a critical sampling rate. The all-or-nothing phenomenon has recently been proved to occur in high-dimensional linear regression. Our analysis goes beyond the linear case and applies to learning the weights of a perceptron with general activation function in a teacher-student scenario. In particular we discuss an all-or-nothing phenomenon for the generalization error with a sublinear set of training examples.},
archivePrefix = {arXiv},
arxivId = {2006.11313},
author = {Luneau, Cl{\'{e}}ment and Macris, Nicolas and Barbier, Jean},
eprint = {2006.11313},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Luneau, Macris, Barbier - 2020 - Information theoretic limits of learning a sparse rule.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Information theoretic limits of learning a sparse rule}},
year = {2020}
}
@article{Xie2020,
abstract = {Causal discovery aims to recover causal structures or models underlying the observed data. Despite its success in certain domains, most existing methods focus on causal relations between observed variables, while in many scenarios the observed ones may not be the underlying causal variables (e.g., image pixels), but are generated by latent causal variables or confounders that are causally related. To this end, in this paper, we consider Linear, Non-Gaussian Latent variable Models (LiNGLaMs), in which latent confounders are also causally related, and propose a Generalized Independent Noise (GIN) condition to estimate such latent variable graphs. Specifically, for two observed random vectors {\$}\backslashmathbf{\{}Y{\}}{\$} and {\$}\backslashmathbf{\{}Z{\}}{\$}, GIN holds if and only if {\$}\backslashomega{\^{}}{\{}\backslashintercal{\}}\backslashmathbf{\{}Y{\}}{\$} and {\$}\backslashmathbf{\{}Z{\}}{\$} are statistically independent, where {\$}\backslashomega{\$} is a parameter vector characterized from the cross-covariance between {\$}\backslashmathbf{\{}Y{\}}{\$} and {\$}\backslashmathbf{\{}Z{\}}{\$}. From the graphical view, roughly speaking, GIN implies that causally earlier latent common causes of variables in {\$}\backslashmathbf{\{}Y{\}}{\$} d-separate {\$}\backslashmathbf{\{}Y{\}}{\$} from {\$}\backslashmathbf{\{}Z{\}}{\$}. Interestingly, we find that the independent noise condition, i.e., if there is no confounder, causes are independent from the error of regressing the effect on the causes, can be seen as a special case of GIN. Moreover, we show that GIN helps locate latent variables and identify their causal structure, including causal directions. We further develop a recursive learning algorithm to achieve these goals. Experimental results on synthetic and real-world data demonstrate the effectiveness of our method.},
archivePrefix = {arXiv},
arxivId = {2010.04917},
author = {Xie, Feng and Cai, Ruichu and Huang, Biwei and Glymour, Clark and Hao, Zhifeng and Zhang, Kun},
eprint = {2010.04917},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2020 - Generalized Independent Noise Condition for Estimating Latent Variable Causal Graphs.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Generalized Independent Noise Condition for Estimating Latent Variable Causal Graphs}},
url = {http://arxiv.org/abs/2010.04917},
volume = {4},
year = {2020}
}
@article{Dong2020,
abstract = {Training models with discrete latent variables is challenging due to the difficulty of estimating the gradients accurately. Much of the recent progress has been achieved by taking advantage of continuous relaxations of the system, which are not always available or even possible. The Augment-REINFORCE-Merge (ARM) estimator provides an alternative that, instead of relaxation, uses continuous augmentation. Applying antithetic sampling over the augmenting variables yields a relatively low-variance and unbiased estimator applicable to any model with binary latent variables. However, while antithetic sampling reduces variance, the augmentation process increases variance. We show that ARM can be improved by analytically integrating out the randomness introduced by the augmentation process, guaranteeing substantial variance reduction. Our estimator, DisARM, is simple to implement and has the same computational cost as ARM. We evaluate DisARM on several generative modeling benchmarks and show that it consistently outperforms ARM and a strong independent sample baseline in terms of both variance and log-likelihood. Furthermore, we propose a local version of DisARM designed for optimizing the multi-sample variational bound, and show that it outperforms VIMCO, the current state-of-the-art method.},
archivePrefix = {arXiv},
arxivId = {2006.10680},
author = {Dong, Zhe and Mnih, Andriy and Tucker, George},
eprint = {2006.10680},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong, Mnih, Tucker - 2020 - Disarm an antithetic gradient estimator for binary latent variables.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Disarm: an antithetic gradient estimator for binary latent variables}},
year = {2020}
}
@article{Johnson2016,
abstract = {We propose a general modeling and inference framework that combines the complementary strengths of probabilistic graphical models and deep learning methods. Our model family composes latent graphical models with neural network observation likelihoods. For inference, we use recognition networks to produce local evidence potentials, then combine them with the model distribution using efficient message-passing algorithms. All components are trained simultaneously with a single stochastic variational inference objective. We illustrate this framework by automatically segmenting and categorizing mouse behavior from raw depth video, and demonstrate several other example models.},
archivePrefix = {arXiv},
arxivId = {1603.06277},
author = {Johnson, Matthew James and Duvenaud, David and Wiltschko, Alexander B. and Datta, Sandeep R. and Adams, Ryan P.},
eprint = {1603.06277},
file = {:C$\backslash$:/Users/serge/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson et al. - 2016 - Composing graphical models with neural networks for structured representations and fast inference.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {graphical models, variational autoencoders, variat},
pages = {2954--2962},
title = {{Composing graphical models with neural networks for structured representations and fast inference}},
year = {2016}
}
@article{Sorscher2020,
author = {Sorscher, Ben and Mel, Gabriel C. and Ocko, Samuel A. and Giocomo, Lisa and Ganguli, Surya},
file = {:C$\backslash$:/Users/serge/Desktop/2020.12.29.424583v1.full.pdf:pdf},
journal = {bioRxiv},
title = {{A unified theory for the computational and mechanistic origins of grid cells}},
url = {https://www.biorxiv.org/content/10.1101/2020.12.29.424583v1},
year = {2020}
}
@article{Battaglia2018,
abstract = {Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences—a hallmark of human intelligence from infancy—remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between “hand-engineering” and “end-to-end” learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias—the graph network—which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have also released an open-source software library for building graph networks, with demonstrations of how to use them in practice.},
archivePrefix = {arXiv},
arxivId = {1806.01261},
author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
eprint = {1806.01261},
file = {:C$\backslash$:/Users/serge/Desktop/1806.01261.pdf:pdf},
journal = {arXiv},
pages = {1--40},
title = {{Relational inductive biases, deep learning, and graph networks}},
year = {2018}
}
@article{Cranmer2020,
abstract = {We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We find the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example—a detailed dark matter simulation—and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distribution-data better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.},
archivePrefix = {arXiv},
arxivId = {2006.11287},
author = {Cranmer, Miles and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
eprint = {2006.11287},
file = {:C$\backslash$:/Users/serge/Desktop/2006.11287.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--25},
title = {{Discovering symbolic models from deep learning with inductive biases}},
year = {2020}
}
@article{Battaglia2016,
abstract = {Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains.},
archivePrefix = {arXiv},
arxivId = {1612.00222},
author = {Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo and Kavukcuoglu, Koray},
eprint = {1612.00222},
file = {:C$\backslash$:/Users/serge/Desktop/1612.00222.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {4509--4517},
title = {{Interaction networks for learning about objects, relations and physics}},
year = {2016}
}
