@article{Kipf2020,
abstract = {A structured understanding of our world in terms of objects, relations, and hierarchies is an important component of human cognition. Learning such a structured world model from raw sensory data remains a challenge. As a step towards this goal, we introduce Contrastively-trained Structured World Models (C-SWMs). C-SWMs utilize a contrastive approach for representation learning in environments with compositional structure. We structure each state embedding as a set of object representations and their relations, modeled by a graph neural network. This allows objects to be discovered from raw pixel observations without direct supervision as part of the learning process. We evaluate C-SWMs on compositional environments involving multiple interacting objects that can be manipulated independently by an agent, simple Atari games, and a multi-object physics simulation. Our experiments demonstrate that C-SWMs can overcome limitations of models based on pixel reconstruction and outperform typical representatives of this model class in highly structured environments, while learning interpretable object-based representations.},
annote = {From Duplicate 1 (CONTRASTIVE LEARNING OF STRUCTURED WORLD MODELS - Kipf, Thomas; Van Der Pol, Elise; Welling, Max)

use the environments from the paper and compare to their learned model in terms of accuracy and sparsity},
archivePrefix = {arXiv},
arxivId = {1911.12247},
author = {Kipf, Thomas and Pol, Elise Van Der and Welling, Max and {Van Der Pol}, Elise and Welling, Max},
eprint = {1911.12247},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kipf, Pol, Welling - 2019 - Contrastive learning of structured world models.pdf:pdf;:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kipf, Van Der Pol, Welling - Unknown - CONTRASTIVE LEARNING OF STRUCTURED WORLD MODELS.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--21},
title = {{Contrastive learning of structured world models}},
year = {2019}
}
@article{Hamming1980,
abstract = {It is evident from the title that this is a philosophical discussion. I shall not apologize for the philosophy, though I am well aware that most scientists, engineers, and mathematicians have little regard for it; instead, I shall give this short prologue to justify the approach.},
author = {Hamming, R. W.},
doi = {10.2307/2321982},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamming - 1980 - The Unreasonable Effectiveness of Mathematics.pdf:pdf},
issn = {00029890},
journal = {The American Mathematical Monthly},
number = {2},
pages = {81},
title = {{The Unreasonable Effectiveness of Mathematics}},
volume = {87},
year = {1980}
}
@article{Mao2019,
abstract = {We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neuro-symbolic reasoning module that executes these programs on the latent scene representation. Analogical to human concept learning, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide the searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.},
annote = {concepts=vectors
neural operators f(v)=v1 (example: shape: obj -> shapes)
RL to train the symbolic part (finding closest from embeddings)},
archivePrefix = {arXiv},
arxivId = {1904.12584},
author = {Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum, Joshua B. and Wu, Jiajun},
eprint = {1904.12584},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mao et al. - 2019 - The neuro-symbolic concept learner Interpreting scenes, words, and sentences from natural supervision.pdf:pdf},
journal = {7th International Conference on Learning Representations, ICLR 2019},
pages = {1--28},
title = {{The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision}},
year = {2019}
}
@article{Tank2017,
abstract = {While most classical approaches to Granger causality detection repose upon linear time series assumptions, many interactions in neuroscience and economics applications are nonlinear. We develop an approach to nonlinear Granger causality detection using multilayer perceptrons where the input to the network is the past time lags of all series and the output is the future value of a single series. A sufficient condition for Granger non-causality in this setting is that all of the outgoing weights of the input data, the past lags of a series, to the first hidden layer are zero. For estimation, we utilize a group lasso penalty to shrink groups of input weights to zero. We also propose a hierarchical penalty for simultaneous Granger causality and lag estimation. We validate our approach on simulated data from both a sparse linear autoregressive model and the sparse and nonlinear Lorenz-96 model.},
archivePrefix = {arXiv},
arxivId = {1711.08160},
author = {Tank, Alex and Cover, Ian and Foti, Nicholas J. and Shojaie, Ali and Fox, Emily B.},
eprint = {1711.08160},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tank et al. - 2017 - An Interpretable and Sparse Neural Network Model for Nonlinear Granger Causality Discovery.pdf:pdf},
number = {Nips},
title = {{An Interpretable and Sparse Neural Network Model for Nonlinear Granger Causality Discovery}},
url = {http://arxiv.org/abs/1711.08160},
year = {2017}
}
@article{Marino2019,
annote = {using the agent to prove properties about the world

gridworlds. hypothesis=(precond, action seq)

Reward based on conditions},
author = {Marino, Kenneth and Fergus, Rob and Szlam, Arthur},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marino, Fergus, Szlam - 2019 - Toward a Scientist Agent Learning to Verify Hypotheses.pdf:pdf},
title = {{Toward a Scientist Agent : Learning to Verify Hypotheses}},
year = {2019}
}
@article{Madumal2019,
annote = {CONCRETE examples of causal models of envs and explanations (for humans by ALGOS)},
archivePrefix = {arXiv},
arxivId = {1905.10958},
author = {Madumal, Prashan and Miller, Tim and Sonenberg, Liz and Vetere, Frank},
eprint = {1905.10958},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madumal et al. - 2019 - Explainable Reinforcement Learning Through a Causal Lens.pdf:pdf},
month = {may},
title = {{Explainable Reinforcement Learning Through a Causal Lens}},
url = {https://arxiv.org/abs/1905.10958},
year = {2019}
}
@article{Nair2019,
abstract = {Causal reasoning has been an indispensable capability for humans and other intelligent animals to interact with the physical world. In this work, we propose to endow an artificial agent with the capability of causal reasoning for completing goal-directed tasks. We develop learning-based approaches to inducing causal knowledge in the form of directed acyclic graphs, which can be used to contextualize a learned goal-conditional policy to perform tasks in novel environments with latent causal structures. We leverage attention mechanisms in our causal induction model and goal-conditional policy, enabling us to incrementally generate the causal graph from the agent's visual observations and to selectively use the induced graph for determining actions. Our experiments show that our method effectively generalizes towards completing new tasks in novel environments with previously unseen causal structures.},
annote = {Neural graph encoding + images, attentoin? Multiple envs. Too simple. It seems, the environment must be special? Can we transform any env to this form?

Edge decoder instead of explicit edge weight matrices

Qs:
1. why not explicit edge matrix?
variables are known, input=pixel
correspondence pixels-nodes is learned
attention to focus on nodes -- sparsity (only to one noce!)
all trained end-to-end




2. which environments it works on?
long term: all
should work in atari


3. why non-standard benchmarks?
goal-conditioned behavior, clear relationships visual--goals

4. how complex are the graph
single update -- 1 time-step

learning on the training graph -- loss=|learned-true|, supervised

Causal Reasoning from Meta-reinforcement Learning
learning the policy instead
best intervention for learning

code being released


INTERESTED in our project:
1. use the graph to do downstream tasks -- not only for the graph!
they were using downstream performance (user study for interpretability) OR final performance (task should favour true learning and true graph) distributional shift

SHORT number of episodes to learn -> need to do things right.

Comparison baseline: accuracy on a limited number of episodes.
Learned agent is better only on a limited number of steps.},
archivePrefix = {arXiv},
arxivId = {1910.01751},
author = {Nair, Suraj and Zhu, Yuke and Savarese, Silvio and Fei-Fei, Li},
eprint = {1910.01751},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nair et al. - 2019 - Causal Induction from Visual Observations for Goal Directed Tasks.pdf:pdf},
pages = {1--13},
title = {{Causal Induction from Visual Observations for Goal Directed Tasks}},
url = {http://arxiv.org/abs/1910.01751},
year = {2019}
}
@article{Lindgren2018,
abstract = {We consider the minimum cost intervention design problem: Given the essential graph of a causal graph and a cost to intervene on a variable, identify the set of interventions with minimum total cost that can learn any causal graph with the given essential graph. We first show that this problem is NP-hard. We then prove that we can achieve a constant factor approximation to this problem with a greedy algorithm. We then constrain the sparsity of each intervention. We develop an algorithm that returns an intervention design that is nearly optimal in terms of size for sparse graphs with sparse interventions and we discuss how to use it when there are costs on the vertices.},
annote = {Optimal intervention design.

Min-cost is NP-hard

Selecting a subset to intervent on by the SIZE of the subset -- not relevant to us since we don't care?},
archivePrefix = {arXiv},
arxivId = {1810.11867},
author = {Lindgren, Erik M. and Dimakis, Alexandros G. and Kocaoglu, Murat and Vishwanath, Sriram},
eprint = {1810.11867},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lindgren et al. - 2018 - Experimental design for cost-aware learning of causal graphs.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {5279--5289},
title = {{Experimental design for cost-aware learning of causal graphs}},
volume = {2018-Decem},
year = {2018}
}
@article{Thomas2018,
abstract = {It has been postulated that a good representation is one that disentangles the underlying explanatory factors of variation. However, it remains an open question what kind of training framework could potentially achieve that. Whereas most previous work focuses on the static setting (e.g., with images), we postulate that some of the causal factors could be discovered if the learner is allowed to interact with its environment. The agent can experiment with different actions and observe their effects. More specifically, we hypothesize that some of these factors correspond to aspects of the environment which are independently controllable, i.e., that there exists a policy and a learnable feature for each such aspect of the environment, such that this policy can yield changes in that feature with minimal changes to other features that explain the statistical variations in the observed data. We propose a specific objective function to find such factors, and verify experimentally that it can indeed disentangle independently controllable aspects of the environment without any extrinsic reward signal.},
annote = {Objective for independently controllable factors. Very small gridworlds.

causality loss and interaction might help learning disentangled representations},
archivePrefix = {arXiv},
arxivId = {1802.09484},
author = {Thomas, Valentin and Bengio, Emmanuel and Fedus, William and Pondard, Jules and Beaudoin, Philippe and Larochelle, Hugo and Pineau, Joelle and Precup, Doina and Bengio, Yoshua},
eprint = {1802.09484},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomas et al. - 2018 - Disentangling the independently controllable factors of variation by interacting with the world.pdf:pdf},
pages = {1--9},
title = {{Disentangling the independently controllable factors of variation by interacting with the world}},
url = {http://arxiv.org/abs/1802.09484},
year = {2018}
}
@article{VonKugelgen2019,
abstract = {We study the problem of causal discovery through targeted interventions. Starting from few observational measurements, we follow a Bayesian active learning approach to perform those experiments which, in expectation with respect to the current model, are maximally informative about the underlying causal structure. Unlike previous work, we consider the setting of continuous random variables with non-linear functional relationships, modelled with Gaussian process priors. To address the arising problem of choosing from an uncountable set of possible interventions, we propose to use Bayesian optimisation to efficiently maximise a Monte Carlo estimate of the expected information gain.},
annote = {Information gain intervention design

NOTE: exponential sum over the graphs, no overcoming},
archivePrefix = {arXiv},
arxivId = {1910.03962},
author = {von K{\"{u}}gelgen, Julius and Rubenstein, Paul K and Sch{\"{o}}lkopf, Bernhard and Weller, Adrian},
eprint = {1910.03962},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/von K{\"{u}}gelgen et al. - 2019 - Optimal experimental design via Bayesian optimization active causal structure learning for Gaussian proces.pdf:pdf},
title = {{Optimal experimental design via Bayesian optimization: active causal structure learning for Gaussian process networks}},
url = {http://arxiv.org/abs/1910.03962},
year = {2019}
}
@article{Corneil2018,
abstract = {Modern reinforcement learning algorithms reach super-human performance on many board and video games, but they are sample inefficient, i.e. they typically require significantly more playing experience than humans to reach an equal performance level. To improve sample efficiency, an agent may build a model of the environment and use planning methods to update its policy. In this article we introduce Variational State Tabulation (VaST), which maps an environment with a high-dimensional state space (e.g. the space of visual inputs) to an abstract tabular model. Prioritized sweeping with small backups, a highly efficient planning method, can then be used to update state-action values. We show how VaST can rapidly learn to maximize reward in tasks like 3D navigation and efficiently adapt to sudden changes in rewards or transition probabilities.},
author = {Corneil, Dane and Gerstner, Wulfram and Brea, Johanni},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Corneil, Gerstner, Brea - 2018 - Efficient model-based deep reinforcement learning with variational state tabulation.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Efficient model-based deep reinforcement learning with variational state tabulation}},
year = {2018}
}
@article{Barnett2015,
abstract = {Granger causality has long been a prominent method for inferring causal interactions between stochastic variables for a broad range of complex physical systems. However, it has been recognized that a moving average (MA) component in the data presents a serious confound to Granger causal analysis, as routinely performed via autoregressive (AR) modeling. We solve this problem by demonstrating that Granger causality may be calculated simply and efficiently from the parameters of a state-space (SS) model. Since SS models are equivalent to autoregressive moving average models, Granger causality estimated in this fashion is not degraded by the presence of a MA component. This is of particular significance when the data has been filtered, downsampled, observed with noise, or is a subprocess of a higher dimensional process, since all of these operations - commonplace in application domains as diverse as climate science, econometrics, and the neurosciences - induce a MA component. We show how Granger causality, conditional and unconditional, in both time and frequency domains, may be calculated directly from SS model parameters via solution of a discrete algebraic Riccati equation. Numerical simulations demonstrate that Granger causality estimators thus derived have greater statistical power and smaller bias than AR estimators. We also discuss how the SS approach facilitates relaxation of the assumptions of linearity, stationarity, and homoscedasticity underlying current AR methods, thus opening up potentially significant new areas of research in Granger causal analysis.},
archivePrefix = {arXiv},
arxivId = {1501.06502},
author = {Barnett, Lionel and Seth, Anil K.},
doi = {10.1103/PhysRevE.91.040101},
eprint = {1501.06502},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barnett, Seth - 2015 - Granger causality for state-space models.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {4},
pages = {1--5},
title = {{Granger causality for state-space models}},
volume = {91},
year = {2015}
}
@article{Kaminski2001,
abstract = {We consider the question of evaluating causal relations among neurobiological signals. In particular, we study the relation between the directed transfer function (DTF) and the well-accepted Granger causality, and show that DTF can be interpreted within the framework of Granger causality. In addition, we propose a method to assess the significance of causality measures. Finally, we demonstrate the applications of these measures to simulated data and actual neurobiological recordings.},
author = {Kami{\'{n}}ski, Maciej and Ding, Mingzhou and Truccolo, Wilson A. and Bressler, Steven L.},
doi = {10.1007/s004220000235},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kami{\'{n}}ski et al. - 2001 - Evaluating causal relations in neural systems Granger causality, directed transfer function and statistical as.pdf:pdf},
issn = {03401200},
journal = {Biological Cybernetics},
number = {2},
pages = {145--157},
pmid = {11508777},
title = {{Evaluating causal relations in neural systems: Granger causality, directed transfer function and statistical assessment of significance}},
volume = {85},
year = {2001}
}
@article{Verdes2005,
abstract = {In this work we propose a general nonparametric test of causality for weakly dependent time series. More precisely, we study the problem of attribution, i.e., the proper comparison of the relative influence that two or more external dynamics trigger on a given system of interest. We illustrate the possible applications of the proposed methodology in very different fields like physiology and climate science. {\textcopyright} 2005 The American Physical Society.},
author = {Verdes, P. F.},
doi = {10.1103/PhysRevE.72.026222},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Verdes - 2005 - Assessing causality from multivariate time series.pdf:pdf},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {2},
pages = {1--9},
title = {{Assessing causality from multivariate time series}},
volume = {72},
year = {2005}
}
@article{Tank2018,
abstract = {While most classical approaches to Granger causality detection assume linear dynamics, many interactions in applied domains, like neuroscience and genomics, are inherently nonlinear. In these cases, using linear models may lead to inconsistent estimation of Granger causal interactions. We propose a class of nonlinear methods by applying structured multilayer perceptrons (MLPs) or recurrent neural networks (RNNs) combined with sparsity-inducing penalties on the weights. By encouraging specific sets of weights to be zero—in particular through the use of convex group-lasso penalties—we can extract the Granger causal structure. To further contrast with traditional approaches, our framework naturally enables us to efficiently capture long-range dependencies between series either via our RNNs or through an automatic lag selection in the MLP. We show that our neural Granger causality methods outperform state-of-the-art nonlinear Granger causality methods on the DREAM3 challenge data. This data consists of nonlinear gene expression and regulation time courses with only a limited number of time points. The successes we show in this challenging dataset provide a powerful example of how deep learning can be useful in cases that go beyond prediction on large datasets. We likewise demonstrate our methods in detecting nonlinear interactions in a human motion capture dataset.},
archivePrefix = {arXiv},
arxivId = {1802.05842},
author = {Tank, Alex and Covert, Ian and Foti, Nicholas J. and Shojaie, Ali and Fox, Emily B.},
eprint = {1802.05842},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tank et al. - 2018 - Neural granger causality for nonlinear time series.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--14},
title = {{Neural granger causality for nonlinear time series}},
year = {2018}
}
@article{Fiez2020,
abstract = {This paper concerns the local stability and convergence rate of gradient descent-ascent in two-player non-convex, non-concave zero-sum games. We study the role that a finite timescale separation parameter $\tau$ has on the learning dynamics where the learning rate of player 1 is denoted by $\gamma$1 and the learning rate of player 2 is defined to be $\gamma$2 = $\tau$$\gamma$1. Existing work analyzing the role of timescale separation in gradient descent-ascent has primarily focused on the edge cases of players sharing a learning rate ($\tau$ = 1) and the maximizing player approximately converging between each update of the minimizing player ($\tau$ → ∞). For the parameter choice of $\tau$ = 1, it is known that the learning dynamics are not guaranteed to converge to a game-theoretically meaningful equilibria in general as shown by Mazumdar et al. (2020) and Daskalakis and Panageas (2018). In contrast, Jin et al. (2020) showed that the stable critical points of gradient descent-ascent coincide with the set of strict local minmax equilibria as $\tau$ → ∞. In this work, we bridge the gap between past work by showing there exists a finite timescale separation parameter $\tau$∗ such that x∗ is a stable critical point of gradient descent-ascent for all $\tau$ ∈ ($\tau$∗,∞) if and only if it is a strict local minmax equilibrium. Moreover, we provide an explicit construction for computing $\tau$∗ along with corresponding convergence rates and results under deterministic and stochastic gradient feedback. The convergence results we present are complemented by a non-convergence result: given a critical point x∗ that is not a strict local minmax equilibrium, then there exists a finite timescale separation $\tau$0 such that x∗ is unstable for all $\tau$ ∈ ($\tau$0,∞). Finally, we extend the stability and convergence results regarding gradient descent-ascent to gradient penalty regularization methods for generative adversarial networks (Mescheder et al., 2018) and empirically demonstrate on the CIFAR-10 and CelebA datasets the significant impact timescale separation has on training performance.},
archivePrefix = {arXiv},
arxivId = {2009.14820},
author = {Fiez, Tanner and Ratliff, Lillian J.},
eprint = {2009.14820},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fiez, Ratliff - 2020 - Gradient descent-ascent provably converges to strict local minmax Equilibria with a finite timescale separation.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--70},
title = {{Gradient descent-ascent provably converges to strict local minmax Equilibria with a finite timescale separation}},
year = {2020}
}
@article{Veness2010,
abstract = {This paper introduces a principled approach for the design of a scalable general reinforcement learning agent. This approach is based on a direct approximation of AIXI, a Bayesian optimality notion for general reinforcement learning agents. Previously, it has been unclear whether the theory of AIXI could motivate the design of practical algorithms. We answer this hitherto open question in the affirmative, by providing the first computationally feasible approximation to the AIXI agent. To develop our approximation, we introduce a Monte Carlo Tree Search algorithm along with an agent-specific extension of the Context Tree Weighting algorithm. Empirically, we present a set of encouraging results on a number of stochastic, unknown, and partially observable domains. Copyright {\textcopyright} 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1007.2049},
author = {Veness, Joel and {Siong Ng}, Kee and Hutter, Marcus and Silver, David},
eprint = {1007.2049},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Veness et al. - 2010 - Reinforcement learning via AIXI approximation(2).pdf:pdf},
isbn = {9781577354642},
journal = {Proceedings of the National Conference on Artificial Intelligence},
keywords = {Technical Papers -- Machine Learning},
number = {3},
pages = {605--611},
title = {{Reinforcement learning via AIXI approximation}},
volume = {1},
year = {2010}
}
@article{Doerig2019,
abstract = {How can we explain consciousness? This question has become a vibrant topic of neuroscience research in recent decades. A large body of empirical results has been accumulated, and many theories have been proposed. Certain theories suggest that consciousness should be explained in terms of brain functions, such as accessing information in a global workspace, applying higher order to lower order representations, or predictive coding. These functions could be realized by a variety of patterns of brain connectivity. Other theories, such as Information Integration Theory (IIT)and Recurrent Processing Theory (RPT), identify causal structure with consciousness. For example, according to these theories, feedforward systems are never conscious, and feedback systems always are. Here, using theorems from the theory of computation, we show that causal structure theories are either false or outside the realm of science.},
author = {Doerig, Adrien and Schurger, Aaron and Hess, Kathryn and Herzog, Michael H.},
doi = {10.1016/j.concog.2019.04.002},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doerig et al. - 2019 - The unfolding argument Why IIT and other causal structure theories cannot explain consciousness(2).pdf:pdf},
issn = {10902376},
journal = {Consciousness and Cognition},
keywords = {Causal structure,Consciousness,IIT,Neural networks,RPT,Theories},
number = {April},
pages = {49--59},
pmid = {31078047},
publisher = {Elsevier},
title = {{The unfolding argument: Why IIT and other causal structure theories cannot explain consciousness}},
url = {https://doi.org/10.1016/j.concog.2019.04.002},
volume = {72},
year = {2019}
}
@article{Bellec2018,
abstract = {Recurrent networks of spiking neurons (RSNNs) underlie the astounding computing and learning capabilities of the brain. But computing and learning capabilities of RSNN models have remained poor, at least in comparison with artificial neural networks (ANNs). We address two possible reasons for that. One is that RSNNs in the brain are not randomly connected or designed according to simple rules, and they do not start learning as a tabula rasa network. Rather, RSNNs in the brain were optimized for their tasks through evolution, development, and prior experience. Details of these optimization processes are largely unknown. But their functional contribution can be approximated through powerful optimization methods, such as backpropagation through time (BPTT). A second major mismatch between RSNNs in the brain and models is that the latter only show a small fraction of the dynamics of neurons and synapses in the brain. We include neurons in our RSNN model that reproduce one prominent dynamical process of biological neurons that takes place at the behaviourally relevant time scale of seconds: neuronal adaptation. We denote these networks as LSNNs because of their Long short-term memory. The inclusion of adapting neurons drastically increases the computing and learning capability of RSNNs if they are trained and configured by deep learning (BPTT combined with a rewiring algorithm that optimizes the network architecture). In fact, the computational performance of these RSNNs approaches for the first time that of LSTM networks. In addition RSNNs with adapting neurons can acquire abstract knowledge from prior learning in a Learning-to-Learn (L2L) scheme, and transfer that knowledge in order to learn new but related tasks from very few examples. We demonstrate this for supervised learning and reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1803.09574},
author = {Bellec, Guillaume and Salaj, Darjan and Subramoney, Anand and Legenstein, Robert and Maass, Wolfgang},
eprint = {1803.09574},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellec et al. - 2018 - Long short-term memory and learning-to-learn in networks of spiking neurons.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {787--797},
title = {{Long short-term memory and learning-to-learn in networks of spiking neurons}},
volume = {2018-Decem},
year = {2018}
}
@article{Tononi2016,
abstract = {In this Opinion article, we discuss how integrated information theory accounts for several aspects of the relationship between consciousness and the brain. Integrated information theory starts from the essential properties of phenomenal experience, from which it derives the requirements for the physical substrate of consciousness. It argues that the physical substrate of consciousness must be a maximum of intrinsic cause-effect power and provides a means to determine, in principle, the quality and quantity of experience. The theory leads to some counterintuitive predictions and can be used to develop new tools for assessing consciousness in non-communicative patients.},
author = {Tononi, Giulio and Boly, Melanie and Massimini, Marcello and Koch, Christof},
doi = {10.1038/nrn.2016.44},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tononi et al. - 2016 - Integrated information theory From consciousness to its physical substrate(2).pdf:pdf},
issn = {14710048},
journal = {Nature Reviews Neuroscience},
number = {7},
pages = {450--461},
pmid = {27225071},
publisher = {Nature Publishing Group},
title = {{Integrated information theory: From consciousness to its physical substrate}},
volume = {17},
year = {2016}
}
@book{Hoang2020,
author = {Hoang, Le Nguyen},
edition = {1st},
publisher = {Chapman and Hall/CRC},
title = {{The Equation of Knowledge}},
year = {2020}
}
@article{Chalupka2015,
abstract = {We provide a rigorous definition of the visual cause of a behavior that is broadly applicable to the visually driven behavior in humans, animals, neurons, robots and other perceiving systems. Our framework generalizes standard accounts of causal learning to settings in which the causal variables need to be constructed from micro-variables. We prove the Causal Coarsening Theorem, which allows us to gain causal knowledge from observational data with minimal experimental effort. The theorem provides a connection to standard inference techniques in machine learning that identify features of an image that correlate with, but may not cause, the target behavior. Finally, we propose an active learning scheme to learn a manipulator function that performs optimal manipulations on the image to automatically identify the visual cause of a target behavior. We illustrate our inference and learning algorithms in experiments based on both synthetic and real data.},
annote = {Trying to augment the image to see if it's the real cause

Microvariables and macrovariables.

causal coarsening -- equivalence classes in microvariables based on the same value of macrovariables},
archivePrefix = {arXiv},
arxivId = {1412.2309},
author = {Chalupka, Krzysztof and Perona, Pietro and Eberhardt, Frederick},
eprint = {1412.2309},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chalupka, Perona, Eberhardt - 2015 - Visual causal feature learning.pdf:pdf},
journal = {Uncertainty in Artificial Intelligence - Proceedings of the 31st Conference, UAI 2015},
pages = {181--190},
title = {{Visual causal feature learning}},
year = {2015}
}
@article{SungryullSohnHyunjaeWooJongwookChoi2017,
annote = {INDUCTIVE LOGIC PROGRAMMING:
decision tree -> formula (when subtasks is active -- precondition)

Boolean function -> subtask active},
archivePrefix = {arXiv},
arxivId = {arXiv:1611.02779v2},
author = {{Sungryull Sohn, Hyunjae Woo, Jongwook Choi}, Honglak Lee},
eprint = {arXiv:1611.02779v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sungryull Sohn, Hyunjae Woo, Jongwook Choi - 2017 - META REINFORCEMENT LEARNING WITH AU- TONOMOUS INFERENCE OF SUBTASK DEPENDENCIES.pdf:pdf},
pages = {1--14},
title = {{META REINFORCEMENT LEARNING WITH AU- TONOMOUS INFERENCE OF SUBTASK DEPENDENCIES}},
year = {2017}
}
@article{Mooij2016,
abstract = {The gold standard for discovering causal relations is by means of experimentation. Over the last decades, alternative methods have been proposed that can infer causal relations between variables from certain statistical patterns in purely observational data. We introduce Joint Causal Inference (JCI), a novel approach to causal discovery from multiple data sets that elegantly unifies both approaches. JCI is a causal modeling approach rather than a specific algorithm, and it can be used in combination with any causal discovery algorithm that can take into account certain background knowledge. The main idea is to reduce causal discovery from multiple datasets originating from different contexts (e.g., different experimental conditions) to causal discovery from a single pooled dataset by adding auxiliary context variables and incorporating applicable background knowledge on the causal relationships involving the context variables. We propose different flavours of JCI that differ in the amount of background knowledge that is assumed. JCI can deal with several different types of interventions in a unified fashion, does not require knowledge on intervention targets or types in case of interventional data, and allows one to fully exploit all the information in the joint distribution on system and context variables. We explain how some well-known causal discovery algorithms can be seen as implementations of the JCI framework, but we also propose novel implementations that are simple adaptations of existing causal discovery methods for purely observational data to the JCI setting. We evaluate different implementations of the JCI approach on synthetic data and on flow cytometry protein expression data and conclude that JCI implementations can outperform state-of-the-art causal discovery algorithms.},
annote = {Aggregating data from multiple datasetss},
archivePrefix = {arXiv},
arxivId = {1611.10351},
author = {Mooij, Joris M. and Magliacane, Sara and Claassen, Tom},
eprint = {1611.10351},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mooij, Magliacane, Claassen - 2016 - Joint Causal Inference from Multiple Contexts.pdf:pdf},
title = {{Joint Causal Inference from Multiple Contexts}},
url = {http://arxiv.org/abs/1611.10351},
year = {2016}
}
@article{Pathak2017,
annote = {Reward for falsifying the model},
author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pathak et al. - 2017 - Curiosity-driven Exploration by Self-supervised Prediction.pdf:pdf},
title = {{Curiosity-driven Exploration by Self-supervised Prediction}},
year = {2017}
}
@article{Lu2018,
abstract = {We propose a general formulation for addressing reinforcement learning (RL) problems in settings with observational data. That is, we consider the problem of learning good policies solely from historical data in which unobserved factors (confounders) affect both observed actions and rewards. Our formulation allows us to extend a representative RL algorithm, the Actor-Critic method, to its deconfounding variant, with the methodology for this extension being easily applied to other RL algorithms. In addition to this, we develop a new benchmark for evaluating deconfounding RL algorithms by modifying the OpenAI Gym environments and the MNIST dataset. Using this benchmark, we demonstrate that the proposed algorithms are superior to traditional RL methods in confounded environments with observational data. To the best of our knowledge, this is the first time that confounders are taken into consideration for addressing full RL problems with observational data. Code is available at https://github.com/CausalRL/DRL.},
annote = {author is doing CRL seriously, and the code looks great

how can actions and reward have a common cause -- something in the environment},
archivePrefix = {arXiv},
arxivId = {1812.10576},
author = {Lu, Chaochao and Sch{\"{o}}lkopf, Bernhard and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel},
eprint = {1812.10576},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Sch{\"{o}}lkopf, Hern{\'{a}}ndez-Lobato - 2018 - Deconfounding Reinforcement Learning in Observational Settings.pdf:pdf},
pages = {1--30},
title = {{Deconfounding Reinforcement Learning in Observational Settings}},
url = {http://arxiv.org/abs/1812.10576},
year = {2018}
}
@article{Chalupka2017,
abstract = {Causal feature learning (CFL) (Chalupka et al. is a causal inference framework rooted in the language of causal graphical models (Pearl J, Reasoning and inference. Cambridge University Press, Cambridge, 2009; Spirtes et al., Causation, Prediction, and Search. Massachusetts Institute of Technology, Massachusetts, 2000), and computational mechanics (Shalizi, PhD thesis, University of Wisconsin at Madison, 2001). CFL is aimed at discovering high-level causal relations from low-level data, and at reducing the experimental effort to understand confounding among the high-level variables. We first review the scientific motivation for CFL, then present a detailed introduction to the framework, laying out the definitions and algorithmic steps. A simple example illustrates the techniques involved in the learning steps and provides visual intuition. Finally, we discuss the limitations of the current framework and list a number of open problems.},
annote = {Learning features from low-level data which are causally related

Microvariables => Macrovariables => causal relationships

Can do it automatically. Using NNs to learn. Need interventions for every variable?},
author = {Chalupka, Krzysztof and Eberhardt, Frederick and Perona, Pietro},
doi = {10.1007/s41237-016-0008-2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chalupka, Eberhardt, Perona - 2017 - Causal feature learning an overview.pdf:pdf},
isbn = {4123701600082},
issn = {0385-7417},
journal = {Behaviormetrika},
keywords = {Causal discovery,Causal inference,Graphical models,causal discovery {\'{a}} causal,communicated by shohei shimizu,inference {\'{a}} graphical models,krzysztof chalupka,multiscale modeling,networks {\'{a}} macrovariables {\'{a}},{\'{a}} bayesian},
number = {1},
pages = {137--164},
publisher = {Springer Japan},
title = {{Causal feature learning: an overview}},
volume = {44},
year = {2017}
}
@article{Everitt2019,
abstract = {Agents are systems that optimize an objective function in an environment. Together, the goal and the environment induce secondary objectives, incentives. Modeling the agent-environment interaction in graphical models called influence diagrams, we can answer two fundamental questions about an agent's incentives directly from the graph: (1) which nodes is the agent incentivized to observe, and (2) which nodes is the agent incentivized to influence? The answers tell us which information and influence points need extra protection. For example, we may want a classifier for job applications to not use the ethnicity of the candidate, and a reinforcement learning agent not to take direct control of its reward mechanism. Different algorithms and training paradigms can lead to different influence diagrams, so our method can be used to identify algorithms with problematic incentives and help in designing algorithms with better incentives.},
annote = {Causal Influence diagrams def and do-properties},
archivePrefix = {arXiv},
arxivId = {1902.09980},
author = {Everitt, Tom and Ortega, Pedro A. and Barnes, Elizabeth and Legg, Shane},
eprint = {1902.09980},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Everitt et al. - 2019 - Understanding Agent Incentives using Causal Influence Diagrams. Part I Single Action Settings.pdf:pdf},
title = {{Understanding Agent Incentives using Causal Influence Diagrams. Part I: Single Action Settings}},
url = {http://arxiv.org/abs/1902.09980},
year = {2019}
}
@article{Griveau-Billion2019,
abstract = {We propose a novel algorithm for efficiently computing a sparse directed adjacency matrix from a group of time series following a causal graph process. Our solution is scalable for both dense and sparse graphs and automatically selects the LASSO coefficient to obtain an appropriate number of edges in the adjacency matrix. Current state-of-the-art approaches rely on sparse-matrix-computation libraries to scale, and either avoid automatic selection of the LASSO penalty coefficient or rely on the prediction mean squared error, which is not directly related to the correct number of edges. Instead, we propose a cyclical coordinate descent algorithm that employs two new non-parametric error metrics to automatically select the LASSO coefficient. We demonstrate state-of-the-art performance of our algorithm on simulated stochastic block models and a real dataset of stocks from the S\&P$500$.},
annote = {Linear-only case? Explicit solution for CD.

L-1 coeff is selected separately from CD via another metirc AS A REGULARIZER -- without l1 coeff search?},
archivePrefix = {arXiv},
arxivId = {1906.04479},
author = {Griveau-Billion, Th{\'{e}}ophile and Calderhead, Ben},
eprint = {1906.04479},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Griveau-Billion, Calderhead - 2019 - Efficient structure learning with automatic sparsity selection for causal graph processes.pdf:pdf},
number = {2001},
pages = {1--13},
title = {{Efficient structure learning with automatic sparsity selection for causal graph processes}},
url = {http://arxiv.org/abs/1906.04479},
year = {2019}
}
@article{Peters2015,
abstract = {Causal inference relies on the structure of a graph, often a directed acyclic graph (DAG). Different graphs may result in different causal inference statements and different intervention distributions. To quantify such differences, we propose a (pre-)metric between DAGs, the structural intervention distance (SID). The SID is based on a graphical criterion only and quantifies the closeness between twoDAGs in terms of their corresponding causal inference statements. It is therefore well suited for evaluating graphs that are used for computing interventions. Instead of DAGs, it is also possible to compare CPDAGs, completed partially DAGs that represent Markov equivalence classes. The SID differs significantly from the widely used structural Hamming distance and therefore constitutes a valuable additional measure. We discuss properties of this distance and provide a (reasonably) efficient implementation with software code available on the first author's home page.},
annote = {Distance accounting for changes in interventional distributions

SHD -- only # edges different},
archivePrefix = {arXiv},
arxivId = {1306.1043},
author = {Peters, Jonas and B{\"{u}}hlmann, Peter},
doi = {10.1162/NECO_a_00708},
eprint = {1306.1043},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peters, B{\"{u}}hlmann - 2015 - Structural intervention distance for evaluating causal graphs.pdf:pdf},
issn = {1530888X},
journal = {Neural Computation},
number = {3},
pages = {771--799},
title = {{Structural intervention distance for evaluating causal graphs}},
volume = {27},
year = {2015}
}
@article{Ke2019,
abstract = {Meta-learning over a set of distributions can be interpreted as learning different types of parameters corresponding to short-term vs long-term aspects of the mechanisms underlying the generation of data. These are respectively captured by quickly-changing parameters and slowly-changing meta-parameters. We present a new framework for meta-learning causal models where the relationship between each variable and its parents is modeled by a neural network, modulated by structural meta-parameters which capture the overall topology of a directed graphical model. Our approach avoids a discrete search over models in favour of a continuous optimization procedure. We study a setting where interventional distributions are induced as a result of a random intervention on a single unknown variable of an unknown ground truth causal model, and the observations arising after such an intervention constitute one meta-example. To disentangle the slow-changing aspects of each conditional from the fast-changing adaptations to each intervention, we parametrize the neural network into fast parameters and slow meta-parameters. We introduce a meta-learning objective that favours solutions robust to frequent but sparse interventional distribution change, and which generalize well to previously unseen interventions. Optimizing this objective is shown experimentally to recover the structure of the causal graph.},
annote = {CAN USE AS AN ELEMENT for learning from RL data in our Artificla Science method because here we learn the causal model in a differentiable way from unknown interventions

Algo:
1. Add a component to reward to value X_i=1, collect trajectories into the dataset for this model
2. Re-train this model

NO CODE?

NN for learning causal model
slow meta/fast normal. 

Meta params + fcn=NN

Efficient parameterization of an exponential number of SCM DAGs},
archivePrefix = {arXiv},
arxivId = {1910.01075},
author = {Ke, Nan Rosemary and Bilaniuk, Olexa and Goyal, Anirudh and Bauer, Stefan and Larochelle, Hugo and Pal, Chris and Bengio, Yoshua},
eprint = {1910.01075},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ke et al. - 2019 - Learning Neural Causal Models from Unknown Interventions.pdf:pdf},
month = {oct},
title = {{Learning Neural Causal Models from Unknown Interventions}},
url = {http://arxiv.org/abs/1910.01075},
year = {2019}
}
@article{Stokes2017,
abstract = {Granger causality methods were developed to analyze the flow of information between time series. These methods have become more widely applied in neuroscience. Frequency-domain causality measures, such as those of Geweke, as well as multivariate methods, have particular appeal in neuroscience due to the prevalence of oscillatory phenomena and highly multivariate experimental recordings. Despite its widespread application in many fields, there are ongoing concerns regarding the applicability of Granger causality methods in neuroscience. When are these methods appropriate? How reliably do they recover the system structure underlying the observed data? What do frequency-domain causality measures tell us about the functional properties of oscillatory neural systems? In this paper, we analyze fundamental properties of Granger–Geweke (GG) causality, both computational and conceptual. Specifically, we show that (i) GG causality estimates can be either severely biased or of high variance, both leading to spurious results; (ii) even if estimated correctly, GG causality estimates alone are not interpretable without examining the component behaviors of the system model; and (iii) GG causality ignores critical components of a system's dynamics. Based on this analysis, we find that the notion of causality quantified is incompatible with the objectives of many neuroscience investigations, leading to highly counterintuitive and potentially misleading results. Through the analysis of these problems, we provide important conceptual clarification of GG causality, with implications for other related causality approaches and for the role of causality analyses in neuroscience as a whole.},
annote = {Problems with Granger causality},
author = {Stokes, Patrick A. and Purdon, Patrick L.},
doi = {10.1073/pnas.1704663114},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stokes, Purdon - 2017 - A study of problems encountered in Granger causality analysis from a neuroscience perspective.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Connectivity,Granger causality,Neural oscillations,System identification,Time series analysis},
number = {34},
pages = {E7063--E7072},
title = {{A study of problems encountered in Granger causality analysis from a neuroscience perspective}},
volume = {114},
year = {2017}
}
@article{He2008,
abstract = {The causal discovery from data is important for various scientific investigations. Because we cannot distinguish the different directed acyclic graphs (DAGs) in a Markov equivalence class learned from observational data, we have to collect further information on causal structures from experiments with external interventions. In this paper, we propose an active learning approach for discovering causal structures in which we first find a Markov equivalence class from observational data, and then we orient undirected edges in every chain component via intervention experiments separately. In the experiments, some variables are manipulated through external interventions. We discuss two kinds of intervention experiments, randomized experiment and quasi-experiment. Furthermore, we give two optimal designs of experiments, a batch-intervention design and a sequential-intervention design, to minimize the number of manipulated variables and the set of candidate structures based on the minimax and the maximum entropy criteria. We show theoretically that structural learning can be done locally in subgraphs of chain components without need of checking illegal v-structures and cycles in the whole network and that a Markov equivalence subclass obtained after each intervention can still be depicted as a chain graph.},
annote = {An approach for active causal discovery. Graph considered explicitly. Theory. Maximum entropy criterion for intervention design},
author = {He, Yang Bo and Geng, Zhi},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Geng - 2008 - Active learning of causal networks with intervention experiments and optimal designs.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Active learning,Causal networks,Directed acyclic graphs,Intervention,Markov equivalence class,Optimal design,Structural learning},
pages = {2523--2547},
title = {{Active learning of causal networks with intervention experiments and optimal designs}},
volume = {9},
year = {2008}
}
@article{Nauta2019,
abstract = {Having insight into the causal associations in a complex system facilitates decision making, e.g., for medical treatments, urban infrastructure improvements or financial investments. The amount of observational data grows, which enables the discovery of causal relationships between variables from observation of their behaviour in time. Existing methods for causal discovery from time series data do not yet exploit the representational power of deep learning. We therefore present the Temporal Causal Discovery Framework (TCDF), a deep learning framework that learns a causal graph structure by discovering causal relationships in observational time series data. TCDF uses attention-based convolutional neural networks combined with a causal validation step. By interpreting the internal parameters of the convolutional networks, TCDF can also discover the time delay between a cause and the occurrence of its effect. Our framework learns temporal causal graphs, which can include confounders and instantaneous effects. Experiments on financial and neuroscientific benchmarks show state-of-the-art performance of TCDF on discovering causal relationships in continuous time series data. Furthermore, we show that TCDF can circumstantially discover the presence of hidden confounders. Our broadly applicable framework can be used to gain novel insights into the causal dependencies in a complex system, which is important for reliable predictions, knowledge discovery and data-driven decision making.},
annote = {Better methods for graph learning

PyTorch library},
author = {Nauta, Meike and Bucur, Doina and Seifert, Christin},
doi = {10.3390/make1010019},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nauta, Bucur, Seifert - 2019 - Causal Discovery with Attention-Based Convolutional Neural Networks.pdf:pdf},
journal = {Machine Learning and Knowledge Extraction},
keywords = {attention,causal discovery,convolutional neural network,machine learning,time series},
number = {1},
pages = {312--340},
title = {{Causal Discovery with Attention-Based Convolutional Neural Networks}},
volume = {1},
year = {2019}
}
@article{DeHaan2019,
abstract = {Behavioral cloning reduces policy learning to supervised learning by training a discriminative model to predict expert actions given observations. Such discriminative models are non-causal: the training procedure is unaware of the causal structure of the interaction between the expert and the environment. We point out that ignoring causality is particularly damaging because of the distributional shift in imitation learning. In particular, it leads to a counter-intuitive "causal misidentification" phenomenon: access to more information can yield worse performance. We investigate how this problem arises, and propose a solution to combat it through targeted interventions---either environment interaction or expert queries---to determine the correct causal model. We show that causal misidentification occurs in several benchmark control domains as well as realistic driving settings, and validate our solution against DAgger and other baselines and ablations.},
annote = {Identifying non-causal variables. Learning variables from data as well

Just subset of variables},
archivePrefix = {arXiv},
arxivId = {1905.11979},
author = {de Haan, Pim and Jayaraman, Dinesh and Levine, Sergey},
eprint = {1905.11979},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Haan, Jayaraman, Levine - 2019 - Causal Confusion in Imitation Learning.pdf:pdf},
number = {NeurIPS},
pages = {1--17},
title = {{Causal Confusion in Imitation Learning}},
url = {http://arxiv.org/abs/1905.11979},
year = {2019}
}
@article{Frisch2014,
abstract = {Accounts of causal discovery have traditionally split into approaches based on passive observational data and approaches based on experimental interventions that take control of (the distribution of) one or more variables. The former includes a vast number of techniques for the inference to causal structure on the basis of statistical features of data, while the latter provides in addition a methodology of how an experiment should be performed, in order to be infor-mative about causal structure. In this thesis, the causal Bayes net framework is used to integrate these two approaches and general guidelines are provided not only of how experiments should be performed but also which experiments should be performed to discover the causal structure among a potentially large number of random variables. In that sense this thesis aims to extend consid-erations found in experimental design from single experiments to sequences of experiments. To do so, the thesis provides a precise account of what constitutes an intervention that allows for, but does not necessessitate, a role of agency in interventions. We describe a space of interventions that is broader than standard randomized controlled trials, and explore what implications follow for discov-ery when different types of interventions are used. Results pertaining to the methodology of causal discovery, its limits, the efficiency of its search strategies and the meta-analysis of experimental results are presented. This thesis analy-ses the combinatorics of sequences of experiments for causal discovery, ties the discovery problem into a game-theoretic framework and points to some of the (many) difficulties that remain open research questions.},
annote = {Big thesis on designing interventions},
author = {Frisch, Mathias and Frisch, Mathias},
doi = {10.1017/cbo9781139381772.004},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frisch, Frisch - 2014 - Causation and intervention.pdf:pdf},
journal = {Causal Reasoning in Physics},
pages = {77--110},
title = {{Causation and intervention}},
year = {2014}
}
@article{Cha2018,
abstract = {Unsupervised methods have proven effective for discriminative tasks in a single-modality scenario. In this paper, we present a multimodal framework for learning sparse representations that can capture semantic correlation between modalities. The framework can model relationships at a higher level by forcing the shared sparse representation. In particular, we propose the use of joint dictionary learning technique for sparse coding and formulate the joint representation for concision, cross-modal representations (in case of a missing modality), and union of the cross-modal representations. Given the accelerated growth of multimodal data posted on the Web such as YouTube, Wikipedia, and Twitter, learning good multimodal features is becoming increasingly important. We show that the shared representations enabled by our framework substantially improve the classification performance under both unimodal and multimodal settings. We further show how deep architectures built on the proposed framework are effective for the case of highly nonlinear correlations between modalities. The effectiveness of our approach is demonstrated experimentally in image denoising, multimedia event detection and retrieval on the TRECVID dataset (audio-video), category classification on the Wikipedia dataset (image-text), and sentiment classification on PhotoTweet (image-text).},
archivePrefix = {arXiv},
arxivId = {1511.06238},
author = {Cha, Miriam and Gwon, Youngjune and Kung, Hsiang-Tsung},
doi = {10.46397/jaih.2.2},
eprint = {1511.06238},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cha, Gwon, Kung - 2018 - Multimodal Sparse Representation Learning and Applications.pdf:pdf},
issn = {26354691},
journal = {Journal of AI Humanities},
pages = {39--64},
title = {{Multimodal Sparse Representation Learning and Applications}},
volume = {2},
year = {2018}
}
@article{Pei2019,
abstract = {The information bottleneck principle in [24] is an elegant and useful approach to representation learning. In this paper, we investigate the problem of representation learning in the context of reinforcement learning using the information bottleneck framework, aiming at improving the sample efficiency of the learning algorithms. We analytically derive the optimal conditional distribution of the representation, and provide a variational lower bound. Then, we maximize this lower bound with the Stein variational (SV) gradient method (originally developed in [13,14]). We incorporate this framework in the advantageous actor critic algorithm (A2C)[15] and the proximal policy optimization algorithm (PPO) [20]. Our experimental results show that our framework can improve the sample efficiency of vanilla A2C and PPO significantly. Finally, we study the information bottleneck (IB) perspective in deep RL with the algorithm called mutual information neural estimation(MINE) [3]. We experimentally verify that the information extraction-compression process also exists in deep RL and our framework is capable of accelerating this process. We also analyze the relationship between MINE and our method, through this relationship, we theoretically derive an algorithm to optimize our IB framework without constructing the lower bound.},
archivePrefix = {arXiv},
arxivId = {1911.05695},
author = {Pei, Yingjun and Hou, Xinwen},
eprint = {1911.05695},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pei, Hou - 2019 - Learning Representations in Reinforcement Learning An Information Bottleneck Approach.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Learning Representations in Reinforcement Learning: An Information Bottleneck Approach}},
year = {2019}
}
@article{Ranzato2007,
abstract = {We describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces "stroke detectors" when trained on handwritten numerals, and Gabor-like filters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the first layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical filter maps.},
author = {Ranzato, Marc Aurelio and Poultney, Christopher and Chopra, Sumit and LeCun, Yann},
doi = {10.7551/mitpress/7503.003.0147},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ranzato et al. - 2007 - Efficient learning of sparse representations with an energy-based model.pdf:pdf},
isbn = {9780262195683},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {1137--1144},
title = {{Efficient learning of sparse representations with an energy-based model}},
year = {2007}
}
@article{Rafati2019,
abstract = {Reinforcement learning (RL) algorithms allow artificial agents to improve their selection of actions to increase rewarding experiences in their environments. Temporal Difference (TD) Learning – a model-free RL method – is a leading account of the midbrain dopamine system and the basal ganglia in reinforcement learning. These algorithms typically learn a mapping from the agent's current sensed state to a selected action (known as a policy function) via learning a value function (expected future rewards). TD Learning methods have been very successful on a broad range of control tasks, but learning can become intractably slow as the state space of the environment grows. This has motivated methods that learn internal representations of the agent's state, effectively reducing the size of the state space and restructuring state representations in order to support generalization. However, TD Learning coupled with an artificial neural network, as a function approximator, has been shown to fail to learn some fairly simple control tasks, challenging this explanation of reward-based learning. We hypothesize that such failures do not arise in the brain because of the ubiquitous presence of lateral inhibition in the cortex, producing sparse distributed internal representations that support the learning of expected future reward. The sparse conjunctive representations can avoid catastrophic interference while still supporting generalization. We provide support for this conjecture through computational simulations, demonstrating the benefits of learned sparse representations for three problematic classic control tasks: Puddle-world, Mountain-car, and Acrobot.},
archivePrefix = {arXiv},
arxivId = {1909.01575},
author = {Rafati, Jacob and Noelle, David C.},
eprint = {1909.01575},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rafati, Noelle - 2019 - Learning sparse representations in reinforcement learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Catastrophic interference,Dopamine system,Generalization,K-Winners-Take-All (kWTA),Lateral inhibition,Learning representations,Midbrain,Reinforcement learning,Representations,SARSA,Sparse,Temporal Difference Learning},
pages = {1--20},
title = {{Learning sparse representations in reinforcement learning}},
year = {2019}
}
@article{Baze2012,
abstract = {Encephalization, or brain size larger than expected from body size, has long been considered to correlate with improved cognitive abilities across species and even intelligence. However, it is still unknown what characteristics of relatively large brains underlie their improved functions. Here, it is shown that more encephalized rodent species have the number of neurons expected for their brain size, but a larger number of neurons than expected for their body size. The number of neurons in excess relative to body size might be available for improved associative functions and, thus, be responsible for the cognitive advantage observed in more encephalized animals. It is further proposed that, if such neuronal excess does provide for improved cognitive abilities, then the total number of excess neurons in each species - here dubbed the neuronal index - should be a better indicator of cognitive abilities than the encephalization quotient (EQ). Because the neuronal index is a function of both the number of neurons expected from the size of the body and the absolute number of neurons in the brain, differences in this parameter across species that share similar EQs might explain why these often have different cognitive capabilities, particularly when comparing across mammalian orders. {\textcopyright} 2007 Wiley-Liss, Inc.},
author = {Baze, Wallace B and Mcarthur, Mark J and Hopkins, William D and Hof, Patrick R and Smaers, Jeroen B. and Dechmann, Dina K.N. and Goswami, Anjali and Soligo, Christophe and Safi, Kamran and Herculano-Houzel, Suzana and Sue, Angela and Hicks, Angela Sue},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baze et al. - 2012 - UC San Diego UC San Diego Electronic Theses and Dissertations by.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Brain allometry,Brain size,Comparative method,Comparative neuroanatomy,Encephalization,Energetics,Evolution,Number of glia,Number of neurons,Phylogenetic,Rodents,Trait coevolution},
number = {44},
pages = {1280--1287},
pmid = {17847061},
title = {{UC San Diego UC San Diego Electronic Theses and Dissertations by}},
volume = {290},
year = {2012}
}
@article{Seeger2007,
abstract = {We present a framework for efficient, accurate approximate Bayesian inference in generalized linear models (GLMs), based on the expectation propagation (EP) technique. The parameters can be endowed with a factorizing prior distribution, encoding properties such as sparsity or non-negativity. The central role of posterior log-concavity in Bayesian GLMs is emphasized and related to stability issues in EP. In particular, we use our technique to infer the parameters of a point process model for neuronal spiking data from multiple electrodes, demonstrating significantly superior predictive performance when a sparsity assumption is enforced via a Laplace prior distribution. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Seeger, Matthias and Gerwinn, Sebastian and Bethge, Matthias},
doi = {10.1007/978-3-540-74958-5_29},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seeger, Gerwinn, Bethge - 2007 - Bayesian inference for sparse generalized linear models.pdf:pdf},
isbn = {9783540749578},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {298--309},
title = {{Bayesian inference for sparse generalized linear models}},
volume = {4701 LNAI},
year = {2007}
}
@article{Yang2011,
abstract = {Sparse representation based classification has led to interesting image recognition results, while the dictionary used for sparse coding plays a key role in it. This paper presents a novel dictionary learning (DL) method to improve the pattern classification performance. Based on the Fisher discrimination criterion, a structured dictionary, whose dictionary atoms have correspondence to the class labels, is learned so that the reconstruction error after sparse coding can be used for pattern classification. Meanwhile, the Fisher discrimination criterion is imposed on the coding coefficients so that they have small within-class scatter but big between-class scatter. A new classification scheme associated with the proposed Fisher discrimination DL (FDDL) method is then presented by using both the discriminative information in the reconstruction error and sparse coding coefficients. The proposed FDDL is extensively evaluated on benchmark image databases in comparison with existing sparse representation and DL based classification methods. {\textcopyright} 2011 IEEE.},
author = {Yang, Meng and Zhang, Lei and Feng, Xiangchu and Zhang, David},
doi = {10.1109/ICCV.2011.6126286},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2011 - Fisher Discrimination Dictionary Learning for sparse representation.pdf:pdf},
isbn = {9781457711015},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {543--550},
publisher = {IEEE},
title = {{Fisher Discrimination Dictionary Learning for sparse representation}},
year = {2011}
}
@article{Li2019,
abstract = {Recently, multi-view representation learning has become a rapidly growing direction in machine learning and data mining areas. This paper introduces two categories for multi-view representation learning: multi-view representation alignment and multi-view representation fusion. Consequently, we first review the representative methods and theories of multi-view representation learning based on the perspective of alignment, such as correlation-based alignment. Representative examples are canonical correlation analysis (CCA) and its several extensions. Then, from the perspective of representation fusion, we investigate the advancement of multi-view representation learning that ranges from generative methods including multi-modal topic learning, multi-view sparse coding, and multi-view latent space Markov networks, to neural network-based methods including multi-modal autoencoders, multi-view convolutional neural networks, and multi-modal recurrent neural networks. Further, we also investigate several important applications of multi-view representation learning. Overall, this survey aims to provide an insightful overview of theoretical foundation and state-of-the-art developments in the field of multi-view representation learning and to help researchers find the most appropriate tools for particular applications.},
archivePrefix = {arXiv},
arxivId = {1610.01206},
author = {Li, Yingming and Yang, Ming and Zhang, Zhongfei},
doi = {10.1109/TKDE.2018.2872063},
eprint = {1610.01206},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Yang, Zhang - 2019 - A Survey of Multi-View Representation Learning.pdf:pdf},
issn = {15582191},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Multi-view representation learning,canonical correlation analysis,multi-view deep learning},
number = {10},
pages = {1863--1883},
publisher = {IEEE},
title = {{A Survey of Multi-View Representation Learning}},
volume = {31},
year = {2019}
}
@article{Fey2019,
abstract = {We introduce PyTorch Geometric, a library for deep learning on irregularly structured input data such as graphs, point clouds and manifolds, built upon PyTorch. In addition to general graph data structures and processing methods, it contains a variety of recently published methods from the domains of relational learning and 3D data processing. PyTorch Geometric achieves high data throughput by leveraging sparse GPU acceleration, by providing dedicated CUDA kernels and by introducing efficient mini-batch handling for input examples of different size. In this work, we present the library in detail and perform a comprehensive comparative study of the implemented methods in homogeneous evaluation scenarios.},
archivePrefix = {arXiv},
arxivId = {1903.02428},
author = {Fey, Matthias and Lenssen, Jan E.},
eprint = {1903.02428},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fey, Lenssen - 2019 - Fast graph representation learning with pytorch geometric.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {1},
pages = {1--9},
title = {{Fast graph representation learning with pytorch geometric}},
year = {2019}
}
@article{Bengio2007,
author = {Bengio, Yoshua and Delalleau, Olivier and Roux, Nicolas Le and Larochelle, Hugo and Lamblin, Pascal and Popovici, Dan and Courville, Aaron and Simard, Clarence and Louradour, Jerome},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio et al. - 2007 - Deep Architectures for Baby AI Summary for Day 1.pdf:pdf},
title = {{Deep Architectures for Baby AI Summary for Day 1}},
year = {2007}
}
@article{Hui2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2007.12770v1},
author = {Hui, David Yu-tung and Chevalier-boisvert, Maxime and Bahdanau, Dzmitry and Bengio, Yoshua},
eprint = {arXiv:2007.12770v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hui et al. - 2020 - BabyAI 1.1.pdf:pdf},
pages = {1--9},
title = {{BabyAI 1.1}},
volume = {1},
year = {2020}
}
@article{Lahlou2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1810.08272v4},
author = {Lahlou, Salem},
eprint = {arXiv:1810.08272v4},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lahlou - 2019 - Baby AI a platform to study the sample-efficiency of grounded language learning.pdf:pdf},
pages = {1--19},
title = {{Baby AI: a platform to study the sample-efficiency of grounded language learning}},
year = {2019}
}
@article{Qu2019,
author = {Qu, Meng and Bengio, Yoshua and Tang, Jian},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qu, Bengio, Tang - 2019 - GMNN Graph Markov Neural Networks.pdf:pdf},
title = {{GMNN : Graph Markov Neural Networks}},
year = {2019}
}
@article{Didolkar2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2103.01937v1},
author = {Didolkar, Aniket and Goyal, Anirudh and Rosemary, Nan and Charles, Ke and Philippe, Blundell and Heess, Nicolas and Mozer, Michael and Bengio, Yoshua},
eprint = {arXiv:2103.01937v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Didolkar et al. - Unknown - Neural Production Systems.pdf:pdf},
title = {{Neural Production Systems}},
year = {2021}
}
@article{Fu2013,
author = {Fu, Fei and Zhou, Qing},
doi = {10.1080/01621459.2012.754359},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu, Zhou - 2013 - Learning Sparse Causal Gaussian Networks With Experimental Intervention Regularization and Coordinate Descent With Ex.pdf:pdf},
keywords = {adaptive lasso,experimental data,l 1 regularization,penalized likelihood,structure learning},
title = {{Learning Sparse Causal Gaussian Networks With Experimental Intervention : Regularization and Coordinate Descent With Experimental Intervention : Regularization}},
volume = {1459},
year = {2013}
}
@article{Priol2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2005.09136v2},
author = {Priol, R{\'{e}}mi Le and Lacoste-julien, Simon},
eprint = {arXiv:2005.09136v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Priol, Lacoste-julien - 2021 - An Analysis of the Adaptation Speed of Causal Models.pdf:pdf},
title = {{An Analysis of the Adaptation Speed of Causal Models}},
volume = {130},
year = {2021}
}
@article{Bengio2020,
archivePrefix = {arXiv},
arxivId = {arXiv:1811.06128v2},
author = {Bengio, Yoshua and Lodi, Andrea and Prouvost, Antoine},
eprint = {arXiv:1811.06128v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio, Lodi, Prouvost - Unknown - Machine Learning for Combinatorial Optimization a Methodological Tour d ' Horizon ∗.pdf:pdf},
pages = {1--47},
title = {{Machine Learning for Combinatorial Optimization : a Methodological Tour d ' Horizon ∗}},
year = {2020}
}
@article{Russin2020,
author = {Russin, Jacob and Reilly, Randall C O},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russin, Reilly - 2020 - Deep Learning needs a prefrontal cortex.pdf:pdf},
number = {Iclr},
pages = {1--11},
title = {{Deep Learning needs a prefrontal cortex}},
year = {2020}
}
@article{Kim2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2008.11783v1},
author = {Kim, Taesup and Kim, Sungwoong and Bengio, Yoshua and Brain, Kakao},
eprint = {arXiv:2008.11783v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - Unknown - Visual Concept Reasoning Networks.pdf:pdf},
pages = {1--13},
title = {{Visual Concept Reasoning Networks}},
year = {2020}
}
@article{Lamb2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2010.08012v1},
author = {Lamb, Alex and Mozer, Michael and Beaudoin, Philippe},
eprint = {arXiv:2010.08012v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lamb, Mozer, Beaudoin - Unknown - Neural Function Modules with Sparse Arguments A Dynamic Approach to Integrating Information across La.pdf:pdf},
title = {{Neural Function Modules with Sparse Arguments : A Dynamic Approach to Integrating Information across Layers}},
year = {2020}
}
@article{Goyal2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2011.15091v3},
author = {Goyal, Anirudh},
eprint = {arXiv:2011.15091v3},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goyal - Unknown - Inductive Biases for Deep Learning of Higher-Level Cognition.pdf:pdf},
pages = {1--42},
title = {{Inductive Biases for Deep Learning of Higher-Level Cognition}},
year = {2021}
}
@article{Kim2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1910.00775v1},
author = {Kim, Taesup and Ahn, Sungjin and Bengio, Yoshua},
eprint = {arXiv:1910.00775v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Ahn, Bengio - Unknown - Variational Temporal Abstraction(2).pdf:pdf},
pages = {1--14},
title = {{Variational Temporal Abstraction}},
year = {2019}
}
@article{Lamb2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2103.00336v1},
author = {Lamb, Alex and He, Di and Goyal, Anirudh and Ke, Guolin and Mirco, Chien-feng Liao and Yoshua, Ravanelli},
eprint = {arXiv:2103.00336v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lamb et al. - Unknown - Transformers with Competitive Ensembles of Independent Mechanisms.pdf:pdf},
title = {{Transformers with Competitive Ensembles of Independent Mechanisms}},
year = {2021}
}
@article{Goyal2017,
archivePrefix = {arXiv},
arxivId = {arXiv:2103.01197v1},
author = {Goyal, Anirudh and Didolkar, Aniket and Lamb, Alex and Badola, Kartikeya and Rosemary, Nan and Nasim, Ke and Binas, Jonathan and Blundell, Charles and Mozer, Michael and Bengio, Yoshua},
eprint = {arXiv:2103.01197v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goyal et al. - 2017 - Coordination Among Neural Modules Through a Shared Global Workspace.pdf:pdf},
title = {{Coordination Among Neural Modules Through a Shared Global Workspace}},
year = {2017}
}
@article{Deleu2015,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.03869v1},
author = {Deleu, Tristan and Bengio, Yoshua},
eprint = {arXiv:2102.03869v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deleu, Bengio - 2015 - Structured Sparsity Inducing Adaptive Optimizers for Deep Learning.pdf:pdf},
title = {{Structured Sparsity Inducing Adaptive Optimizers for Deep Learning}},
year = {2015}
}
@article{Ma2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2001.04025v1},
author = {Ma, Chen and Ashley, Dylan R and Wen, Junfeng and Bengio, Yoshua},
eprint = {arXiv:2001.04025v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - Unknown - Transfer Reinforcement Learning.pdf:pdf},
pages = {1--18},
title = {{Transfer Reinforcement Learning}},
year = {2020}
}
@article{Serban2020,
author = {Serban, Iulian Vlad and Pieper, Michael and Pineau, Joelle},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serban, Pieper, Pineau - 2020 - The Bottleneck Simulator A Model-Based Deep Reinforcement Learning Approach.pdf:pdf},
pages = {571--612},
title = {{The Bottleneck Simulator : A Model-Based Deep Reinforcement Learning Approach}},
volume = {69},
year = {2020}
}
@article{Arpit2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2002.09046v1},
author = {Arpit, Devansh and Wang, Huan and Xiong, Caiming and Socher, Richard and Bengio, Yoshua},
eprint = {arXiv:2002.09046v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arpit et al. - Unknown - Representation Learning.pdf:pdf},
title = {{Neural Bayes: A Generic Parameterization Method for Unsupervised Representation Learning}},
year = {2020}
}
@article{Adegbege2021,
author = {Adegbege, Ambrose A and Member, Senior and Kim, Mun Y},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adegbege, Member, Kim - 2021 - Saddle-Point Convergence of Constrained Primal-Dual Dynamics.pdf:pdf},
number = {4},
pages = {1357--1362},
title = {{Saddle-Point Convergence of Constrained Primal-Dual Dynamics}},
volume = {5},
year = {2021}
}
@article{Ayoub2020,
author = {Ayoub, Alex and Jia, Zeyu and Szepesv, Csaba and Lin, Wang},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ayoub et al. - 2020 - Model-Based Reinforcement Learning with Value-Targeted Regression.pdf:pdf},
title = {{Model-Based Reinforcement Learning with Value-Targeted Regression}},
year = {2020}
}
@article{Rajeswaran2020,
abstract = {Model-based reinforcement learning (MBRL) has recently gained immense interest due to its potential for sample efficiency and ability to incorporate off-policy data. However, designing stable and efficient MBRL algorithms using rich function approximators have remained challenging. To help expose the practical challenges in MBRL and simplify algorithm design from the lens of abstraction, we develop a new framework that casts MBRL as a game between: (1) a policy player, which attempts to maximize rewards under the learned model; (2) a model player, which attempts to fit the real-world data collected by the policy player. For algorithm development, we construct a Stackelberg game between the two players, and show that it can be solved with approximate bi-level optimization. This gives rise to two natural families of algorithms for MBRL based on which player is chosen as the leader in the Stackelberg game. Together, they encapsulate, unify, and generalize many previous MBRL algorithms. Furthermore, our framework is consistent with and provides a clear basis for heuristics known to be important in practice from prior works. Finally, through experiments we validate that our proposed algorithms are highly sample efficient, match the asymptotic performance of model-free policy gradient, and scale gracefully to high-dimensional tasks like dexterous hand manipulation.},
archivePrefix = {arXiv},
arxivId = {2004.07804},
author = {Rajeswaran, Aravind and Mordatch, Igor and Kumar, Vikash},
eprint = {2004.07804},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rajeswaran, Mordatch, Kumar - 2020 - A game theoretic framework for model based reinforcement learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{A game theoretic framework for model based reinforcement learning}},
year = {2020}
}
@article{Kepner2019,
abstract = {—The MIT/IEEE/Amazon GraphChallenge.org encourages community approaches to developing new solutions for analyzing graphs and sparse data. Sparse AI analytics present unique scalability difficulties. The proposed Sparse Deep Neural Network (DNN) Challenge draws upon prior challenges from machine learning, high performance computing, and visual analytics to create a challenge that is reflective of emerging sparse AI systems. The Sparse DNN Challenge is based on a mathematically well-defined DNN inference computation and can be implemented in any programming environment. Sparse DNN inference is amenable to both vertex-centric implementations and array-based implementations (e.g., using the GraphBLAS.org standard). The computations are simple enough that performance predictions can be made based on simple computing hardware models. The input data sets are derived from the MNIST handwritten letters. The surrounding I/O and verification provide the context for each sparse DNN inference that allows rigorous definition of both the input and the output. Furthermore, since the proposed sparse DNN challenge is scalable in both problem size and hardware, it can be used to measure and quantitatively compare a wide range of present day and future systems. Reference implementations have been implemented and their serial and parallel performance have been measured. Specifications, data, and software are publicly available at GraphChallenge.org.},
author = {Kepner, Jeremy and Alford, Simon and Gadepally, Vijay and Jones, Michael and Milechin, Lauren and Robinett, Ryan and Samsi, Sid},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kepner et al. - 2019 - Sparse Deep Neural Network Graph Challenge.pdf:pdf},
isbn = {9781728150208},
issn = {23318422},
journal = {arXiv},
publisher = {IEEE},
title = {{Sparse Deep Neural Network Graph Challenge}},
year = {2019}
}
@article{Zhang2018,
archivePrefix = {arXiv},
arxivId = {arXiv:2011.12491v2},
author = {Zhang, Lunjun and Yang, Ge and Stadie, Bradly},
eprint = {arXiv:2011.12491v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Yang, Stadie - 2018 - World Model as a Graph.pdf:pdf},
title = {{World Model as a Graph :}},
year = {2018}
}
@article{Martic2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2103.03938v1},
author = {Martic, Grau-moya Miljan and Genewein, Tim and Mcgrath, Tom},
eprint = {arXiv:2103.03938v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martic, Genewein, Mcgrath - 2020 - Causal Analysis of Agent Behavior for AI Safety.pdf:pdf},
keywords = {agent,agent analysis,ai safety,allow for investigating and,black-box analysis,causal reasoning,nisms that underlie an,s behavior,such methodologies,uncovering the causal mecha-},
title = {{Causal Analysis of Agent Behavior for AI Safety}},
year = {2020}
}
@article{Ollivier2019,
author = {Ollivier, Carl-johann Simon-gabriel Yann and Sch{\"{o}}lkopf, Bernhard and Bottou, L{\'{e}}on},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ollivier, Sch{\"{o}}lkopf, Bottou - 2019 - First-order Adversarial Vulnerability of Neural Networks and Input Dimension.pdf:pdf},
title = {{First-order Adversarial Vulnerability of Neural Networks and Input Dimension}},
year = {2019}
}
@article{Simon-Gabriel2018,
author = {Simon-Gabriel, Carl-ohann},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2018 - Distribution-Dissimilarities in Machine Learning(2).pdf:pdf},
title = {{Distribution-Dissimilarities in Machine Learning}},
year = {2018}
}
@article{Sch2015,
author = {Sch, Bernhard and Hogg, David W and Janzing, Dominik and Mpg, Tuebingen and Peters, Jonas and Peters, Jonas and Mpg, Tuebingen},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sch et al. - 2015 - Removing systematic errors for exoplanet search via latent causes.pdf:pdf},
title = {{Removing systematic errors for exoplanet search via latent causes}},
volume = {37},
year = {2015}
}
@article{Mitchell2020,
archivePrefix = {arXiv},
arxivId = {2102.10717},
author = {Mitchell, Melanie},
doi = {10.1162/isal_a_00354},
eprint = {2102.10717},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitchell - 2020 - Conceptual Abstraction and Analogy in Artificial Intelligence.pdf:pdf},
pages = {7--7},
title = {{Conceptual Abstraction and Analogy in Artificial Intelligence}},
year = {2020}
}
@article{Pend2021,
author = {Pend, Hao and Pappas, Nikolaos and Yogatama, Dani and Schwartz, Roy and Smith, Noah and Kong, Lingpeng},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Transformers, Transformer - 2021 - Andom eature ttention.pdf:pdf},
pages = {1--19},
title = {{Random feature attention}},
year = {2021}
}
@article{Jia2021,
abstract = {Pre-trained representations are becoming crucial for many NLP and perception tasks. While representation learning in NLP has transitioned to training on raw text without human annotations, visual and vision-language representations still rely heavily on curated training datasets that are expensive or require expert knowledge. For vision applications, representations are mostly learned using datasets with explicit class labels such as ImageNet or OpenImages. For vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all involve a non-trivial data collection (and cleaning) process. This costly curation process limits the size of datasets and hence hinders the scaling of trained models. In this paper, we leverage a noisy dataset of over one billion image alt-text pairs, obtained without expensive filtering or post-processing steps in the Conceptual Captions dataset. A simple dual-encoder architecture learns to align visual and language representations of the image and text pairs using a contrastive loss. We show that the scale of our corpus can make up for its noise and leads to state-of-the-art representations even with such a simple learning scheme. Our visual representation achieves strong performance when transferred to classification tasks such as ImageNet and VTAB. The aligned visual and language representations also set new state-of-the-art results on Flickr30K and MSCOCO benchmarks, even when compared with more sophisticated cross-attention models. The representations also enable cross-modality search with complex text and text + image queries.},
archivePrefix = {arXiv},
arxivId = {2102.05918},
author = {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V. and Sung, Yunhsuan and Li, Zhen and Duerig, Tom},
eprint = {2102.05918},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - 2021 - Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision.pdf:pdf},
title = {{Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision}},
url = {http://arxiv.org/abs/2102.05918},
year = {2021}
}
@article{Learning2014,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.10543v1},
author = {Learning, Contrastive and Need, You},
eprint = {arXiv:2102.10543v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Learning, Need - 2014 - Do Generative Models Know Disentanglement Contrastive Learning is All You Need.pdf:pdf},
title = {{Do Generative Models Know Disentanglement? Contrastive Learning is All You Need}},
year = {2014}
}
@article{Scholkopf2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.11107v1},
author = {Sch{\"{o}}lkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal},
eprint = {arXiv:2102.11107v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sch{\"{o}}lkopf et al. - Unknown - Towards Causal Representation Learning.pdf:pdf},
pages = {1--24},
title = {{Towards Causal Representation Learning}},
year = {2021}
}
@article{Ibrahim2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.05623v1},
author = {Ibrahim, Mark},
eprint = {arXiv:2102.05623v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ibrahim - 2020 - Addressing the topological defects of disentanglement via distributed operators.pdf:pdf},
pages = {1--46},
title = {{Addressing the topological defects of disentanglement via distributed operators}},
year = {2020}
}
@article{Le2021,
author = {Le, Lynn and Ambrogioni, Luca and Seeliger, Katja and G{\"{u}}{\c{c}}l{\"{u}}t{\"{u}}rk, Yağmur and Van, Marcel and G{\"{u}}{\c{c}}l{\"{u}}, Umut},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le et al. - 2021 - Brain2Pix Fully convolutional naturalistic video reconstruction from brain activity.pdf:pdf},
pages = {1--15},
title = {{Brain2Pix : Fully convolutional naturalistic video reconstruction from brain activity}},
year = {2021}
}
@article{Ecoffet2019,
abstract = {A grand challenge in reinforcement learning is intelligent exploration, especially when rewards are sparse or deceptive. Two Atari games serve as benchmarks for such hard-exploration domains: Montezuma's Revenge and Pitfall. On both games, current RL algorithms perform poorly, even those with intrinsic motivation, which is the dominant method to encourage exploration and improve performance on hard-exploration domains. To address this shortfall, we introduce a new algorithm called Go-Explore. It exploits the following principles: (1) remember states that have previously been visited, (2) first return to a promising state (without exploration), then explore from it, and (3) solve simulated environments through exploiting any available means (including by introducing determinism), then robustify (create a policy that can reliably perform the solution) via imitation learning. The combined effect of these principles generates dramatic performance improvements on hard-exploration problems. On Montezuma's Revenge, without being provided any domain knowledge, Go-Explore scores over 43,000 points, almost 4 times the previous state of the art. Go-Explore can also easily harness human-provided domain knowledge, and when augmented with it Go-Explore scores a mean of over 650,000 points on Montezuma's Revenge. Its max performance of 18 million surpasses the human world record by an order of magnitude, thus meeting even the strictest definition of “superhuman” performance. On Pitfall, Go-Explore with domain knowledge is the first algorithm to score above zero. Its mean performance of almost 60,000 points also exceeds expert human performance. Because Go-Explore can produce many high-performing demonstrations automatically and cheaply, it also outperforms previous imitation learning work in which the solution was provided in the form of a human demonstration. Go-Explore opens up many new research directions into improving it and weaving its insights into current RL algorithms. It may also enable progress on previously unsolvable hard-exploration problems in a variety of domains, especially the many that often harness a simulator during training (e.g. robotics).},
archivePrefix = {arXiv},
arxivId = {1901.10995},
author = {Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
eprint = {1901.10995},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ecoffet et al. - 2019 - Go-Explore A new approach for hard-exploration problems.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--37},
title = {{Go-Explore: A new approach for hard-exploration problems}},
year = {2019}
}
@article{Vignac2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2006.15107v3},
author = {Vignac, Cl{\'{e}}ment and Loukas, Andreas and Frossard, Pascal},
eprint = {arXiv:2006.15107v3},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vignac, Loukas, Frossard - 2020 - Building powerful and equivariant graph neural networks with structural message-passing arXiv 2006 ..pdf:pdf},
number = {NeurIPS},
title = {{Building powerful and equivariant graph neural networks with structural message-passing arXiv : 2006 . 15107v3 [ cs . LG ] 23 Oct 2020}},
year = {2020}
}
@article{Wang2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.12122v1},
author = {Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
eprint = {arXiv:2102.12122v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - Unknown - Pyramid Vision Transformer A Versatile Backbone for Dense Prediction without Convolutions.pdf:pdf},
title = {{Pyramid Vision Transformer : A Versatile Backbone for Dense Prediction without Convolutions}},
year = {2021}
}
@article{Yarats2016,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.11271v1},
author = {Yarats, Denis and Fergus, Rob and Lazaric, Alessandro and Pinto, Lerrel},
eprint = {arXiv:2102.11271v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yarats et al. - 2016 - Reinforcement Learning with Prototypical Representations.pdf:pdf},
title = {{Reinforcement Learning with Prototypical Representations}},
year = {2016}
}
@article{Hoefler2008,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.00554v1},
author = {Hoefler, Torsten and Alistarh, D A N and Ben-nun, T A L and Dryden, Nikoli and Peste, Alexandra},
eprint = {arXiv:2102.00554v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoefler et al. - 2008 - Sparsity in deep learning pruning and growth for efficient inference and training in neural networks.pdf:pdf},
title = {{Sparsity in deep learning: pruning and growth for efficient inference and training in neural networks}},
year = {2008}
}
@article{Zimmermann2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.08850v1},
author = {Zimmermann, Roland S and Sharma, Yash and Schneider, Steffen and Bethge, Matthias and Brendel, Wieland},
eprint = {arXiv:2102.08850v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zimmermann et al. - 2020 - Contrastive Learning Inverts the Data Generating Process.pdf:pdf},
title = {{Contrastive Learning Inverts the Data Generating Process}},
year = {2020}
}
@article{Xiong2021,
abstract = {Transformers have emerged as a powerful tool for a broad range of natural language processing tasks. A key component that drives the impressive performance of Transformers is the self-attention mechanism that encodes the influence or dependence of other tokens on each specific token. While beneficial, the quadratic complexity of self-attention on the input sequence length has limited its application to longer sequences -- a topic being actively studied in the community. To address this limitation, we propose Nystr\"omformer -- a model that exhibits favorable scalability as a function of sequence length. Our idea is based on adapting the Nystr\"om method to approximate standard self-attention with $O(n)$ complexity. The scalability of Nystr\"omformer enables application to longer sequences with thousands of tokens. We perform evaluations on multiple downstream tasks on the GLUE benchmark and IMDB reviews with standard sequence length, and find that our Nystr\"omformer performs comparably, or in a few cases, even slightly better, than standard Transformer. Our code is at https://github.com/mlpen/Nystromformer.},
archivePrefix = {arXiv},
arxivId = {2102.03902},
author = {Xiong, Yunyang and Zeng, Zhanpeng and Chakraborty, Rudrasis and Tan, Mingxing and Fung, Glenn and Li, Yin and Singh, Vikas},
eprint = {2102.03902},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiong et al. - 2021 - Nystromformer A Nystrom-Based Algorithm for Approximating Self-Attention.pdf:pdf},
title = {{Nystromformer: A Nystrom-Based Algorithm for Approximating Self-Attention}},
url = {http://arxiv.org/abs/2102.03902},
year = {2021}
}
@article{Ramabathiran2021,
abstract = {We introduce a class of Sparse, Physics-based, and Interpretable Neural Networks (SPINN) for solving ordinary and partial differential equations. By reinterpreting a traditional meshless representation of solutions of PDEs as a special sparse deep neural network, we develop a class of sparse neural network architectures that are interpretable. The SPINN model we propose here serves as a seamless bridge between two extreme modeling tools for PDEs, dense neural network based methods and traditional mesh-based and mesh-free numerical methods, thereby providing a novel means to develop a new class of hybrid algorithms that build on the best of both these viewpoints. A unique feature of the SPINN model we propose that distinguishes it from other neural network based approximations proposed earlier is that our method is both fully interpretable and sparse in the sense that it has much fewer connections than a dense neural network of the same size. Further, we demonstrate that Fourier series representations can be expressed as a special class of SPINN and propose generalized neural network analogues of Fourier representations. We illustrate the utility of the proposed method with a variety of examples involving ordinary differential equations, elliptic, parabolic, hyperbolic and nonlinear partial differential equations, and an example in fluid dynamics.},
archivePrefix = {arXiv},
arxivId = {2102.13037},
author = {Ramabathiran, Amuthan A. and Ramachandran, Prabhu},
eprint = {2102.13037},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramabathiran, Ramachandran - 2021 - SPINN Sparse, Physics-based, and Interpretable Neural Networks for PDEs.pdf:pdf},
title = {{SPINN: Sparse, Physics-based, and Interpretable Neural Networks for PDEs}},
url = {http://arxiv.org/abs/2102.13037},
year = {2021}
}
@article{Chari2020,
abstract = {Explainability has been an important goal since the early days of Artificial Intelligence. Several approaches for producing explanations have been developed. However, many of these approaches were tightly coupled with the capabilities of the artificial intelligence systems at the time. With the proliferation of AI-enabled systems in sometimes critical settings, there is a need for them to be explainable to end-users and decision-makers. We present a historical overview of explainable artificial intelligence systems, with a focus on knowledge-enabled systems, spanning the expert systems, cognitive assistants, semantic applications, and machine learning domains. Additionally, borrowing from the strengths of past approaches and identifying gaps needed to make explanations user- and contextfocused, we propose new definitions for explanations and explainable knowledgeenabled systems.},
archivePrefix = {arXiv},
arxivId = {2003.07520},
author = {Chari, Shruthi and Gruen, Daniel M. and Seneviratne, Oshani and McGuinness, Deborah L.},
eprint = {2003.07520},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chari et al. - 2020 - Foundations of explainable knowledge-enabled systems.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Explainable Knowledge-Enabled Systems,Historical Evolution,KG4XAI},
number = {March},
title = {{Foundations of explainable knowledge-enabled systems}},
year = {2020}
}
@article{Nagarajan2020,
abstract = {Empirical studies suggest that machine learning models often rely on features, such as the background, that may be spuriously correlated with the label only during training time, resulting in poor accuracy during test-time. In this work, we identify the fundamental factors that give rise to this behavior, by explaining why models fail this way {\em even} in easy-to-learn tasks where one would expect these models to succeed. In particular, through a theoretical study of gradient-descent-trained linear classifiers on some easy-to-learn tasks, we uncover two complementary failure modes. These modes arise from how spurious correlations induce two kinds of skews in the data: one geometric in nature, and another, statistical in nature. Finally, we construct natural modifications of image classification datasets to understand when these failure modes can arise in practice. We also design experiments to isolate the two failure modes when training modern neural networks on these datasets.},
archivePrefix = {arXiv},
arxivId = {2010.15775},
author = {Nagarajan, Vaishnavh and Andreassen, Anders and Neyshabur, Behnam},
eprint = {2010.15775},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nagarajan, Andreassen, Neyshabur - 2020 - Understanding the Failure Modes of Out-of-Distribution Generalization.pdf:pdf},
pages = {1--31},
title = {{Understanding the Failure Modes of Out-of-Distribution Generalization}},
url = {http://arxiv.org/abs/2010.15775},
year = {2020}
}
@article{Lillicrap2019,
archivePrefix = {arXiv},
arxivId = {arXiv:2010.02193v2},
author = {Lillicrap, Timothy and Ba, Jimmy},
eprint = {arXiv:2010.02193v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lillicrap, Ba - 2019 - Mastering Atari with discrete world models.pdf:pdf},
pages = {1--24},
title = {{Mastering Atari with discrete world models}},
year = {2019}
}
@article{DeVries2021,
abstract = {MuZero, a model-based reinforcement learning algorithm that uses a value equivalent dynamics model, achieved state-of-the-art performance in Chess, Shogi and the game of Go. In contrast to standard forward dynamics models that predict a full next state, value equivalent models are trained to predict a future value, thereby emphasizing value relevant information in the representations. While value equivalent models have shown strong empirical success, there is no research yet that visualizes and investigates what types of representations these models actually learn. Therefore, in this paper we visualize the latent representation of MuZero agents. We find that action trajectories may diverge between observation embeddings and internal state transition dynamics, which could lead to instability during planning. Based on this insight, we propose two regularization techniques to stabilize MuZero's performance. Additionally, we provide an open-source implementation of MuZero along with an interactive visualizer of learned representations, which may aid further investigation of value equivalent algorithms.},
archivePrefix = {arXiv},
arxivId = {2102.12924},
author = {de Vries, Joery A. and Voskuil, Ken S. and Moerland, Thomas M. and Plaat, Aske},
eprint = {2102.12924},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Vries et al. - 2021 - Visualizing MuZero Models.pdf:pdf},
number = {Icml},
title = {{Visualizing MuZero Models}},
url = {http://arxiv.org/abs/2102.12924},
year = {2021}
}
@article{Biehl2021,
author = {Biehl, Martin and Pollock, Felix A},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biehl, Pollock - 2021 - A Technical Critique of Some Parts of the Free Energy Principle.pdf:pdf},
keywords = {free energy principle,markov blanket,stochastic differential equations},
pages = {1--24},
title = {{A Technical Critique of Some Parts of the Free Energy Principle}},
year = {2021}
}
@article{Nomer2020,
abstract = {This paper introduces a heuristic solver based on neural networks and deep learning for the knapsack problem. The solver is inspired by mechanisms and strategies used by both algorithmic solvers and humans. The neural model of the solver is based on introducing several biases in the architecture. We introduce a stored memory of vectors that holds up items representations and their relationship to the capacity of the knapsack and a module that allows the solver to access all the previous outputs it generated. The solver is trained and tested on synthetic datasets that represent a variety of instance types with different complexities. The solver neural model capabilities to generalize were tested on instances with up to 200 items, the model succeed to obtain near optimal solutions better than the greedy algorithm for instances in which there exists a correlation between items values and weights. The results also show that the capacity of the knapsack has a role in learning useful representations for each item in an instance and for the instance itself. Although the proposed solver may be not superior to other solvers, the results described here are insights for how the connection between combinatorial optimization, machine learning, and cognitive science could serve a great purpose in the operation research field. The goal of this work is not to design a state of the art solver, rather it full-fills some of the holes in the recent line of research that incorporates learning in combinatorial optimization problems.},
author = {Nomer, Hazem A.A. and Alnowibet, Khalid Abdulaziz and Elsayed, Ashraf and Mohamed, Ali Wagdy},
doi = {10.1109/ACCESS.2020.3044005},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nomer et al. - 2020 - Neural Knapsack A Neural Network Based Solver for the Knapsack Problem.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Knapsack,combinatorial optimization,machine learning,neural networks},
pages = {224200--224210},
title = {{Neural Knapsack: A Neural Network Based Solver for the Knapsack Problem}},
volume = {8},
year = {2020}
}
@article{Yogatama2021,
abstract = {We present a language model that combines a large parametric neural network (i.e., a transformer) with a non-parametric episodic memory component in an integrated architecture. Our model uses extended short-term context by caching local hidden states -- similar to transformer-XL -- and global long-term memory by retrieving a set of nearest neighbor tokens at each timestep. We design a gating function to adaptively combine multiple information sources to make a prediction. This mechanism allows the model to use either local context, short-term memory, or long-term memory (or any combination of them) on an ad hoc basis depending on the context. Experiments on word-based and character-based language modeling datasets demonstrate the efficacy of our proposed method compared to strong baselines.},
archivePrefix = {arXiv},
arxivId = {2102.02557},
author = {Yogatama, Dani and D'Autume, Cyprien de Masson and Kong, Lingpeng},
eprint = {2102.02557},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yogatama, d'Autume, Kong - 2021 - Adaptive Semiparametric Language Models.pdf:pdf},
title = {{Adaptive Semiparametric Language Models}},
url = {http://arxiv.org/abs/2102.02557},
year = {2021}
}
@article{Hinton2021,
archivePrefix = {arXiv},
arxivId = {arXiv:2102.12627v1},
author = {Hinton, Geoffrey},
eprint = {arXiv:2102.12627v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton - 2021 - How to represent part-whole hierarchies in a neural network (Presentation, video and transcript).pdf:pdf},
pages = {18},
title = {{How to represent part-whole hierarchies in a neural network (Presentation, video and transcript)}},
year = {2021}
}
@article{Schlag2021,
abstract = {We show the formal equivalence of linearised self-attention mechanisms and fast weight memories from the early '90s. From this observation we infer a memory c Capacity limitation of recent linearised softmax attention variants. With finite memory, a desirable behaviour of fast weight memory models is to manipulate the contents of memory and dynamically interact with it. Inspired by previous work on fast weights, we propose to replace the update rule by an alternative rule yielding such behaviour. We also propose a new kernel function to linearise attention, balancing simplicity and effectiveness. We conduct experiments on synthetic retrieval problems as well as standard machine translation and language modelling tasks which demonstrate the benefits of our methods.},
archivePrefix = {arXiv},
arxivId = {2102.11174},
author = {Schlag, Imanol and Irie, Kazuki and Schmidhuber, J{\"{u}}rgen},
eprint = {2102.11174},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schlag, Irie, Schmidhuber - 2021 - Linear Transformers Are Secretly Fast Weight Memory Systems.pdf:pdf},
title = {{Linear Transformers Are Secretly Fast Weight Memory Systems}},
url = {http://arxiv.org/abs/2102.11174},
year = {2021}
}
@article{Meo2021,
abstract = {Active inference, a theoretical construct inspired by brain processing, is a promising alternative to control artificial agents. However, current methods do not yet scale to high-dimensional inputs in continuous control. Here we present a novel active inference torque controller for industrial arms that maintains the adaptive characteristics of previous proprioceptive approaches but also enables large-scale multimodal integration (e.g., raw images). We extended our previous mathematical formulation by including multimodal state representation learning using a linearly coupled multimodal variational autoencoder. We evaluated our model on a simulated 7DOF Franka Emika Panda robot arm and compared its behavior with a previous active inference baseline and the Panda built-in optimized controller. Results showed improved tracking and control in goal-directed reaching due to the increased representation power, high robustness to noise and adaptability in changes on the environmental conditions and robot parameters without the need to relearn the generative models nor parameters retuning.},
archivePrefix = {arXiv},
arxivId = {2103.04412},
author = {Meo, Cristian and Lanillos, Pablo},
eprint = {2103.04412},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meo, Lanillos - 2021 - Multimodal VAE Active Inference Controller.pdf:pdf},
number = {c},
title = {{Multimodal VAE Active Inference Controller}},
url = {http://arxiv.org/abs/2103.04412},
year = {2021}
}
@article{Krueger2020,
abstract = {Active reinforcement learning (ARL) is a variant on reinforcement learning where the agent does not observe the reward unless it chooses to pay a query cost c > 0. The central question of ARL is how to quantify the long-term value of reward information. Even in multi-armed bandits, computing the value of this information is intractable and we have to rely on heuristics. We propose and evaluate several heuristic approaches for ARL in multi-armed bandits and (tabular) Markov decision processes, and discuss and illustrate some challenging aspects of the ARL problem.},
archivePrefix = {arXiv},
arxivId = {2011.06709},
author = {Krueger, David and Leike, Jan and Evans, Owain and Salvatier, John},
eprint = {2011.06709},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krueger et al. - 2020 - Active reinforcement learning Observing rewards at a cost.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS},
title = {{Active reinforcement learning: Observing rewards at a cost}},
year = {2020}
}
@article{Dieleman2021,
abstract = {Semantically meaningful information content in perceptual signals is usually unevenly distributed. In speech signals for example, there are often many silences, and the speed of pronunciation can vary considerably. In this work, we propose slow autoencoders (SlowAEs) for unsupervised learning of high-level variable-rate discrete representations of sequences, and apply them to speech. We show that the resulting event-based representations automatically grow or shrink depending on the density of salient information in the input signals, while still allowing for faithful signal reconstruction. We develop run-length Transformers (RLTs) for event-based representation modelling and use them to construct language models in the speech domain, which are able to generate grammatical and semantically coherent utterances and continuations.},
archivePrefix = {arXiv},
arxivId = {2103.06089},
author = {Dieleman, Sander and Nash, Charlie and Engel, Jesse and Simonyan, Karen},
eprint = {2103.06089},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dieleman et al. - 2021 - Variable-rate discrete representation learning.pdf:pdf},
title = {{Variable-rate discrete representation learning}},
url = {http://arxiv.org/abs/2103.06089},
year = {2021}
}
@article{Javaloy2021,
abstract = {While multi-task learning (MTL) has been successfully applied in several domains, it still triggers challenges. As a consequence of negative transfer, simultaneously learning several tasks can lead to unexpectedly poor results. A key factor contributing to this undesirable behavior is the problem of conflicting gradients. In this paper, we propose a novel approach for MTL, Rotograd, which homogenizes the gradient directions across all tasks by rotating their shared representation. Our algorithm is formalized as a Stackelberg game, which allows us to provide stability guarantees. Rotograd can be transparently combined with task-weighting approaches (e.g., GradNorm) to mitigate negative transfer, resulting in a robust learning process. Thorough empirical evaluation on several architectures (e.g., ResNet) and datasets (e.g., CIFAR) verifies our theoretical results, and shows that Rotograd outperforms previous approaches. A Pytorch implementation can be found in https://github.com/adrianjav/rotograd .},
archivePrefix = {arXiv},
arxivId = {2103.02631},
author = {Javaloy, Adri{\'{a}}n and Valera, Isabel},
eprint = {2103.02631},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Javaloy, Valera - 2021 - Rotograd Dynamic Gradient Homogenization for Multi-Task Learning.pdf:pdf},
title = {{Rotograd: Dynamic Gradient Homogenization for Multi-Task Learning}},
url = {http://arxiv.org/abs/2103.02631},
year = {2021}
}
@article{Stammer2020,
abstract = {Most explanation methods in deep learning map importance estimates for a model's prediction back to the original input space. These “visual” explanations are often insufficient, as the model's actual concept remains elusive. Moreover, without insights into the model's semantic concept, it is difficult —if not impossible— to intervene on the model's behavior via its explanations, called Explanatory Interactive Learning. Consequently, we propose to intervene on a Neuro-Symbolic scene representation, which allows one to revise the model on the semantic level, e.g. “never focus on the color to make your decision”. We compiled a novel confounded visual scene data set, the CLEVR-Hans data set, capturing complex compositions of different objects. The results of our experiments on CLEVR-Hans demonstrate that our semantic explanations, i.e. compositional explanations at a per-object level, can identify confounders that are not identifiable using “visual” explanations only. More importantly, feedback on this semantic level makes it possible to revise the model from focusing on these confounding factors.},
archivePrefix = {arXiv},
arxivId = {2011.12854},
author = {Stammer, Wolfgang and Schramowski, Patrick and Kersting, Kristian},
eprint = {2011.12854},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stammer, Schramowski, Kersting - 2020 - Right for the right concept Revising neuro-symbolic concepts by interacting with their explanati.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeSy XIL},
title = {{Right for the right concept: Revising neuro-symbolic concepts by interacting with their explanations}},
year = {2020}
}
@article{Sing2017,
author = {Sing, P Olicies U and Nsembles, M Odel E},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sing, Nsembles - 2017 - Learning robust state abstractions for hidden-parameter block MDPs.pdf:pdf},
number = {2},
pages = {1--15},
title = {{Learning robust state abstractions for hidden-parameter block MDPs}},
year = {2017}
}
@article{Viano2020,
abstract = {We study the inverse reinforcement learning (IRL) problem under the transition dynamics mismatch between the expert and the learner. In particular, we consider the Maximum Causal Entropy (MCE) IRL learner model and provide an upper bound on the learner's performance degradation based on the `1-distance between the two transition dynamics of the expert and the learner. Then, by leveraging insights from the Robust RL literature, we propose a robust MCE IRL algorithm, which is a principled approach to help with this mismatch issue. Finally, we empirically demonstrate the stable performance of our algorithm compared to the standard MCE IRL algorithm under transition mismatches in finite MDP problems.},
archivePrefix = {arXiv},
arxivId = {2007.01174},
author = {Viano, Luca and Huang, Yu Ting and Kamalaruban, Parameswaran and Cevher, Volkan},
eprint = {2007.01174},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viano et al. - 2020 - Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch}},
year = {2020}
}
@article{Claassen2013,
abstract = {This paper shows that causal model discovery is not an NP-hard problem, in the sense that for sparse graphs bounded by node degree k the sound and complete causal model can be obtained in worst case order N2(k+2) independence tests, even when latent variables and selection bias may be present. We present a modification of the well-known FCI algorithm that implements the method for an independence oracle, and suggest improvements for sample/real-world data versions. It does not contradict any known hardness results, and does not solve an NP-hard problem: it just proves that sparse causal discovery is perhaps more complicated, but not as hard as learning minimal Bayesian networks.},
archivePrefix = {arXiv},
arxivId = {1309.6824},
author = {Claassen, Tom and Mooij, Joris M. and Heskes, Tom},
eprint = {1309.6824},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Claassen, Mooij, Heskes - 2013 - Learning sparse causal models is not NP-hard.pdf:pdf},
journal = {Uncertainty in Artificial Intelligence - Proceedings of the 29th Conference, UAI 2013},
pages = {172--181},
title = {{Learning sparse causal models is not NP-hard}},
year = {2013}
}
@article{Jonsson2006,
abstract = {We present Variable Influence Structure Analysis, or VISA, an algorithm that performs hierarchical decomposition of factored Markov decision processes. VISA uses a dynamic Bayesian network model of actions, and constructs a causal graph that captures relationships between state variables. In tasks with sparse causal graphs VISA exploits structure by introducing activities that cause the values of state variables to change. The result is a hierarchy of activities that together represent a solution to the original task. VISA performs state abstraction for each activity by ignoring irrelevant state variables and lower-level activities. In addition, we describe an algorithm for constructing compact models of the activities introduced. State abstraction and compact activity models enable VISA to apply efficient algorithms to solve the stand-alone subtask associated with each activity. Experimental results show that the decomposition introduced by VISA can significantly accelerate construction of an optimal, or near-optimal, policy.},
author = {Jonsson, Anders and Barto, Andrew},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jonsson, Barto - 2006 - Causal graph based decomposition of factored MDPs.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Hierarchical decomposition,Markov decision processes,State abstraction},
pages = {2259--2301},
title = {{Causal graph based decomposition of factored MDPs}},
volume = {7},
year = {2006}
}
@article{Liu2018,
abstract = {We investigate sparse representations for control in reinforcement learning. While these representations are widely used in computer vision, their prevalence in reinforcement learning is limited to sparse coding where extracting representations for new data can be computationally intensive. Here, we begin by demonstrating that learning a control policy incrementally with a representation from a standard neural network fails in classic control domains, whereas learning with a representation obtained from a neural network that has sparsity properties enforced is effective. We provide evidence that the reason for this is that the sparse representation provides locality, and so avoids catastrophic interference, and particularly keeps consistent, stable values for bootstrapping. We then discuss how to learn such sparse representations. We explore the idea of Distributional Regularizers, where the activation of hidden nodes is encouraged to match a particular distribution that results in sparse activation across time. We identify a simple but effective way to obtain sparse representations, not afforded by previously proposed strategies, making it more practical for further investigation into sparse representations for reinforcement learning.},
author = {Liu, Vincent and Kumaraswamy, Raksha and Le, Lei and White, Martha},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2018 - The utility of sparse representations for control in reinforcement learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Reinforcement Learning, Representation Learning},
title = {{The utility of sparse representations for control in reinforcement learning}},
year = {2018}
}
@article{Schwartz2020,
author = {Schwartz, Erez and Tessler, Chen and Tennenholtz, Guy},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwartz, Tessler, Tennenholtz - 2020 - Semantic State Representation for Reinforcement Learning.pdf:pdf},
pages = {1--5},
title = {{Semantic State Representation for Reinforcement Learning}},
year = {2020}
}
@article{Kurutach2021,
abstract = {Discrete representations have been key in enabling robots to plan at more abstract levels and solve temporally-extended tasks more efficiently for decades. However, they typically require expert specifications. On the other hand, deep reinforcement learning aims to learn to solve tasks end-to-end, but struggles with long-horizon tasks. In this work, we propose Discrete Object-factorized Representation Planning (DORP), which learns temporally-abstracted discrete representations from exploratory video data in an unsupervised fashion via a mutual information max-imization objective. DORP plans a sequence of abstract states for a low-level model-predictive controller to follow. In our experiments, we show that DORP robustly solves unseen long-horizon tasks. Interestingly, it discovers independent representations per object and binary properties such as a key-and-door.},
author = {Kurutach, Thanard and Russell, Stuart and Abbeel, Pieter},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurutach, Russell, Abbeel - 2021 - Discrete Predictive Representation for Long-Horizon Planning.pdf:pdf},
journal = {ICLR openrevivew},
pages = {1--10},
title = {{Discrete Predictive Representation for Long-Horizon Planning}},
url = {https://openreview.net/forum?id=jcpcUjw7Kzz},
year = {2021}
}
@article{Bakhtin2019,
abstract = {Understanding and reasoning about physics is an important ability of intelligent agents. We develop the PHYRE benchmark for physical reasoning that contains a set of simple classical mechanics puzzles in a 2D physical environment. The benchmark is designed to encourage the development of learning algorithms that are sample-efficient and generalize well across puzzles. We test several modern learning algorithms on PHYRE and find that these algorithms fall short in solving the puzzles efficiently. We expect that PHYRE will encourage the development of novel sample-efficient agents that learn efficient but useful models of physics. For code and to play PHYRE for yourself, please visit https://player.phyre.ai.},
archivePrefix = {arXiv},
arxivId = {1908.05656},
author = {Bakhtin, Anton and van der Maaten, Laurens and Johnson, Justin and Gustafson, Laura and Girshick, Ross},
eprint = {1908.05656},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bakhtin et al. - 2019 - PHYRE A new benchmark for physical reasoning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS},
title = {{PHYRE: A new benchmark for physical reasoning}},
year = {2019}
}
@article{Chen2020,
abstract = {In this paper, we propose an end-to-end graph learning framework, namely Iterative Deep Graph Learning (IDGL), for jointly and iteratively learning graph structure and graph embedding. The key rationale of IDGL is to learn a better graph structure based on better node embeddings, and vice versa (i.e., better node embeddings based on a better graph structure). Our iterative method dynamically stops when the learned graph approaches close enough to the graph optimized for the prediction task. In addition, we cast the graph learning problem as a similarity metric learning problem and leverage adaptive graph regularization for controlling the quality of the learned graph. Finally, combining the anchor-based approximation technique, we further propose a scalable version of IDGL, namely IDGL-ANCH, which significantly reduces the time and space complexity of IDGL without compromising the performance. Our extensive experiments on nine benchmarks show that our proposed IDGL models can consistently outperform or match state-of-the-art baselines. Furthermore, IDGL can be more robust to adversarial graphs and cope with both transductive and inductive learning.},
archivePrefix = {arXiv},
arxivId = {2006.13009},
author = {Chen, Yu and Wu, Lingfei and Zaki, Mohammed J.},
eprint = {2006.13009},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Wu, Zaki - 2020 - Iterative deep graph learning for graph neural networks Better and robust node embeddings.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS},
title = {{Iterative deep graph learning for graph neural networks: Better and robust node embeddings}},
year = {2020}
}
@article{Seth2011,
abstract = {An outstanding challenge in neuroscience is to develop theoretically grounded and practically applicable quantitative measures that are sensitive to conscious level. Such measures should be high for vivid alert conscious wakefulness, and low for unconscious states such as dreamless sleep, coma and general anaesthesia. Here, we describe recent progress in the development of measures of dynamical complexity, in particular causal density and integrated information. These and similar measures capture in different ways the extent to which a system's dynamics are simultaneously differentiated and integrated. Because conscious scenes are distinguished by the same dynamical features, these measures are therefore good candidates for reflecting conscious level. After reviewing the theoretical background, we present new simulation results demonstrating similarities and differences between the measures, and we discuss remaining challenges in the practical application of the measures to empirically obtained data. {\textcopyright} 2011 The Royal Society.},
author = {Seth, Anil K. and Barrett, Adam B. and Barnett, Lionel},
doi = {10.1098/rsta.2011.0079},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seth, Barrett, Barnett - 2011 - Causal density and integrated information as measures of conscious level.pdf:pdf},
issn = {1364503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
keywords = {Causal density,Consciousness,Integrated information},
number = {1952},
pages = {3748--3767},
pmid = {21893526},
title = {{Causal density and integrated information as measures of conscious level}},
volume = {369},
year = {2011}
}
@article{Kaiser2019,
abstract = {Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction - substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of 100k interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games SimPLe outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.},
archivePrefix = {arXiv},
arxivId = {1903.00374},
author = {Kaiser, {\L}ukasz and Babaeizadeh, Mohammad and Mi{\l}os, Piotr and Osi{\'{n}}ski, B{\l}a{\.{z}}ej and Campbell, Roy H. and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and Mohiuddin, Afroz and Sepassi, Ryan and Tucker, George and Michalewski, Henryk},
eprint = {1903.00374},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaiser et al. - 2019 - Model based reinforcement learning for atari.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Model based reinforcement learning for atari}},
year = {2019}
}
@article{Zhang2019b,
abstract = {Model-based reinforcement learning (RL) has proven to be a data efficient approach for learning control tasks but is difficult to utilize in domains with complex observations such as images. In this paper, we present a method for learning representations that are suitable for iterative model-based policy improvement, even when the underlying dynamical system has complex dynamics and image observations, in that these representations are optimized for inferring simple dynamics and cost models given data from the current policy. This enables a model-based RL method based on the linear-quadratic regulator (LQR) to be used for systems with image observations. We evaluate our approach on a range of robotics tasks, including manipulation with a real-world robotic arm directly from images. We find that our method produces substantially better final performance than other model-based RL methods while being significantly more efficient than model-free RL.},
archivePrefix = {arXiv},
arxivId = {1808.09105},
author = {Zhang, Marvin and Vikram, Sharad and Smith, Laura and Abbeel, Pieter and Johnson, Matthew J. and Levine, Sergey},
eprint = {1808.09105},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Solar Deep structured representations for model-based reinforcement learning.pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
pages = {12861--12874},
title = {{Solar: Deep structured representations for model-based reinforcement learning}},
volume = {2019-June},
year = {2019}
}
@article{Franceschi2019,
abstract = {Graph neural networks (GNNs) are a popular class of machine learning models whose major advantage is their ability to incorporate a sparse and discrete dependency structure between data points. Unfortunately, GNNs can only be used when such a graph-structure is available. In practice, however, real-world graphs are often noisy and incomplete or might not be available at all. With this work, we propose to jointly learn the graph structure and the parameters of graph convolutional networks (GCNs) by approximately solving a bilevel program that learns a discrete probability distribution on the edges of the graph. This allows one to apply GCNs not only in scenarios where the given graph is incomplete or corrupted but also in those where a graph is not available. We conduct a series of experiments that analyze the behavior of the proposed method and demonstrate that it outperforms related methods by a significant margin.},
author = {Franceschi, Luca and Niepert, Mathias and Pontil, Massimiliano and He, Xiao},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Franceschi et al. - 2019 - Learning discrete structures for graph neural networks.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Learning discrete structures for graph neural networks}},
year = {2019}
}
@article{Yang2020,
abstract = {Learning disentanglement aims at finding a low dimensional representation which consists of multiple explanatory and generative factors of the observational data. The framework of variational autoencoder (VAE) is commonly used to disentangle independent factors from observations. However, in real scenarios, factors with semantics are not necessarily independent. Instead, there might be an underlying causal structure which renders these factors dependent. We thus propose a new VAE based framework named CausalVAE, which includes a Causal Layer to transform independent exogenous factors into causal endogenous ones that correspond to causally related concepts in data. We further analyze the model identifiabitily, showing that the proposed model learned from observations recovers the true one up to a certain degree. Experiments are conducted on various datasets, including synthetic and real word benchmark CelebA. Results show that the causal representations learned by CausalVAE are semantically interpretable, and their causal relationship as a Directed Acyclic Graph (DAG) is identified with good accuracy. Furthermore, we demonstrate that the proposed CausalVAE model is able to generate counterfactual data through "do-operation" to the causal factors.},
archivePrefix = {arXiv},
arxivId = {2004.08697},
author = {Yang, Mengyue and Liu, Furui and Chen, Zhitang and Shen, Xinwei and Hao, Jianye and Wang, Jun},
eprint = {2004.08697},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2020 - CausalVAE Disentangled Representation Learning via Neural Structural Causal Models.pdf:pdf},
pages = {1--22},
title = {{CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models}},
url = {http://arxiv.org/abs/2004.08697},
year = {2020}
}
@article{Shen2020,
abstract = {This paper proposes a Disentangled gEnerative cAusal Representation (DEAR) learning method. Unlike existing disentanglement methods that enforce independence of the latent variables, we consider the general case where the underlying factors of interests can be causally correlated. We show that previous methods with independent priors fail to disentangle causally correlated factors. Motivated by this finding, we propose a new disentangled learning method called DEAR that enables causal controllable generation and causal representation learning. The key ingredient of this new formulation is to use a structural causal model (SCM) as the prior for a bidirectional generative model. The prior is then trained jointly with a generator and an encoder using a suitable GAN loss. Theoretical justification on the proposed formulation is provided, which guarantees disentangled causal representation learning under appropriate conditions. We conduct extensive experiments on both synthesized and real datasets to demonstrate the effectiveness of DEAR in causal controllable generation, and the benefits of the learned representations for downstream tasks in terms of sample efficiency and distributional robustness.},
archivePrefix = {arXiv},
arxivId = {2010.02637},
author = {Shen, Xinwei and Liu, Furui and Dong, Hanze and Lian, Qing and Chen, Zhitang and Zhang, Tong},
eprint = {2010.02637},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen et al. - 2020 - Disentangled generative causal representation learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--37},
title = {{Disentangled generative causal representation learning}},
year = {2020}
}
@article{Suter2019,
abstract = {The ability to learn disentangled representations that split underlying sources of variation in high dimensional, unstructured data is important for data efficient and robust use of neural networks. While various approaches aiming towards this goal have been proposed in recent times, a commonly accepted definition and validation procedure is missing. We provide a causal perspective on representation learning which covers disentanglement and domain shift robustness as special cases. Our causal framework allows us to introduce a new metric for the quantitative evaluation of deep latent variable models. We show how this metric can be estimated from labeled observational data and further provide an efficient estimation algorithm that scales linearly in the dataset size.},
author = {Suter, Raphael and Miladinovi{\'{c}}, Đorđe and Sch{\"{o}}lkopf, Bernhard and Bauer, Stefan},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Suter et al. - 2019 - Robustly Disentangled Causal Mechanisms Validating Deep Representations for Interventional Robustness. (arXiv1811..pdf:pdf},
journal = {arXiv Computer Science},
title = {{Robustly Disentangled Causal Mechanisms: Validating Deep Representations for Interventional Robustness. (arXiv:1811.00007v2 [stat.ML] UPDATED)}},
url = {http://arxiv.org/abs/1811.00007},
year = {2019}
}
@article{Yi2012,
abstract = {Basic understanding and recognition of human actions can be accomplished by modeling the spatiotemporal relationship among major skeletal joints. In this work we present an approach that models human actions using temporal causal relations of joint movements. The relations form a graph with joints as nodes and edges induced by the Granger causality measure between pairs of joint point processes. Each human action is then represented by a distinct sparse causality graph. Experiments on motion capture data illustrate the robustness of this approach and its advantages over state-of-the-art methods. {\textcopyright} 2012 ICPR Org Committee.},
author = {Yi, Saehoon and Pavlovic, Vladimir},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yi, Pavlovic - 2012 - Sparse Granger causality graphs for human action classification.pdf:pdf},
isbn = {9784990644109},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
number = {Icpr},
pages = {3374--3377},
publisher = {IEEE},
title = {{Sparse Granger causality graphs for human action classification}},
year = {2012}
}
@article{Franceschi2019a,
abstract = {Time series constitute a challenging data type for machine learning algorithms, due to their highly variable lengths and sparse labeling in practice. In this paper, we tackle this challenge by proposing an unsupervised method to learn universal embeddings of time series. Unlike previous works, it is scalable with respect to their length and we demonstrate the quality, transferability and practicability of the learned representations with thorough experiments and comparisons. To this end, we combine an encoder based on causal dilated convolutions with a novel triplet loss employing time-based negative sampling, obtaining general-purpose representations for variable length and multivariate time series.},
archivePrefix = {arXiv},
arxivId = {1901.10738},
author = {Franceschi, Jean Yves and Dieuleveut, Aymeric and Jaggi, Martin},
eprint = {1901.10738},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Franceschi, Dieuleveut, Jaggi - 2019 - Unsupervised scalable representation learning for multivariate time series.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS 2019},
title = {{Unsupervised scalable representation learning for multivariate time series}},
year = {2019}
}
@article{Zhu2017,
abstract = {In this paper, we propose a new unsupervised spectral feature selection model by embedding a graph regularizer into the framework of joint sparse regression for preserving the local structures of data. To do this, we first extract the bases of training data by previous dictionary learning methods and, then, map original data into the basis space to generate their new representations, by proposing a novel joint graph sparse coding (JGSC) model. In JGSC, we first formulate its objective function by simultaneously taking subspace learning and joint sparse regression into account, then, design a new optimization solution to solve the resulting objective function, and further prove the convergence of the proposed solution. Furthermore, we extend JGSC to a robust JGSC (RJGSC) via replacing the least square loss function with a robust loss function, for achieving the same goals and also avoiding the impact of outliers. Finally, experimental results on real data sets showed that both JGSC and RJGSC outperformed the state-of-the-art algorithms in terms of $\kappa$-nearest neighbor classification performance.},
author = {Zhu, Xiaofeng and Li, Xuelong and Zhang, Shichao and Ju, Chunhua and Wu, Xindong},
doi = {10.1109/TNNLS.2016.2521602},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2017 - Robust Joint Graph Sparse Coding for Unsupervised Spectral Feature Selection.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Dimensionality reduction,manifold learning,regression,sparse coding},
number = {6},
pages = {1263--1275},
pmid = {26955053},
publisher = {IEEE},
title = {{Robust Joint Graph Sparse Coding for Unsupervised Spectral Feature Selection}},
volume = {28},
year = {2017}
}
@article{DeBruin2018,
abstract = {Most deep reinforcement learning techniques are unsuitable for robotics, as they require too much interaction time to learn useful, general control policies. This problem can be largely attributed to the fact that a state representation needs to be learned as a part of learning control policies, which can only be done through fitting expected returns based on observed rewards. While the reward function provides information on the desirability of the state of the world, it does not necessarily provide information on how to distill a good, general representation of that state from the sensory observations. State representation learning objectives can be used to help learn such a representation. While many of these objectives have been proposed, they are typically not directly combined with reinforcement learning algorithms. We investigate several methods for integrating state representation learning into reinforcement learning. In these methods, the state representation learning objectives help regularize the state representation during the reinforcement learning, and the reinforcement learning itself is viewed as a crucial state representation learning objective and allowed to help shape the representation. Using autonomous racing tests in the TORCS simulator, we show how the integrated methods quickly learn policies that generalize to new environments much better than deep reinforcement learning without state representation learning.},
author = {{De Bruin}, Tim and Kober, Jens and Tuyls, Karl and Babuska, Robert},
doi = {10.1109/LRA.2018.2800101},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Bruin et al. - 2018 - Integrating State Representation Learning into Deep Reinforcement Learning.pdf:pdf},
issn = {23773766},
journal = {IEEE Robotics and Automation Letters},
keywords = {Deep learning in robotics and automation,learning and adaptive systems,sensor fusion},
number = {3},
pages = {1394--1401},
publisher = {IEEE},
title = {{Integrating State Representation Learning into Deep Reinforcement Learning}},
volume = {3},
year = {2018}
}
@techreport{Bengio2013,
abstract = {Stochastic neurons and hard non-linearities can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic or non-smooth neurons? I.e., can we "back-propagate" through these stochastic neurons? We examine this question, existing approaches, and compare four families of solutions, applicable in different settings. One of them is the minimum variance unbiased gradient estimator for stochatic binary neurons (a special case of the REINFORCE algorithm). A second approach, introduced here, decomposes the operation of a binary stochastic neuron into a stochastic binary part and a smooth differentiable part, which approximates the expected effect of the pure stochatic binary neuron to first order. A third approach involves the injection of additive or multiplicative noise in a computational graph that is otherwise differentiable. A fourth approach heuristically copies the gradient with respect to the stochastic output directly as an estimator of the gradient with respect to the sigmoid argument (we call this the straight-through estimator). To explore a context where these estimators are useful, we consider a small-scale version of conditional computation, where sparse stochastic units form a distributed representation of gaters that can turn off in combinatorially many ways large chunks of the computation performed in the rest of the neural network. In this case, it is important that the gating units produce an actual 0 most of the time. The resulting sparsity can be potentially be exploited to greatly reduce the computational cost of large deep networks for which conditional computation would be useful.},
archivePrefix = {arXiv},
arxivId = {1308.3432v1},
author = {Bengio, Yoshua and L{\'{e}}onard, Nicholas and Courville, Aaron},
eprint = {1308.3432v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio, L{\'{e}}onard, Courville - Unknown - Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation.pdf:pdf},
title = {{Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation}},
year = {2013}
}
@techreport{Tang2019,
abstract = {Graph Convolutional Neural Networks (GCNNs) extend classical CNNs to graph data domain, such as brain networks, social networks and 3D point clouds. It is critical to identify an appropriate graph for the subsequent graph convolution. Existing methods manually construct or learn one fixed graph for all the layers of a GCNN. In order to adapt to the underlying structure of node features in different layers, we propose dynamic learning of graphs and node features jointly in GCNNs. In particular, we cast the graph optimization problem as distance metric learning to capture pairwise similarities of features in each layer. We deploy the Mahalanobis distance metric and further decompose the metric matrix into a low-dimensional matrix, which converts graph learning to the optimization of a low-dimensional matrix for efficient implementation. Extensive experiments on point clouds and citation network datasets demonstrate the superiority of the proposed method in terms of both accuracies and robustness.},
author = {Tang, Jiaxiang and Hu, Wei and Gao, Xiang and Guo, Zongming},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang et al. - 2019 - JOINT GRAPH AND FEATURE LEARNING IN GRAPH CONVOLUTIONAL NEURAL NETWORKS A PREPRINT.pdf:pdf},
title = {{JOINT GRAPH AND FEATURE LEARNING IN GRAPH CONVOLUTIONAL NEURAL NETWORKS A PREPRINT}},
year = {2019}
}
@article{Bansal2021,
author = {Bansal, Gagan and Nushi, Besmira and Kamar, Ece and Horvitz, Eric and Weld, Daniel S},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bansal et al. - Unknown - Is the Most Accurate AI the Best Teammate Optimizing AI for Teamwork.pdf:pdf},
title = {{Is the Most Accurate AI the Best Teammate ? Optimizing AI for Teamwork}},
year = {2021}
}
@article{Yamada2018,
abstract = {Feature selection problems have been extensively studied for linear estimation, for instance, Lasso, but less emphasis has been placed on feature selection for non-linear functions. In this study, we propose a method for feature selection in high-dimensional non-linear function estimation problems. The new procedure is based on minimizing the `0 norm of the vector of indicator variables that represent if a feature is selected or not. Our approach relies on the continuous relaxation of Bernoulli distributions, which allows our model to learn the parameters of the approximate Bernoulli distributions via gradient descent. This general framework simultaneously minimizes a loss function while selecting relevant features. Furthermore, we provide an information-theoretic justification of incorporating Bernoulli distribution into our approach and demonstrate the potential of the approach on synthetic and real-life applications.},
archivePrefix = {arXiv},
arxivId = {1810.04247},
author = {Yamada, Yutaro and Lindenbaum, Ofir and Negahban, Sahand and Kluger, Yuval},
eprint = {1810.04247},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yamada et al. - 2018 - Feature selection using stochastic gates.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Machine Learning, ICML},
title = {{Feature selection using stochastic gates}},
year = {2018}
}
@article{Abid2019,
abstract = {We introduce the concrete autoencoder, an endto- end differentiable method for global feature selection, which efficiently identifies a subset of the most informative features and simultaneously learns a neural network to reconstruct the input data from the selected features. Our method is unsupervised, and is based on using a concrete selector layer as the encoder and using a standard neural network as the decoder. During the training phase, the temperature of the concrete selector layer is gradually decreased, which encourages a user-specified number of discrete features to be learned. During test time, the selected features can be used with the decoder network to reconstruct the remaining input features. We evaluate concrete autoencoders on a variety of datasets, where they significantly outperform state-of-theart methods for feature selection and data reconstruction. In particular, on a large-scale gene expression dataset, the concrete autoencoder selects a small subset of genes whose expression levels can be use to impute the expression levels of the remaining genes. In doing so, it improves on the current widely-used expert-curated L1000 landmark genes, potentially reducing measurement costs by 20%. The concrete autoencoder can be implemented by adding just a few lines of code to a standard autoencoder.},
author = {Abid, Abubakar and Balin, Muhammad Fatih and Zou, James},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abid, Balin, Zou - 2019 - Concrete autoencoders for differentiable feature selection and reconstruction.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Concrete autoencoders for differentiable feature selection and reconstruction}},
year = {2019}
}
@article{Liang2021,
abstract = {The mushroom body of the fruit fly brain is one of the best studied systems in neuroscience. At its core it consists of a population of Kenyon cells, which receive inputs from multiple sensory modalities. These cells are inhibited by the anterior paired lateral neuron, thus creating a sparse high dimensional representation of the inputs. In this work we study a mathematical formalization of this network motif and apply it to learning the correlational structure between words and their context in a corpus of unstructured text, a common natural language processing (NLP) task. We show that this network can learn semantic representations of words and can generate both static and context-dependent word embeddings. Unlike conventional methods (e.g., BERT, GloVe) that use dense representations for word embedding, our algorithm encodes semantic meaning of words and their context in the form of sparse binary hash codes. The quality of the learned representations is evaluated on word similarity analysis, word-sense disambiguation, and document classification. It is shown that not only can the fruit fly network motif achieve performance comparable to existing methods in NLP, but, additionally, it uses only a fraction of the computational resources (shorter training time and smaller memory footprint).},
archivePrefix = {arXiv},
arxivId = {2101.06887},
author = {Liang, Yuchen and Ryali, Chaitanya K. and Hoover, Benjamin and Grinberg, Leopold and Navlakha, Saket and Zaki, Mohammed J. and Krotov, Dmitry},
eprint = {2101.06887},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2021 - Can a Fruit Fly Learn Word Embeddings.pdf:pdf},
pages = {1--16},
title = {{Can a Fruit Fly Learn Word Embeddings?}},
url = {http://arxiv.org/abs/2101.06887},
year = {2021}
}
@article{Han2019,
abstract = {The objective of this paper is self-supervised learning of spatio-temporal embeddings from video, suitable for human action recognition. We make three contributions: First, we introduce the Dense Predictive Coding (DPC) framework for self-supervised representation learning on videos. This learns a dense encoding of spatio-temporal blocks by recurrently predicting future representations; Second, we propose a curriculum training scheme to predict further into the future with progressively less temporal context. This encourages the model to only encode slowly varying spatial-temporal signals, therefore leading to semantic representations; Third, we evaluate the approach by first training the DPC model on the Kinetics-400 dataset with self-supervised learning, and then finetuning the representation on a downstream task, i.e. action recognition. With single stream (RGB only), DPC pretrained representations achieve state-of-the-art self-supervised performance on both UCF101 (75.7% top1 acc) and HMDB51 (35.7% top1 acc), outperforming all previous learning methods by a significant margin, and approaching the performance of a baseline pre-trained on ImageNet. The code is available at https://github.com/TengdaHan/DPC.},
author = {Han, Tengda and Xie, Weidi and Zisserman, Andrew},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Xie, Zisserman - 2019 - Video representation learning by dense predictive coding.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Video representation learning by dense predictive coding}},
year = {2019}
}
@article{Ppearance2019,
author = {Ppearance, A},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ppearance - 2019 - U Nsupervised D Isentangling S Tructure.pdf:pdf},
pages = {1--12},
title = {{U Nsupervised D Isentangling S Tructure}},
year = {2019}
}
@article{Weiß2011,
author = {Wei{\ss}, Gregor and Meine, Christian},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wei{\ss}, Meine - 2011 - END-TO-END INPUT SELECTION FOR DEEP NEURAL NETWORKS.pdf:pdf},
journal = {Dbw},
number = {1},
pages = {83--87},
title = {{END-TO-END INPUT SELECTION FOR DEEP NEURAL NETWORKS}},
volume = {70},
year = {2011}
}
@article{Yeshurun2021,
author = {Yeshurun, Yaara and Nguyen, Mai and Hasson, Uri},
doi = {10.1038/s41583-020-00420-w},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeshurun, Nguyen, Hasson - Unknown - The default mode network where the idiosyncratic self meets the shared social world.pdf:pdf},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
publisher = {Springer US},
title = {{The default mode network: where the idiosyncratic self meets the shared social world}},
url = {http://dx.doi.org/10.1038/s41583-020-00420-w},
year = {2021}
}
@article{Casgrain2020,
abstract = {The need for fast and robust optimization algorithms are of critical importance in all areas of machine learning. This paper treats the task of designing optimization algorithms as an optimal control problem. Using regret as a metric for an algorithm's performance, we study the existence, uniqueness and consistency of regret-optimal algorithms. By providing first-order optimality conditions for the control problem, we show that regret-optimal algorithms must satisfy a specific structure in their dynamics which we show is equivalent to performing dual-preconditioned gradient descent on the value function generated by its regret. Using these optimal dynamics, we provide bounds on their rates of convergence to solutions of convex optimization problems. Though closed-form optimal dynamics cannot be obtained in general, we present fast numerical methods for approximating them, generating optimization algorithms which directly optimize their long-term regret. Lastly, these are benchmarked against commonly used optimization algorithms to demonstrate their effectiveness.},
archivePrefix = {arXiv},
arxivId = {2101.00041},
author = {Casgrain, Philippe and Kratsios, Anastasis},
eprint = {2101.00041},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Casgrain, Kratsios - 2020 - Optimizing Optimizers Regret-optimal gradient descent algorithms.pdf:pdf},
keywords = {algorithm generation,convex optimization,hyperparameter optimization,non-convex optimization,optimal control,tion,variational optimiza-},
title = {{Optimizing Optimizers: Regret-optimal gradient descent algorithms}},
url = {http://arxiv.org/abs/2101.00041},
year = {2020}
}
@article{Fan2020,
abstract = {Transformers are feedforward networks that can process input tokens in parallel. While this parallelization makes them computationally efficient, it restricts the model from fully exploiting the sequential nature of the input — the representation at a given layer can only access representations from lower layers, rather than the higher level representations already built in previous time steps. In this work, we propose the Feedback Transformer architecture that exposes all previous representations to all future representations, meaning the lowest representation of the current timestep is formed from the highest-level abstract representation of the past. We demonstrate on a variety of benchmarks in language modeling, neural machine translation, summarization, and reinforcement learning that the increased representation capacity can improve over Transformer baselines.},
archivePrefix = {arXiv},
arxivId = {2002.09402},
author = {Fan, Angela and Lavril, Thibaut and Grave, Edouard and Joulin, Armand and Sukhbaatar, Sainbayar},
eprint = {2002.09402},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan et al. - 2020 - Accessing higher-level representations in sequential transformers with Feedback memory.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--18},
title = {{Accessing higher-level representations in sequential transformers with Feedback memory}},
year = {2020}
}
@article{Acharya2020,
abstract = {Graph Neural Networks (GNNs) have been a latest hot research topic in data science, due to the fact that they use the ubiquitous data structure graphs as the underlying elements for constructing and training neural networks. In a GNN, each node has numerous features associated with it. The entire task (for example, classification, or clustering) utilizes the features of the nodes to make decisions, at node level or graph level. In this paper, (1) we extend the feature selection algorithm presented in via Gumbel Softmax to GNNs. We conduct a series of experiments on our feature selection algorithms, using various benchmark datasets: Cora, Citeseer and Pubmed. (2) We implement a mechanism to rank the extracted features. We demonstrate the effectiveness of our algorithms, for both feature selection and ranking. For the Cora dataset, (1) we use the algorithm to select 225 features out of 1433 features. Our experimental results demonstrate their effectiveness for the same classification problem. (2) We extract features such that they are linear combinations of the original features, where the coefficients for extracted features are non-negative and sum up to one. We propose an algorithm to rank the extracted features in the sense that when using them for the same classification problem, the accuracy goes down gradually for the extracted features within the rank 1 - 50, 51 - 100, 100 - 150, and 151 - 200.},
archivePrefix = {arXiv},
arxivId = {1910.10682},
author = {Acharya, Deepak Bhaskar and Zhang, Huaming},
doi = {10.1145/3374135.3385309},
eprint = {1910.10682},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Acharya, Zhang - 2020 - Feature selection and extraction for graph neural networks.pdf:pdf},
isbn = {9781450371056},
journal = {ACMSE 2020 - Proceedings of the 2020 ACM Southeast Conference},
keywords = {Feature Extraction,Feature Selection,Graph Neural Networks,Gumbel-Softmax},
pages = {252--255},
title = {{Feature selection and extraction for graph neural networks}},
year = {2020}
}
@article{Mayner2020,
author = {Mayner, William G P and Marshall, William and Albantakis, Larissa and Findlay, Graham and Marchman, Robert and Tononi, Giulio},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mayner et al. - Unknown - Calculating Phi.pdf:pdf},
title = {{Calculating Phi}},
year = {2020}
}
@article{Amrami2021,
abstract = {We present a simple proof for the benefit of depth in multi-layer feedforward network with rectified activation ("depth separation"). Specifically we present a sequence of classification problems indexed by $m$ such that (a) for any fixed depth rectified network there exist an $m$ above which classifying problem $m$ correctly requires exponential number of parameters (in $m$); and (b) for any problem in the sequence, we present a concrete neural network with linear depth (in $m$) and small constant width ($\leq 4$) that classifies the problem with zero error. The constructive proof is based on geometric arguments and a space folding construction. While stronger bounds and results exist, our proof uses substantially simpler tools and techniques, and should be accessible to undergraduate students in computer science and people with similar backgrounds.},
archivePrefix = {arXiv},
arxivId = {2101.07126},
author = {Amrami, Asaf and Goldberg, Yoav},
eprint = {2101.07126},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amrami, Goldberg - 2021 - A simple geometric proof for the benefit of depth in ReLU networks.pdf:pdf},
month = {jan},
title = {{A simple geometric proof for the benefit of depth in ReLU networks}},
url = {http://arxiv.org/abs/2101.07126},
year = {2021}
}
@article{Noroozi2017,
abstract = {We introduce a novel method for representation learning that uses an artificial supervision signal based on counting visual primitives. This supervision signal is obtained from an equivariance relation, which does not require any manual annotation. We relate transformations of images to transformations of the representations. More specifically, we look for the representation that satisfies such relation rather than the transformations that match a given representation. In this paper, we use two image transformations in the context of counting: scaling and tiling. The first transformation exploits the fact that the number of visual primitives should be invariant to scale. The second transformation allows us to equate the total number of visual primitives in each tile to that in the whole image. These two transformations are combined in one constraint and used to train a neural network with a contrastive loss. The proposed task produces representations that perform on par or exceed the state of the art in transfer learning benchmarks.},
author = {Noroozi, Mehdi and Pirsiavash, Hamed and Favaro, Paolo},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Noroozi, Pirsiavash, Favaro - 2017 - Representation learning by learning to count.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {5898--5906},
title = {{Representation learning by learning to count}},
year = {2017}
}
@article{Hamilton2017,
abstract = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.},
archivePrefix = {arXiv},
arxivId = {1709.05584},
author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
eprint = {1709.05584},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamilton, Ying, Leskovec - 2017 - Representation Learning on Graphs Methods and Applications.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--24},
title = {{Representation Learning on Graphs: Methods and Applications}},
year = {2017}
}
@article{Donahue2019,
abstract = {Adversarially trained generative models (GANs) have recently achieved compelling image synthesis results. But despite early successes in using GANs for unsupervised representation learning, they have since been superseded by approaches based on self-supervision. In this work we show that progress in image generation quality translates to substantially improved representation learning performance. Our approach, BigBiGAN, builds upon the state-of-the-art BigGAN model, extending it to representation learning by adding an encoder and modifying the discriminator. We extensively evaluate the representation learning and generation capabilities of these BigBiGAN models, demonstrating that these generation-based models achieve the state of the art in unsupervised representation learning on ImageNet, as well as in unconditional image generation.},
archivePrefix = {arXiv},
arxivId = {1907.02544},
author = {Donahue, Jeff and Simonyan, Karen},
eprint = {1907.02544},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Donahue, Simonyan - 2019 - Large Scale Adversarial Representation Learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS},
pages = {1--11},
title = {{Large Scale Adversarial Representation Learning}},
year = {2019}
}
@article{VandenOord2017,
abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: The encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" - where the latents are ignored when they are paired with a powerful autoregressive decoder - typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
author = {{Van den Oord}, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van den Oord, Vinyals, Kavukcuoglu - 2017 - Neural discrete representation learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {Nips},
title = {{Neural discrete representation learning}},
year = {2017}
}
@article{Kalainathan2018,
abstract = {A new causal discovery method, Structural Agnostic Modeling (SAM), is presented in this paper. Leveraging both conditional independencies and distributional asymmetries in the data, SAM aims at recovering full causal models from continuous observational data along a multivariate nonparametric setting. The approach is based on a game between d players estimating each variable distribution conditionally to the others as a neural net, and an adversary aimed at discriminating the overall joint conditional distribution, and that of the original data. An original learning criterion combining distribution estimation, sparsity and acyclicity constraints is used to enforce the end-to-end optimization of the graph structure and parameters through stochastic gradient descent. Besides the theoretical analysis of the approach in the large sample limit, SAM is extensively experimentally validated on synthetic and real data.},
archivePrefix = {arXiv},
arxivId = {1803.04929},
author = {Kalainathan, Diviyan and Goudet, Olivier and Guyon, Isabelle and Lopez-Paz, David and Sebag, Mich{\`{e}}le},
eprint = {1803.04929},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalainathan et al. - 2018 - Structural agnostic modeling Adversarial learning of causal graphs.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--49},
title = {{Structural agnostic modeling: Adversarial learning of causal graphs}},
year = {2018}
}
@article{Ng2019,
abstract = {Learning causal graphical models based on directed acyclic graphs is an important task in causal discovery and causal inference. We consider a general framework towards efficient causal structure learning with potentially large graphs. Within this framework, we propose a masked gradient-based structure learning method based on binary adjacency matrix that exists for any structural equation model. To enable first-order optimization methods, we use Gumbel-Softmax approach to approximate the binary valued entries of the adjacency matrix, which usually results in real values that are close to zero or one. The proposed method can readily include any differentiable score function and model function for learning causal structures. Experiments on both synthetic and real-world datasets are conducted to show the effectiveness of our approach.},
archivePrefix = {arXiv},
arxivId = {1910.08527},
author = {Ng, Ignavier and Fang, Zhuangyan and Zhu, Shengyu and Chen, Zhitang},
eprint = {1910.08527},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng et al. - 2019 - Masked gradient-based causal structure learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Masked gradient-based causal structure learning}},
year = {2019}
}
@article{VanSteenkiste2020,
author = {van Steenkiste, Sjoerd},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Steenkiste - 2020 - Learning Structured Neural Representations for Visual Reasoning Tasks Sjoerd van Steenkiste under the supervisio.pdf:pdf},
journal = {2020},
number = {November},
title = {{Learning Structured Neural Representations for Visual Reasoning Tasks Sjoerd van Steenkiste under the supervision of}},
year = {2020}
}
@article{Citation2021,
author = {Citation, License Other},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Citation - 2021 - UvA-DARE (Digital Academic Repository) A coding perspective on deep latent variable models Ullrich, K.pdf:pdf},
title = {{UvA-DARE (Digital Academic Repository) A coding perspective on deep latent variable models Ullrich, K.}},
year = {2021}
}
@article{Lino2021,
abstract = {Figure 1: Example in the WikiBio dataset (Lebret et al., 2016) showing the biography of Frank Lino. The baseline Pointer-Generator (See et al., 2017) exhibits hallucination. network (See et al., 2017), which contains the phrase criminal defense attorney that is false (but loosely related to FBI in the table). Thus, hallucination can often result from the coupling of model shortcomings (e.g. lack of formal reasoning, learning false correlations), and noise/artifacts in the training data. In this work, we propose a confidence oriented approach which assigns a learned confidence score to each decoder position, and then uses the score in two ways to reduce hallucination: (1) In test, it uses confidence to adjust the output probabilities by a calibration technique (Braverman et al., 2019). (2) In training, we employ a variational Bayes objective to jointly learn the confidence score while allowing the model to skip tokens with a low confidence score to avoid training on reference phrases that are difficult to infer from the source. In Figure 1, our approach leads to a faithful generation that omits the occupation. Empirically, when evaluated on the WikiBio dataset (Lebret et al., 2016), we show that our approach is considerably more faithful to the source than existing state-of-the-art solutions, according to both PARENT precision (Dhingra et al., 2019) and human evaluation.},
author = {Lino, Frank},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lino - 1938 - Practical Real Time Recurrent Learning with a Sparse Approximation to the Jacobian.pdf:pdf},
pages = {11--39},
title = {{Practical Real Time Recurrent Learning with a Sparse Approximation to the Jacobian}},
year = {2021}
}
@article{Wulfmeier2020,
abstract = {Projecting high-dimensional environment observations into lower-dimensional structured representations can considerably improve data-efficiency for reinforcement learning in domains with limited data such as robotics. Can a single generally useful representation be found? In order to answer this question, it is important to understand how the representation will be used by the agent and what properties such a 'good' representation should have. In this paper we systematically evaluate a number of common learnt and hand-engineered representations in the context of three robotics tasks: lifting, stacking and pushing of 3D blocks. The representations are evaluated in two use-cases: as input to the agent, or as a source of auxiliary tasks. Furthermore, the value of each representation is evaluated in terms of three properties: dimensionality, observability and disentanglement. We can significantly improve performance in both use-cases and demonstrate that some representations can perform commensurate to simulator states as agent inputs. Finally, our results challenge common intuitions by demonstrating that: 1) dimensionality strongly matters for task generation, but is negligible for inputs, 2) observability of task-relevant aspects mostly affects the input representation use-case, and 3) disentanglement leads to better auxiliary tasks, but has only limited benefits for input representations. This work serves as a step towards a more systematic understanding of what makes a 'good' representation for control in robotics, enabling practitioners to make more informed choices for developing new learned or hand-engineered representations.},
archivePrefix = {arXiv},
arxivId = {2011.01758},
author = {Wulfmeier, Markus and Byravan, Arunkumar and Hertweck, Tim and Higgins, Irina and Gupta, Ankush and Kulkarni, Tejas and Reynolds, Malcolm and Teplyashin, Denis and Hafner, Roland and Lampe, Thomas and Riedmiller, Martin},
eprint = {2011.01758},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wulfmeier et al. - 2020 - Representation Matters Improving Perception and Exploration for Robotics.pdf:pdf},
title = {{Representation Matters: Improving Perception and Exploration for Robotics}},
url = {http://arxiv.org/abs/2011.01758},
year = {2020}
}
@article{PriyaInala2020,
abstract = {We study the problem of inferring communication structures that can solve cooperative multi-agent planning problems while minimizing the amount of communication. We quantify the amount of communication as the maximum degree of the communication graph; this metric captures settings where agents have limited bandwidth. Minimizing communication is challenging due to the combinatorial nature of both the decision space and the objective; for instance, we cannot solve this problem by training neural networks using gradient descent. We propose a novel algorithm that synthesizes a control policy that combines a programmatic communication policy used to generate the communication graph with a transformer policy network used to choose actions. Our algorithm first trains the transformer policy, which implicitly generates a "soft" communication graph; then, it synthesizes a programmatic communication policy that "hardens" this graph, forming a neurosymbolic transformer. Our experiments demonstrate how our approach can synthesize policies that generate low-degree communication graphs while maintaining near-optimal performance.},
archivePrefix = {arXiv},
arxivId = {arXiv:2101.03238v1},
author = {{Priya Inala}, Jeevana and Yang, Yichen and Paulos, James and Pu, Yewen and Bastani, Osbert and Kumar, Vijay and Rinard, Martin and Solar-Lezama, Armando},
eprint = {arXiv:2101.03238v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Priya Inala et al. - 2020 - Neurosymbolic Transformers for Multi-Agent Communication.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {1--15},
title = {{Neurosymbolic Transformers for Multi-Agent Communication}},
url = {https://github.com/jinala/},
volume = {33},
year = {2020}
}
@article{Gagliano2016,
abstract = {In complex and ever-changing environments, resources such as food are often scarce and unevenly distributed in space and time. Therefore, utilizing external cues to locate and remember high-quality sources allows more efficient foraging, thus increasing chances for survival. Associations between environmental cues and food are readily formed because of the tangible benefits they confer. While examples of the key role they play in shaping foraging behaviours are widespread in the animal world, the possibility that plants are also able to acquire learned associations to guide their foraging behaviour has never been demonstrated. Here we show that this type of learning occurs in the garden pea, Pisum sativum. By using a Y-maze task, we show that the position of a neutral cue, predicting the location of a light source, affected the direction of plant growth. This learned behaviour prevailed over innate phototropism. Notably, learning was successful only when it occurred during the subjective day, suggesting that behavioural performance is regulated by metabolic demands. Our results show that associative learning is an essential component of plant behaviour. We conclude that associative learning represents a universal adaptive mechanism shared by both animals and plants.},
author = {Gagliano, Monica and Vyazovskiy, Vladyslav V. and Borb{\'{e}}ly, Alexander A. and Grimonprez, Mavra and Depczynski, Martial},
doi = {10.1038/srep38427},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagliano et al. - 2016 - Learning by Association in Plants.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {December},
pages = {1--9},
pmid = {27910933},
publisher = {Nature Publishing Group},
title = {{Learning by Association in Plants}},
volume = {6},
year = {2016}
}
@article{Fedus2021,
abstract = {In deep learning, models typically reuse the same parameters for all inputs. Mixture of Experts (MoE) defies this and instead selects different parameters for each incoming example. The result is a sparsely-activated model -- with outrageous numbers of parameters -- but a constant computational cost. However, despite several notable successes of MoE, widespread adoption has been hindered by complexity, communication costs and training instability -- we address these with the Switch Transformer. We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and computational costs. Our proposed training techniques help wrangle the instabilities and we show large sparse models may be trained, for the first time, with lower precision (bfloat16) formats. We design models based off T5-Base and T5-Large to obtain up to 7x increases in pre-training speed with the same computational resources. These improvements extend into multilingual settings where we measure gains over the mT5-Base version across all 101 languages. Finally, we advance the current scale of language models by pre-training up to trillion parameter models on the "Colossal Clean Crawled Corpus" and achieve a 4x speedup over the T5-XXL model.},
archivePrefix = {arXiv},
arxivId = {2101.03961},
author = {Fedus, William and Zoph, Barret and Shazeer, Noam},
eprint = {2101.03961},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fedus, Zoph, Shazeer - 2021 - Switch Transformers Scaling to Trillion Parameter Models with Simple and Efficient Sparsity.pdf:pdf},
pages = {1--31},
title = {{Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity}},
url = {http://arxiv.org/abs/2101.03961},
year = {2021}
}
@article{Battaglia2016,
abstract = {Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains.},
annote = {fitting dynamics (time series)},
archivePrefix = {arXiv},
arxivId = {1612.00222},
author = {Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo and Kavukcuoglu, Koray},
eprint = {1612.00222},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Battaglia et al. - 2016 - Interaction networks for learning about objects, relations and physics.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {4509--4517},
title = {{Interaction networks for learning about objects, relations and physics}},
year = {2016}
}
@article{Cranmer2020,
abstract = {We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We find the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example—a detailed dark matter simulation—and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distribution-data better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.},
annote = {1. l1-sparsity in the edge model in GNN
2. Out-of-the-box symbolic regression applied to the learned edge/node model},
archivePrefix = {arXiv},
arxivId = {2006.11287},
author = {Cranmer, Miles and Sanchez-Gonzalez, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
eprint = {2006.11287},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cranmer et al. - 2020 - Discovering symbolic models from deep learning with inductive biases.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--25},
title = {{Discovering symbolic models from deep learning with inductive biases}},
year = {2020}
}
@article{Battaglia2018,
abstract = {Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences—a hallmark of human intelligence from infancy—remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between “hand-engineering” and “end-to-end” learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias—the graph network—which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have also released an open-source software library for building graph networks, with demonstrations of how to use them in practice.},
annote = {1. graphs describe multiple abstract domains well (sorting, images, text, physics)
2. graphs can be processed with Graph Neural Networks
2.1. Graph neural network aggregates edges into embeddings, then edges into node variables, and then returns the new graph with updated attributes
2.2. The proposed method works on various tasks},
archivePrefix = {arXiv},
arxivId = {1806.01261},
author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
eprint = {1806.01261},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Battaglia et al. - 2018 - Relational inductive biases, deep learning, and graph networks.pdf:pdf},
journal = {arXiv},
pages = {1--40},
title = {{Relational inductive biases, deep learning, and graph networks}},
year = {2018}
}
@article{Sorscher2020,
annote = {grid cell automatically emerge when the network is asked to path-integrate

nonnegative (excitation neuron) -> hexagonal

eigenvectors, fourier [of what?] -> repeated cells pattern},
author = {Sorscher, Ben and Mel, Gabriel C. and Ocko, Samuel A. and Giocomo, Lisa and Ganguli, Surya},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sorscher et al. - 2020 - A unified theory for the computational and mechanistic origins of grid cells.pdf:pdf},
journal = {bioRxiv},
title = {{A unified theory for the computational and mechanistic origins of grid cells}},
url = {https://www.biorxiv.org/content/10.1101/2020.12.29.424583v1},
year = {2020}
}
@article{Johnson2016,
abstract = {We propose a general modeling and inference framework that combines the complementary strengths of probabilistic graphical models and deep learning methods. Our model family composes latent graphical models with neural network observation likelihoods. For inference, we use recognition networks to produce local evidence potentials, then combine them with the model distribution using efficient message-passing algorithms. All components are trained simultaneously with a single stochastic variational inference objective. We illustrate this framework by automatically segmenting and categorizing mouse behavior from raw depth video, and demonstrate several other example models.},
annote = {switching linear dynamics -- piecewise-linear, switch according to a Markov model},
archivePrefix = {arXiv},
arxivId = {1603.06277},
author = {Johnson, Matthew James and Duvenaud, David and Wiltschko, Alexander B. and Datta, Sandeep R. and Adams, Ryan P.},
eprint = {1603.06277},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson et al. - 2016 - Composing graphical models with neural networks for structured representations and fast inference.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {graphical models, variational autoencoders, variat},
pages = {2954--2962},
title = {{Composing graphical models with neural networks for structured representations and fast inference}},
year = {2016}
}
@article{Dong2020,
abstract = {Training models with discrete latent variables is challenging due to the difficulty of estimating the gradients accurately. Much of the recent progress has been achieved by taking advantage of continuous relaxations of the system, which are not always available or even possible. The Augment-REINFORCE-Merge (ARM) estimator provides an alternative that, instead of relaxation, uses continuous augmentation. Applying antithetic sampling over the augmenting variables yields a relatively low-variance and unbiased estimator applicable to any model with binary latent variables. However, while antithetic sampling reduces variance, the augmentation process increases variance. We show that ARM can be improved by analytically integrating out the randomness introduced by the augmentation process, guaranteeing substantial variance reduction. Our estimator, DisARM, is simple to implement and has the same computational cost as ARM. We evaluate DisARM on several generative modeling benchmarks and show that it consistently outperforms ARM and a strong independent sample baseline in terms of both variance and log-likelihood. Furthermore, we propose a local version of DisARM designed for optimizing the multi-sample variational bound, and show that it outperforms VIMCO, the current state-of-the-art method.},
annote = {reducing variance when doing variational inference with discrete variables},
archivePrefix = {arXiv},
arxivId = {2006.10680},
author = {Dong, Zhe and Mnih, Andriy and Tucker, George},
eprint = {2006.10680},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong, Mnih, Tucker - 2020 - Disarm an antithetic gradient estimator for binary latent variables.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Disarm: an antithetic gradient estimator for binary latent variables}},
year = {2020}
}
@article{Xie2020,
abstract = {Causal discovery aims to recover causal structures or models underlying the observed data. Despite its success in certain domains, most existing methods focus on causal relations between observed variables, while in many scenarios the observed ones may not be the underlying causal variables (e.g., image pixels), but are generated by latent causal variables or confounders that are causally related. To this end, in this paper, we consider Linear, Non-Gaussian Latent variable Models (LiNGLaMs), in which latent confounders are also causally related, and propose a Generalized Independent Noise (GIN) condition to estimate such latent variable graphs. Specifically, for two observed random vectors $\mathbf{Y}$ and $\mathbf{Z}$, GIN holds if and only if $\omega^{\intercal}\mathbf{Y}$ and $\mathbf{Z}$ are statistically independent, where $\omega$ is a parameter vector characterized from the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. From the graphical view, roughly speaking, GIN implies that causally earlier latent common causes of variables in $\mathbf{Y}$ d-separate $\mathbf{Y}$ from $\mathbf{Z}$. Interestingly, we find that the independent noise condition, i.e., if there is no confounder, causes are independent from the error of regressing the effect on the causes, can be seen as a special case of GIN. Moreover, we show that GIN helps locate latent variables and identify their causal structure, including causal directions. We further develop a recursive learning algorithm to achieve these goals. Experimental results on synthetic and real-world data demonstrate the effectiveness of our method.},
archivePrefix = {arXiv},
arxivId = {2010.04917},
author = {Xie, Feng and Cai, Ruichu and Huang, Biwei and Glymour, Clark and Hao, Zhifeng and Zhang, Kun},
eprint = {2010.04917},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2020 - Generalized Independent Noise Condition for Estimating Latent Variable Causal Graphs.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Generalized Independent Noise Condition for Estimating Latent Variable Causal Graphs}},
url = {http://arxiv.org/abs/2010.04917},
volume = {4},
year = {2020}
}
@article{Luneau2020,
abstract = {We consider generalized linear models in regimes where the number of nonzero components of the signal and accessible data points are sublinear with respect to the size of the signal. We prove a variational formula for the asymptotic mutual information per sample when the system size grows to infinity. This result allows us to heuristically derive an expression for the minimum mean-square error (MMSE) of the Bayesian estimator. We then find that, for discrete signals and suitable vanishing scalings of the sparsity and sampling rate, the MMSE displays an all-or-nothing phenomenon, namely, the MMSE sharply jumps from its maximum value to zero at a critical sampling rate. The all-or-nothing phenomenon has recently been proved to occur in high-dimensional linear regression. Our analysis goes beyond the linear case and applies to learning the weights of a perceptron with general activation function in a teacher-student scenario. In particular we discuss an all-or-nothing phenomenon for the generalization error with a sublinear set of training examples.},
archivePrefix = {arXiv},
arxivId = {2006.11313},
author = {Luneau, Cl{\'{e}}ment and Macris, Nicolas and Barbier, Jean},
eprint = {2006.11313},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luneau, Macris, Barbier - 2020 - Information theoretic limits of learning a sparse rule.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Information theoretic limits of learning a sparse rule}},
year = {2020}
}
@article{Lample2019,
abstract = {Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.},
annote = {seq2seq model to do symbolic operations on mathematical expressions (integration, differentiation, simplification)},
archivePrefix = {arXiv},
arxivId = {1912.01412},
author = {Lample, Guillaume and Charton, Fran{\c{c}}ois},
eprint = {1912.01412},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lample, Charton - 2019 - Deep Learning for Symbolic Mathematics.pdf:pdf},
journal = {arXiv},
pages = {1--24},
title = {{Deep Learning for Symbolic Mathematics}},
year = {2019}
}
@article{Zhang2019,
abstract = {“Thinking in pictures,” [1] i.e., spatial-temporal reasoning, effortless and instantaneous for humans, is believed to be a significant ability to perform logical induction and a crucial factor in the intellectual history of technology development. Modern Artificial Intelligence (AI), fueled by massive datasets, deeper models, and mighty computation, has come to a stage where (super-)human-level performances are observed in certain specific tasks. However, current AI's ability in “thinking in pictures” is still far lacking behind. In this work, we study how to improve machines' reasoning ability on one challenging task of this kind: Raven's Progressive Matrices (RPM). Specifically, we borrow the very idea of “contrast effects” from the field of psychology, cognition, and education to design and train a permutation-invariant model. Inspired by cognitive studies, we equip our model with a simple inference module that is jointly trained with the perception backbone. Combining all the elements, we propose the Contrastive Perceptual Inference network (CoPINet) and empirically demonstrate that CoPINet sets the new state-of-the-art for permutation-invariant models on two major datasets. We conclude that spatial-temporal reasoning depends on envisaging the possibilities consistent with the relations between objects and can be solved from pixel-level inputs.},
archivePrefix = {arXiv},
arxivId = {1912.00086},
author = {Zhang, Chi and Jia, Baoxiong and Gao, Feng and Zhu, Yixin and Lu, Hongjing and Zhu, Song Chun},
eprint = {1912.00086},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Learning perceptual inference by contrasting.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--13},
title = {{Learning perceptual inference by contrasting}},
year = {2019}
}
@article{Hu2020,
abstract = {reasoning refers to the ability to analyze information, discover rules at an intangible level, and solve problems in innovative ways. Raven's Progressive Matrices (RPM) test is typically used to examine the capability of abstract reasoning. In the test, the subject is asked to identify the correct choice from the answer set to fill the missing panel at the bottom right of RPM (e.g., a 3×3 matrix), following the underlying rules inside the matrix. Recent studies, taking advantage of Convolutional Neural Networks (CNNs), have achieved encouraging progress to accomplish the RPM test problems. Unfortunately, simply relying on the relation extraction at the matrix level, they fail to recognize the complex attribute patterns inside or across rows/columns of RPM. To address this problem, in this paper we propose a Hierarchical Rule Induction Network (HriNet), by intimating human induction strategies. HriNet extracts multiple granularity rule embeddings at different levels and integrates them through a gated embedding fusion module. We further introduce a rule similarity metric based on the embeddings, so that HriNet can not only be trained using a tuplet loss but also infer the best answer according to the similarity score. To comprehensively evaluate HriNet, we first fix the defects contained in the very recent RAVEN dataset and generate a new one named Balanced-RAVEN. Then extensive experiments are conducted on the large-scale dataset PGM and our Balanced-RAVEN, the results of which show that HriNet outperforms the state-of-the-art models by a large margin.},
archivePrefix = {arXiv},
arxivId = {2002.06838},
author = {Hu, Sheng and Ma, Yuqing and Liu, Xianglong and Wei, Yanlu and Bai, Shihao},
eprint = {2002.06838},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2020 - Hierarchical rule induction network for abstract visual reasoning.pdf:pdf},
journal = {arXiv},
title = {{Hierarchical rule induction network for abstract visual reasoning}},
year = {2020}
}
@article{Bai2020,
abstract = {We propose a new class of implicit networks, the multiscale deep equilibrium model (MDEQ), suited to large-scale and highly hierarchical pattern recognition domains. An MDEQ directly solves for and backpropagates through the equilibrium points of multiple feature resolutions simultaneously, using implicit differentiation to avoid storing intermediate states (and thus requiring only O(1) memory consumption). These simultaneously-learned multi-resolution features allow us to train a single model on a diverse set of tasks and loss functions, such as using a single MDEQ to perform both image classification and semantic segmentation. We illustrate the effectiveness of this approach on two large-scale vision tasks: ImageNet classification and semantic segmentation on high-resolution images from the Cityscapes dataset. In both settings, MDEQs are able to match or exceed the performance of recent competitive computer vision models: the first time such performance and scale have been achieved by an implicit deep learning approach. The code and pre-trained models are at https://github.com/locuslab/mdeq.},
annote = {equilibrium=fixed point (weight tying)},
archivePrefix = {arXiv},
arxivId = {2006.08656},
author = {Bai, Shaojie and Koltun, Vladlen and Kolter, J. Zico},
eprint = {2006.08656},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai, Koltun, Kolter - 2020 - Multiscale deep equilibrium models.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Multiscale deep equilibrium models}},
year = {2020}
}
@article{Hahne2019,
abstract = {Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction. However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.},
archivePrefix = {arXiv},
arxivId = {1911.05990},
author = {Hahne, Lukas and L{\"{u}}ddecke, Timo and W{\"{o}}rg{\"{o}}tter, Florentin and Kappel, David},
eprint = {1911.05990},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hahne et al. - 2019 - Attention on abstract visual reasoning.pdf:pdf},
journal = {arXiv},
pages = {1--15},
title = {{Attention on abstract visual reasoning}},
year = {2019}
}
@article{Maron2020,
abstract = {Learning from unordered sets is a fundamental learning setup, which is attracting increasing attention. Research in this area has focused on the case where elements of the set are represented by feature vectors, and far less emphasis has been given to the common case where set elements themselves adhere to certain symmetries. That case is relevant to numerous applications, from deblurring image bursts to multi-view 3D shape recognition and reconstruction. In this paper, we present a principled approach to learning sets of general symmetric elements. We first characterize the space of linear layers that are equivariant both to element reordering and to the inherent symmetries of elements, like translation in the case of images. We further show that networks that are composed of these layers, called Deep Sets for Symmetric elements layers (DSS), are universal approximators of both invariant and equivariant functions. DSS layers are also straightforward to implement. Finally, we show that they improve over existing set-learning architectures in a series of experiments with images, graphs and point-clouds.},
annote = {defining the properties of weight matrices to allow for certain properties of the layers (symmetries in the input-output)},
archivePrefix = {arXiv},
arxivId = {2002.08599},
author = {Maron, Haggai and Litany, Or and Chechik, Gal and Fetaya, Ethan},
eprint = {2002.08599},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maron et al. - 2020 - On learning sets of symmetric elements.pdf:pdf},
journal = {arXiv},
title = {{On learning sets of symmetric elements}},
year = {2020}
}
@article{Paulus2020,
abstract = {The Gumbel-Max trick is the basis of many relaxed gradient estimators. These estimators are easy to implement and low variance, but the goal of scaling them comprehensively to large combinatorial distributions is still outstanding. Working within the perturbation model framework, we introduce stochastic softmax tricks, which generalize the Gumbel-Softmax trick to combinatorial spaces. Our framework is a unified perspective on existing relaxed estimators for perturbation models, and it contains many novel relaxations. We design structured relaxations for subset selection, spanning trees, arborescences, and others. When compared to less structured baselines, we find that stochastic softmax tricks can be used to train latent variable models that perform better and discover more latent structure.},
annote = {nice mathy explanation of softmax trick, generalization to subset selection},
archivePrefix = {arXiv},
arxivId = {2006.08063},
author = {Paulus, Max B. and Choi, Dami and Tarlow, Daniel and Krause, Andreas and Maddison, Chris J.},
eprint = {2006.08063},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulus et al. - 2020 - Gradient Estimation with Stochastic Softmax Tricks.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Gradient Estimation with Stochastic Softmax Tricks}},
year = {2020}
}
@article{Velickovic2020,
abstract = {Graph neural networks (GNNs) are typically applied to static graphs that are assumed to be known upfront. This static input structure is often informed purely by insight of the machine learning practitioner, and might not be optimal for the actual task the GNN is solving. In absence of reliable domain expertise, one might resort to inferring the latent graph structure, which is often difficult due to the vast search space of possible graphs. Here we introduce Pointer Graph Networks (PGNs) which augment sets or graphs with additional inferred edges for improved model expressivity. PGNs allow each node to dynamically point to another node, followed by message passing over these pointers. The sparsity of this adaptable graph structure makes learning tractable while still being sufficiently expressive to simulate complex algorithms. Critically, the pointing mechanism is directly supervised to model long-term sequences of operations on classical data structures, incorporating useful structural inductive biases from theoretical computer science. Qualitatively, we demonstrate that PGNs can learn parallelisable variants of pointer-based data structures, namely disjoint set unions and link/cut trees. PGNs generalise out-of-distribution to 5× larger test inputs on dynamic graph connectivity tasks, outperforming unrestricted GNNs and Deep Sets.},
annote = {graph neural network, with additional learned nodes that allow for message-passing},
archivePrefix = {arXiv},
arxivId = {2006.06380},
author = {Veli{\v{c}}kovi{\'{c}}, Petar and Buesing, Lars and Overlan, Matthew C. and Pascanu, Razvan and Vinyals, Oriol and Blundell, Charles},
eprint = {2006.06380},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Veli{\v{c}}kovi{\'{c}} et al. - 2020 - Pointer Graph Networks.pdf:pdf},
journal = {arXiv},
title = {{Pointer Graph Networks}},
year = {2020}
}
@article{Feinman2020,
abstract = {Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.},
annote = {generating 'letters' with an RNN},
archivePrefix = {arXiv},
arxivId = {2003.08978},
author = {Feinman, Reuben and Lake, Brenden M.},
eprint = {2003.08978},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feinman, Lake - 2020 - Generating new concepts with hybrid neuro-symbolic models.pdf:pdf},
journal = {arXiv},
keywords = {Causality,Compositionality,Generative models,Neural networks},
title = {{Generating new concepts with hybrid neuro-symbolic models}},
year = {2020}
}
@article{Gilmer2017,
abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
archivePrefix = {arXiv},
arxivId = {1704.01212},
author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
eprint = {1704.01212},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilmer et al. - 2017 - Neural message passing for quantum chemistry.pdf:pdf},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
pages = {2053--2070},
title = {{Neural message passing for quantum chemistry}},
volume = {3},
year = {2017}
}
@article{VanDenOord2018,
abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
archivePrefix = {arXiv},
arxivId = {1807.03748},
author = {{Van Den Oord}, Aaron and Li, Yazhe and Vinyals, Oriol},
eprint = {1807.03748},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Den Oord, Li, Vinyals - 2018 - Representation learning with contrastive predictive coding.pdf:pdf},
journal = {arXiv},
title = {{Representation learning with contrastive predictive coding}},
year = {2018}
}
@article{Maddison2017,
abstract = {The reparameterization trick enables optimizing large scale stochastic computation graphs via gradient descent. The essence of the trick is to refactor each stochastic node into a differentiable function of its parameters and a random variable with fixed distribution. After refactoring, the gradients of the loss propagated by the chain rule through the graph are low variance unbiased estimators of the gradients of the expected loss. While many continuous random variables have such reparameterizations, discrete random variables lack useful reparameterizations due to the discontinuous nature of discrete states. In this work we introduce CONCRETE random variables-CONtinuous relaxations of disCRETE random variables. The Concrete distribution is a new family of distributions with closed form densities and a simple reparameterization. Whenever a discrete stochastic node of a computation graph can be refactored into a one-hot bit representation that is treated continuously, Concrete stochastic nodes can be used with automatic differentiation to produce low-variance biased gradients of objectives (including objectives that depend on the log-probability of latent stochastic nodes) on the corresponding discrete graph. We demonstrate the effectiveness of Concrete relaxations on density estimation and structured prediction tasks using neural networks.},
archivePrefix = {arXiv},
arxivId = {1611.00712},
author = {Maddison, Chris J. and Mnih, Andriy and Teh, Yee Whye},
eprint = {1611.00712},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maddison, Mnih, Teh - 2017 - The concrete distribution A continuous relaxation of discrete random variables.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
pages = {1--20},
title = {{The concrete distribution: A continuous relaxation of discrete random variables}},
year = {2017}
}
@article{Chollet2019,
abstract = {To make deliberate progress towards more intelligent and more human-like artificial systems, we need to be following an appropriate feedback signal: we need to be able to define and evaluate intelligence in a way that enables comparisons between two systems, as well as comparisons with humans. Over the past hundred years, there has been an abundance of attempts to define and measure intelligence, across both the fields of psychology and AI. We summarize and critically assess these definitions and evaluation approaches, while making apparent the two historical conceptions of intelligence that have implicitly guided them. We note that in practice, the contemporary AI community still gravitates towards benchmarking intelligence by comparing the skill exhibited by AIs and humans at specific tasks, such as board games and video games. We argue that solely measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience: unlimited priors or unlimited training data allow experimenters to “buy” arbitrary levels of skills for a system, in a way that masks the system's own generalization power. We then articulate a new formal definition of intelligence based on Algorithmic Information Theory, describing intelligence as skill-acquisition efficiency and highlighting the concepts of scope, generalization difficulty, priors, and experience, as critical pieces to be accounted for in characterizing intelligent systems. Using this definition, we propose a set of guidelines for what a general AI benchmark should look like. Finally, we present a new benchmark closely following these guidelines, the Abstraction and Reasoning Corpus (ARC), built upon an explicit set of priors designed to be as close as possible to innate human priors. We argue that ARC can be used to measure a human-like form of general fluid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.},
archivePrefix = {arXiv},
arxivId = {1911.01547},
author = {Chollet, Fran{\c{c}}ois},
eprint = {1911.01547},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chollet - 2019 - On the Measure of Intelligence.pdf:pdf},
journal = {arXiv},
pages = {1--64},
title = {{On the Measure of Intelligence}},
year = {2019}
}
@article{Lee2019,
abstract = {We design and conduct a simple experiment to study whether neural networks can perform several steps of approximate reasoning in a fixed dimensional latent space. The set of rewrites (i.e. transformations) that can be successfully performed on a statement represents essential semantic features of the statement. We can compress this information by embedding the formula in a vector space, such that the vector associated with a statement can be used to predict whether a statement can be rewritten by other theorems. Predicting the embedding of a formula generated by some rewrite rule is naturally viewed as approximate reasoning in the latent space. In order to measure the effectiveness of this reasoning, we perform approximate deduction sequences in the latent space and use the resulting embedding to inform the semantic features of the corresponding formal statement (which is obtained by performing the corresponding rewrite sequence using real formulas). Our experiments show that graph neural networks can make non-trivial predictions about the rewrite-success of statements, even when they propagate predicted latent representations for several steps. Since our corpus of mathematical formulas includes a wide variety of mathematical disciplines, this experiment is a strong indicator for the feasibility of deduction in latent space in general.},
archivePrefix = {arXiv},
arxivId = {1909.11851},
author = {Lee, Dennis and Szegedy, Christian and Rabe, Markus N. and Loos, Sarah M. and Bansal, Kshitij},
eprint = {1909.11851},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2019 - Mathematical reasoning in latent space.pdf:pdf},
journal = {arXiv},
pages = {1--10},
title = {{Mathematical reasoning in latent space}},
year = {2019}
}
@article{Steenbrugge2018,
abstract = {In this work we explore the generalization characteristics of unsupervised representation learning by leveraging disentangled VAE's to learn a useful latent space on a set of relational reasoning problems derived from Raven Progressive Matrices. We show that the latent representations, learned by unsupervised training using the right objective function, significantly outperform the same architectures trained with purely supervised learning, especially when it comes to generalization.},
archivePrefix = {arXiv},
arxivId = {1811.04784},
author = {Steenbrugge, Xander and Leroux, Sam and Verbelen, Tim and Dhoedt, Bart},
eprint = {1811.04784},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steenbrugge et al. - 2018 - Improving generalization for abstract reasoning tasks using disentangled feature representations.pdf:pdf},
journal = {arXiv},
number = {Nips 2018},
pages = {1--8},
title = {{Improving generalization for abstract reasoning tasks using disentangled feature representations}},
year = {2018}
}
@article{Barrett2018,
abstract = {Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation 'regimes' in which the training and test data differ in clearlydefined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with a structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model's ability to generalise improves markedly if it is trained to predict symbolic explanations for its answers. Altogether, we introduce and explore ways to both measure and induce stronger abstract reasoning in neural networks. Our freely-available dataset should motivate further progress in this direction.},
archivePrefix = {arXiv},
arxivId = {1807.04225},
author = {Barrett, David G.T. and Hill, Felix and Santoro, Adam and Morcos, Ari S. and Lillicrap, Timothy},
eprint = {1807.04225},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrett et al. - 2018 - Measuring abstract reasoning in neural networks.pdf:pdf},
isbn = {9781510867963},
journal = {35th International Conference on Machine Learning, ICML 2018},
pages = {7118--7127},
title = {{Measuring abstract reasoning in neural networks}},
volume = {10},
year = {2018}
}
@article{Hofstadter1994,
abstract = {describe Copycat, a nondeterministic model of analogy making aiming at psychological realism / the authors maintain that the hybrid middle ground in cognitive modeling occupied by Copycat is, at present, the most useful level at which to attempt to understand the fluidity of concepts and perception that is so clearly apparent in human analogy making / argue that nondeterminism is necessary for flexible cognition, and claim that their architecture, being essentially a model of fluid concepts and mental pressures, has validity beyond analogy making (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
author = {Hofstadter, Douglas and Mitchell, Melanie},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hofstadter, Mitchell - 1994 - The copycat project A model of mental fluidity and analogy-making.pdf:pdf},
journal = {Advances in connectionist and neural computation theory},
number = {31-112},
pages = {29--30},
title = {{The copycat project: A model of mental fluidity and analogy-making}},
volume = {2},
year = {1994}
}
@article{Zheng2019,
abstract = {Abstraction reasoning is a long-standing challenge in artificial intelligence. Recent studies suggest that many of the deep architectures that have triumphed over other domains failed to work well in abstract reasoning. In this paper, we first illustrate that one of the main challenges in such a reasoning task is the presence of distracting features, which requires the learning algorithm to leverage counter-evidence and to reject any of the false hypotheses in order to learn the true patterns. We later show that carefully designed learning trajectory over different categories of training data can effectively boost learning performance by mitigating the im-pacts of distracting features. Inspired by this fact, we propose feature robust ab-stract reasoning (FRAR) model, which consists of a reinforcement learning based teacher network to determine the sequence of training and a student network for predictions. Experimental results demonstrated strong improvements over baseline algorithms and we are able to beat the state-of-the-art models by 18.7% in the RAVEN dataset and 13.3% in the PGM dataset.},
archivePrefix = {arXiv},
arxivId = {1912.00569},
author = {Zheng, Kecheng and Zha, Zheng Jun and Wei, Wei},
eprint = {1912.00569},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zheng, Zha, Wei - 2019 - Abstract reasoning with distracting features.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--12},
title = {{Abstract reasoning with distracting features}},
year = {2019}
}
@article{Zhang2020,
abstract = {One of the common ways children learn is by mimicking adults. Imitation learning focuses on learning policies with suitable performance from demonstrations generated by an expert, with an unspecified performance measure, and unobserved reward signal. Popular methods for imitation learning start by either directly mimicking the behavior policy of an expert (behavior cloning) or by learning a reward function that prioritizes observed expert trajectories (inverse reinforcement learning). However, these methods rely on the assumption that covariates used by the expert to determine her/his actions are fully observed. In this paper, we relax this assumption and study imitation learning when sensory inputs of the learner and the expert differ. First, we provide a non-parametric, graphical criterion that is complete (both necessary and sufficient) for determining the feasibility of imitation from the combinations of demonstration data and qualitative assumptions about the underlying environment, represented in the form of a causal model. We then show that when such a criterion does not hold, imitation could still be feasible by exploiting quantitative knowledge of the expert trajectories. Finally, we develop an efficient procedure for learning the imitating policy from experts' trajectories.},
author = {Zhang, Junzhe and Kumor, Daniel and Bareinboim, Elias},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Kumor, Bareinboim - 2020 - Causal Imitation Learning with Unobserved Confounders.pdf:pdf},
journal = {NeurIPS 34th},
number = {NeurIPS},
pages = {1--12},
title = {{Causal Imitation Learning with Unobserved Confounders}},
volume = {33},
year = {2020}
}
@article{Jahrens2019,
abstract = {Relational Networks (RN) as introduced by Santoro et al. in 2017 have demonstrated strong relational reasoning capabilities with a rather shallow architecture. Its single-layer design, however, only considers pairs of information objects, making it unsuitable for problems requiring reasoning across a higher number of facts. To overcome this limitation, we propose a multi-layer relation network architecture which enables successive refinements of relational information through multiple layers. We show that the increased depth allows for more complex relational reasoning by applying it to the bAbI 20 QA dataset, solving all 20 tasks with joint training and surpassing the state-of-the-art results.},
author = {Jahrens, Marius and Martinetz, Thomas},
doi = {10.1145/3309772.3309782},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jahrens, Martinetz - 2019 - Multi-layer Relation Networks for relational reasoning.pdf:pdf},
isbn = {9781450360852},
journal = {ACM International Conference Proceeding Series},
title = {{Multi-layer Relation Networks for relational reasoning}},
year = {2019}
}
@article{Look2020,
abstract = {In this paper, we introduce an efficient backpropagation scheme for non-constrained implicit functions. These functions are parametrized by a set of learnable weights and may optionally depend on some input; making them perfectly suitable as learnable layer in a neural network. We demonstrate our scheme on different applications: (i) neural ODEs with the implicit Euler method, and (ii) system identification in model predictive control.},
archivePrefix = {arXiv},
arxivId = {2010.07078},
author = {Look, Andreas and Doneva, Simona and Kandemir, Melih and Gemulla, Rainer and Peters, Jan},
eprint = {2010.07078},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Look et al. - 2020 - Differentiable Implicit Layers.pdf:pdf},
pages = {1--12},
title = {{Differentiable Implicit Layers}},
url = {http://arxiv.org/abs/2010.07078},
year = {2020}
}
@article{Li2016,
abstract = {This short paper extends the free-energy derivations of variational inference, loopy belief propagation and expectation propagation (EP) to a wider range of approximate inference methods including power EP, distributed EP, and black-box alpha-divergence minimisation. The framework provides a very flexible framework for the design of variational algorithms that can mix versions of any of the aforemen-tioned algorithms inside a single coherent algorithm. The framework is general, extending to latent variable models, for example.},
author = {Li, Yingzhen and Turner, Richard E},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Turner - 2016 - A Unifying Approximate Inference Framework from Variational Free Energy Relaxation.pdf:pdf},
pages = {1--11},
title = {{A Unifying Approximate Inference Framework from Variational Free Energy Relaxation}},
year = {2016}
}
@article{Gershman2019,
abstract = {The free energy principle has been proposed as a unifying account of brain function. It is closely related, and in some cases subsumes, earlier unifying ideas such as Bayesian inference, predictive coding, and active learning. This article clarifies these connections, teasing apart distinctive and shared predictions.},
archivePrefix = {arXiv},
arxivId = {1901.07945},
author = {Gershman, Samuel J.},
eprint = {1901.07945},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gershman - 2019 - What does the free energy principle tell us about the brain.pdf:pdf},
journal = {arXiv},
keywords = {Bayesian brain,Decision theory,Predictive coding,Variational inference},
pages = {1--10},
title = {{What does the free energy principle tell us about the brain?}},
year = {2019}
}
@article{Gong2019,
abstract = {In this paper we introduce the ice-start problem, i.e., the challenge of deploying machine learning models when only little or no training data is initially available, and acquiring each feature element of data is associated with costs. This setting is representative for the real-world machine learning applications. For instance, in the health-care domain, when training an AI system for predicting patient metrics from lab tests, obtaining every single measurement comes with a high cost. Active learning, where only the label is associated with a cost does not apply to such problem, because performing all possible lab tests to acquire a new training datum would be costly, as well as unnecessary due to redundancy. We propose Icebreaker, a principled framework to approach the ice-start problem. Icebreaker uses a full Bayesian Deep Latent Gaussian Model (BELGAM) with a novel inference method. Our proposed method combines recent advances in amortized inference and stochastic gradient MCMC to enable fast and accurate posterior inference. By utilizing BELGAM's ability to fully quantify model uncertainty, we also propose two information acquisition functions for imputation and active prediction problems. We demonstrate that BELGAM performs significantly better than the previous VAE (Variational autoencoder) based models, when the data set size is small, using both machine learning benchmarks and real-world recommender systems and health-care applications. Moreover, based on BELGAM, Icebreaker further improves the performance and demonstrate the ability to use minimum amount of the training data to obtain the highest test time performance.},
archivePrefix = {arXiv},
arxivId = {1908.04537},
author = {Gong, Wenbo and Tschiatschek, Sebastian and Turner, Richard and Nowozin, Sebastian and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel and Zhang, Cheng},
eprint = {1908.04537},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gong et al. - 2019 - Icebreaker Element-wise active information acquisition with bayesian deep latent gaussian model.pdf:pdf},
journal = {arXiv},
title = {{Icebreaker: Element-wise active information acquisition with bayesian deep latent gaussian model}},
year = {2019}
}
@article{Zhang2020a,
abstract = {We present a causal view on the robustness of neural networks against input manipulations, which applies not only to traditional classification tasks but also to general measurement data. Based on this view, we design a deep causal manipulation augmented model (deep CAMA) which explicitly models possible manipulations on certain causes leading to changes in the observed effect. We further develop data augmentation and test-time fine-tuning methods to improve deep CAMA's robustness. When compared with discriminative deep neural networks, our proposed model shows superior robustness against unseen manipulations. As a by-product, our model achieves disentangled representation which separates the representation of manipulations from those of other latent causes.},
archivePrefix = {arXiv},
arxivId = {2005.01095},
author = {Zhang, Cheng and Zhang, Kun and Li, Yingzhen},
eprint = {2005.01095},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhang, Li - 2020 - A Causal View on Robustness of Neural Networks.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--21},
title = {{A Causal View on Robustness of Neural Networks}},
year = {2020}
}
@article{Ma2019,
abstract = {Many real-life decision making situations allow further relevant information to be acquired at a specific cost, for example, in assessing the health status of a patient we may decide to take additional measurements such as diagnostic tests or imaging scans before making a final assessment. Acquiring more relevant information enables better decision making, but may be costly. How can we trade off the desire to make good decisions by acquiring further information with the cost of performing that acquisition? To this end, we propose a principled framework, named EDDI (Efficient Dynamic Discovery of high-value Information), based on the theory of Bayesian experimental design. In KDDI, we propose a novel partial variational autoencoder (Partial VAE) to predict missing data entries problematically given any subset of the observed ones, and combine it with an acquisition function that maximizes expected information gain on a set of target variables. We show cost reduction at the same decision quality and improved decision quality at the same cost in multiple machine learning benchmarks and two real-world health-care applications.},
archivePrefix = {arXiv},
arxivId = {1809.11142},
author = {Ma, Chao and Tschiatschek, Sebastian and Palla, Konstantina and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel and Nowozin, Sebastian and Zhang, Cheng},
eprint = {1809.11142},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2019 - EdDI Efficient dynamic discovery of high-value information with partial VAE.pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
pages = {7483--7504},
title = {{EdDI: Efficient dynamic discovery of high-value information with partial VAE}},
volume = {2019-June},
year = {2019}
}
@article{Li2018,
abstract = {Neural network training relies on our ability to find “good” minimizers of highly non-convex loss functions. It is well-known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and well-chosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effect on the underlying loss landscape, are not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple “filter normalization” method that helps us visualize loss function curvature and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.},
archivePrefix = {arXiv},
arxivId = {1712.09913},
author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
eprint = {1712.09913},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2018 - Visualizing the loss landscape of neural nets.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips 2018},
pages = {6389--6399},
title = {{Visualizing the loss landscape of neural nets}},
volume = {2018-Decem},
year = {2018}
}
@article{Blass2018,
abstract = {A signed probability distribution may extend a given traditional probability from observable events to all events. We formalize and illustrate this approach. We also illustrate its limitation. We argue that the right question is not what negative probabilities are but what they are for.},
archivePrefix = {arXiv},
arxivId = {2009.10552},
author = {Blass, Andreas and Gurevich, Yuri},
eprint = {2009.10552},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blass, Gurevich - 2018 - Negative probabilities, II what they are and what they are for.pdf:pdf},
journal = {arXiv},
pages = {1--24},
title = {{Negative probabilities, II what they are and what they are for}},
year = {2018}
}
@article{Heyes2018,
abstract = {Cognitive gadgets are distinctively human neurocognitive mechanisms - such as imitation, mindreading, and language - that have been shaped by cultural rather than genetic evolution. New gadgets emerge, not by genetic mutation, but by innovations in cognitive development; they are specialised cognitive mechanisms built by general cognitive mechanisms using information from the sociocultural environment. Innovations are passed on to subsequent generations, not by DNA replication, but through social learning: people with a new cognitive mechanism pass it on to others through social interaction. And some of the new mechanisms, like literacy, have spread through human populations, while others have died out, because the holders had more students, not just more babies. The cognitive gadgets hypothesis is developed through four case studies, drawing on evidence from comparative and developmental psychology, experimental psychology and cognitive neuroscience. The framework employed, cultural evolutionary psychology, a descendant of evolutionary psychology and cultural evolutionary theory, addresses parallel issues across the cognitive and behavioural sciences. In common with evo-devo and the extended evolutionary synthesis, cultural evolutionary psychology underlines the importance of developmental processes and environmental factors in the emergence of human cognition. In common with computational approaches (deep learning, predictive coding, hierarchical reinforcement learning, causal modelling) it emphasises the power of general-purpose mechanisms of learning. However, cultural evolutionary psychology also challenges use of the behavioural gambit in economics and behavioral ecology, and rejects the view that human minds are composed of 'innate modules' or 'cognitive instincts'.},
author = {Heyes, Cecilia},
doi = {10.1017/S0140525X18002145},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heyes - 2018 - Pr{\'{e}}cis of Cognitive Gadgets The Cultural Evolution of Thinking.pdf:pdf},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
keywords = {cultural evolution,domain-specific/domain-general,evolutionary psychology,innateness,social construction,teleosemantics},
title = {{Pr{\'{e}}cis of Cognitive Gadgets: The Cultural Evolution of Thinking}},
volume = {42},
year = {2018}
}
@article{Lampinen2020,
abstract = {An important aspect of intelligence is the ability to adapt to a novel task without any direct experience (zero-shot), based on its relationship to previous tasks. Humans can exhibit this cognitive flexibility. By contrast, deep-learning models that achieve superhuman performance in specific tasks generally fail to adapt to even slight task alterations. To address this, we propose a general computational framework for adapting to novel tasks based on their relationship to prior tasks. We begin by learning vector representations of tasks. To adapt to new tasks, we propose meta-mappings, higher-order tasks that transform basic task representations. We demonstrate this framework across a wide variety of tasks and computational paradigms, ranging from regression to image classification and reinforcement learning. We compare to both human adaptability, and language-based approaches to zero-shot learning. Across these domains, meta-mapping is successful, often achieving 80-90% performance, without any data, on a novel task that directly contradicts its prior experience. We further show that using meta-mapping as a starting point can dramatically accelerate later learning on a new task, and reduce learning time and cumulative error substantially. Our results provide insight into a possible computational basis of intelligent adaptability, and offer a possible framework for modeling cognitive flexibility and building more flexible artificial intelligence.},
archivePrefix = {arXiv},
arxivId = {arXiv:2005.04318v3},
author = {Lampinen, Andrew K. and McClelland, James L.},
eprint = {arXiv:2005.04318v3},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lampinen, McClelland - 2020 - Transforming task representations to allow deep learning models to perform novel tasks.pdf:pdf},
journal = {arXiv},
title = {{Transforming task representations to allow deep learning models to perform novel tasks}},
year = {2020}
}
@book{VanOpheusden2020,
abstract = {The fate of scientific hypotheses often relies on the ability of a computational model to explain the data, quantified in modern statistical approaches by the likelihood function. The log-likelihood is the key element for parameter estimation and model evaluation. However, the log-likelihood of complex models in fields such as computational biology and neuroscience is often intractable to compute analytically or numerically. In those cases, researchers can often only estimate the log-likelihood by comparing observed data with synthetic observations generated by model simulations. Standard techniques to approximate the likelihood via simulation either use summary statistics of the data or are at risk of producing severe biases in the estimate. Here, we explore another method, inverse binomial sampling (IBS), which can estimate the log-likelihood of an entire data set efficiently and without bias. For each observation, IBS draws samples from the simulator model until one matches the observation. The log-likelihood estimate is then a function of the number of samples drawn. The variance of this estimator is uniformly bounded, achieves the minimum variance for an unbiased estimator, and we can compute calibrated estimates of the variance. We provide theoretical arguments in favor of IBS and an empirical assessment of the method for maximum-likelihood estimation with simulation-based models. As case studies, we take three model-fitting problems of increasing complexity from computational and cognitive neuroscience. In all problems, IBS generally produces lower error in the estimated parameters and maximum log-likelihood values than alternative sampling methods with the same average number of samples. Our results demonstrate the potential of IBS as a practical, robust, and easy to implement method for log-likelihood evaluation when exact techniques are not available.},
archivePrefix = {arXiv},
arxivId = {2001.03985},
author = {van Opheusden, Bas and Acerbi, Luigi and Ma, Wei Ji},
booktitle = {arXiv},
doi = {10.1371/journal.pcbi.1008483},
eprint = {2001.03985},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Opheusden, Acerbi, Ma - 2020 - Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial Sampling.pdf:pdf},
isbn = {1111111111},
keywords = {Likelihood-free inference,Maximum-likelihood estimation,Simulation model},
pages = {1--32},
title = {{Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial Sampling}},
url = {http://dx.doi.org/10.1371/journal.pcbi.1008483},
year = {2020}
}
@article{Wilson2020,
abstract = {The key distinguishing property of a Bayesian approach is marginalization, rather than using a single setting of weights. Bayesian marginalization can particularly improve the accuracy and calibration of modern deep neural networks, which are typically underspecified by the data, and can represent many compelling but different solutions. We show that deep ensembles provide an effective mechanism for approximate Bayesian marginalization, and propose a related approach that further improves the predictive distribution by marginalizing within basins of attraction, without significant overhead. We also investigate the prior over functions implied by a vague distribution over neural network weights, explaining the generalization properties of such models from a probabilistic perspective. From this perspective, we explain results that have been presented as mysterious and distinct to neural network generalization, such as the ability to fit images with random labels, and show that these results can be reproduced with Gaussian processes. We also show that Bayesian model averaging alleviates double descent, resulting in monotonic performance improvements with increased flexibility. Finally, we provide a Bayesian perspective on tempering for calibrating predictive distributions.},
archivePrefix = {arXiv},
arxivId = {2002.08791},
author = {Wilson, Andrew Gordon and Izmailov, Pavel},
eprint = {2002.08791},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilson, Izmailov - 2020 - Bayesian deep learning and a probabilistic perspective of generalization.pdf:pdf},
journal = {arXiv},
number = {3},
title = {{Bayesian deep learning and a probabilistic perspective of generalization}},
year = {2020}
}
@article{Sun2020,
abstract = {The brain codes continuous spatial, temporal and sensory changes in daily experience. Recent studies suggest that the brain also tracks experience as segmented subdivisions (events), but the neural basis for encoding events remains unclear. Here, we designed a maze for mice, composed of four materially indistinguishable lap events, and identify hippocampal CA1 neurons whose activity are modulated not only by spatial location but also lap number. These ‘event-specific rate remapping' (ESR) cells remain lap-specific even when the maze length is unpredictably altered within trials, which suggests that ESR cells treat lap events as fundamental units. The activity pattern of ESR cells is reused to represent lap events when the maze geometry is altered from square to circle, which suggests that it helps transfer knowledge between experiences. ESR activity is separately manipulable from spatial activity, and may therefore constitute an independent hippocampal code: an ‘event code' dedicated to organizing experience by events as discrete and transferable units.},
author = {Sun, Chen and Yang, Wannan and Martin, Jared and Tonegawa, Susumu},
doi = {10.1038/s41593-020-0614-x},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2020 - Hippocampal neurons represent events as transferable units of experience.pdf:pdf},
issn = {15461726},
journal = {Nature Neuroscience},
number = {5},
pages = {651--663},
pmid = {32251386},
publisher = {Springer US},
title = {{Hippocampal neurons represent events as transferable units of experience}},
url = {http://dx.doi.org/10.1038/s41593-020-0614-x},
volume = {23},
year = {2020}
}
@article{Dong2020a,
abstract = {Traditional change detection (CD) methods operate in the simple image domain or hand-crafted features, which has less robustness to the inconsistencies (e.g., brightness and noise distribution, etc.) between bitemporal satellite images. Recently, deep learning techniques have reported compelling performance on robust feature learning. However, generating accurate semantic supervision that reveals real change information in satellite images still remains challenging, especially for manual annotation. To solve this problem, we propose a novel self-supervised representation learning method based on temporal prediction for remote sensing image CD. The main idea of our algorithm is to transform two satellite images into more consistent feature representations through a self-supervised mechanism without semantic supervision and any additional computations. Based on the transformed feature representations, a better difference image (DI) can be obtained, which reduces the propagated error of DI on the final detection result. In the self-supervised mechanism, the network is asked to identify different sample patches between two temporal images, namely, temporal prediction. By designing the network for the temporal prediction task to imitate the discriminator of generative adversarial networks, the distribution-aware feature representations are automatically captured and the result with powerful robustness can be acquired. Experimental results on real remote sensing data sets show the effectiveness and superiority of our method, improving the detection precision up to 0.94-35.49%.},
author = {Dong, Huihui and Ma, Wenping and Wu, Yue and Zhang, Jun and Jiao, Licheng},
doi = {10.3390/rs12111868},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong et al. - 2020 - Self-supervised representation learning for remote sensing image change detection based on temporal prediction.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Deep belief networks,Generative adversarial networks,Remote sensing images,Self-supervised representation learning,Unsupervised change detection},
number = {11},
pages = {1--38},
title = {{Self-supervised representation learning for remote sensing image change detection based on temporal prediction}},
volume = {12},
year = {2020}
}
@article{Song2020,
abstract = {Syntactic structure of a sentence text is correlated with the prosodic structure of the speech that is crucial for improving the prosody and naturalness of a text-to-speech (TTS) system. Nowadays TTS systems usually try to incorporate syntactic structure information with manually designed features based on expert knowledge. In this paper, we propose a syntactic representation learning method based on syntactic parse tree traversal to automatically utilize the syntactic structure information. Two constituent label sequences are linearized through left-first and right-first traversals from constituent parse tree. Syntactic representations are then extracted at word level from each constituent label sequence by a corresponding uni-directional gated recurrent unit (GRU) network. Meanwhile, nuclear-norm maximization loss is introduced to enhance the discriminability and diversity of the embeddings of constituent labels. Upsampled syntactic representations and phoneme embeddings are concatenated to serve as the encoder input of Tacotron2. Experimental results demonstrate the effectiveness of our proposed approach, with mean opinion score (MOS) increasing from 3.70 to 3.82 and ABX preference exceeding by 17% compared with the baseline. In addition, for sentences with multiple syntactic parse trees, prosodic differences can be clearly perceived from the synthesized speeches.},
archivePrefix = {arXiv},
arxivId = {2012.06971},
author = {Song, Changhe and Li, Jingbei and Zhou, Yixuan and Wu, Zhiyong and Meng, Helen},
eprint = {2012.06971},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2020 - Syntactic representation learning for neural network based TTS with syntactic parse tree traversal.pdf:pdf},
pages = {2--6},
title = {{Syntactic representation learning for neural network based TTS with syntactic parse tree traversal}},
url = {http://arxiv.org/abs/2012.06971},
year = {2020}
}
@article{Li2020,
abstract = {Low-dimension graph embeddings have proved extremely useful in various downstream tasks in large graphs, e.g., link-related content recommendation and node classification tasks, etc. Most existing embedding approaches take nodes as the basic unit for information aggregation, e.g., node perception fields in GNN or con-textual nodes in random walks. The main drawback raised by such node-view is its lack of support for expressing the compound relationships between nodes, which results in the loss of a certain degree of graph information during embedding. To this end, this paper pro-poses PairE(Pair Embedding), a solution to use "pair", a higher level unit than a "node" as the core for graph embeddings. Accordingly, a multi-self-supervised auto-encoder is designed to fulfill two pretext tasks, to reconstruct the feature distribution for respective pairs and their surrounding context. PairE has three major advantages: 1) Informative, embedding beyond node-view are capable to preserve richer information of the graph; 2) Simple, the solutions provided by PairE are time-saving, storage-efficient, and require the fewer hyper-parameters; 3) High adaptability, with the introduced translator operator to map pair embeddings to the node embeddings, PairE can be effectively used in both the link-based and the node-based graph analysis. Experiment results show that PairE consistently outperforms the state of baselines in all four downstream tasks, especially with significant edges in the link-prediction and multi-label node classification tasks.},
archivePrefix = {arXiv},
arxivId = {2012.06113},
author = {Li, You and Luo, Binli and Gui, Ning},
eprint = {2012.06113},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Luo, Gui - 2020 - Pair-view Unsupervised Graph Representation Learning.pdf:pdf},
title = {{Pair-view Unsupervised Graph Representation Learning}},
url = {http://arxiv.org/abs/2012.06113},
year = {2020}
}
@article{Sariyildiz2020,
abstract = {Measuring concept generalization, i.e., the extent to which models trained on a set of (seen) visual concepts can be used to recognize a new set of (unseen) concepts, is a popular way of evaluating visual representations, especially when they are learned with self-supervised learning. Nonetheless, the choice of which unseen concepts to use is usually made arbitrarily, and independently from the seen concepts used to train representations, thus ignoring any semantic relationships between the two. In this paper, we argue that semantic relationships between seen and unseen concepts affect generalization performance and propose ImageNet-CoG, a novel benchmark on the ImageNet dataset that enables measuring concept generalization in a principled way. Our benchmark leverages expert knowledge that comes from WordNet in order to define a sequence of unseen ImageNet concept sets that are semantically more and more distant from the ImageNet-1K subset, a ubiquitous training set. This allows us to benchmark visual representations learned on ImageNet-1K out-of-the box: we analyse a number of such models from supervised, semi-supervised and self-supervised approaches under the prism of concept generalization, and show how our benchmark is able to uncover a number of interesting insights. We will provide resources for the benchmark at https://europe.naverlabs.com/cog-benchmark.},
archivePrefix = {arXiv},
arxivId = {2012.05649},
author = {Sariyildiz, Mert Bulent and Kalantidis, Yannis and Larlus, Diane and Alahari, Karteek},
eprint = {2012.05649},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sariyildiz et al. - 2020 - Concept Generalization in Visual Representation Learning.pdf:pdf},
title = {{Concept Generalization in Visual Representation Learning}},
url = {http://arxiv.org/abs/2012.05649},
year = {2020}
}
@article{Cortese2020,
author = {Cortese, Aurelio and Yamamoto, Asuka and Hashemzadeh, Maryam and Sepulveda, Pradyumna and Kawato, Mitsuo and Martino, Benedetto De},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cortese et al. - 2020 - Value Shapes Abstraction During Learning.pdf:pdf},
journal = {PsyArXiv},
keywords = {abstraction,fmri,hippocampus,multivoxel neurofeedback,neural reinforcement,reinforcement learning,sensory features,vmpfc},
pages = {1--36},
title = {{Value Shapes Abstraction During Learning}},
year = {2020}
}
@article{VanRullen2020,
abstract = {Recent advances in deep learning have allowed Artificial Intelligence (AI) to reach near human-level performance in many sensory, perceptual, linguistic or cognitive tasks. There is a growing need, however, for novel, brain-inspired cognitive architectures. The Global Workspace theory refers to a large-scale system integrating and distributing information among networks of specialized modules to create higher-level forms of cognition and awareness. We argue that the time is ripe to consider explicit implementations of this theory using deep learning techniques. We propose a roadmap based on unsupervised neural translation between multiple latent spaces (neural networks trained for distinct tasks, on distinct sensory inputs and/or modalities) to create a unique, amodal global latent workspace (GLW). Potential functional advantages of GLW are reviewed.},
archivePrefix = {arXiv},
arxivId = {2012.10390},
author = {VanRullen, Rufin and Kanai, Ryota},
eprint = {2012.10390},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/VanRullen, Kanai - 2020 - Deep Learning and the Global Workspace Theory.pdf:pdf},
pages = {1--16},
title = {{Deep Learning and the Global Workspace Theory}},
url = {http://arxiv.org/abs/2012.10390},
year = {2020}
}
@article{Ding2020,
abstract = {Neural networks have achieved success in a wide array of perceptual tasks, but it is often stated that they are incapable of solving tasks that require higher-level reasoning. Two new task domains, CLEVRER and CATER, have recently been developed to focus on reasoning, as opposed to perception, in the context of spatio-temporal interactions between objects. Initial experiments on these domains found that neuro-symbolic approaches, which couple a logic engine and language parser with a neural perceptual front-end, substantially outperform fully-learned distributed networks, a finding that was taken to support the above thesis. Here, we show on the contrary that a fully-learned neural network with the right inductive biases can perform substantially better than all previous neural-symbolic models on both of these tasks, particularly on questions that most emphasize reasoning over perception. Our model makes critical use of both self-attention and learned "soft" object-centric representations, as well as BERT-style semi-supervised predictive losses. These flexible biases allow our model to surpass the previous neuro-symbolic state-of-the-art using less than 60% of available labelled data. Together, these results refute the neuro-symbolic thesis laid out by previous work involving these datasets, and they provide evidence that neural networks can indeed learn to reason effectively about the causal, dynamic structure of physical events.},
archivePrefix = {arXiv},
arxivId = {2012.08508},
author = {Ding, David and Hill, Felix and Santoro, Adam and Botvinick, Matt},
eprint = {2012.08508},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - 2020 - Object-based attention for spatio-temporal reasoning Outperforming neuro-symbolic models with flexible distributed.pdf:pdf},
title = {{Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architectures}},
url = {http://arxiv.org/abs/2012.08508},
year = {2020}
}
@article{Mohammadi2020,
abstract = {The effective application of representation learning to real-world problems requires both techniques for learning useful representations, and also robust ways to evaluate properties of representations. Recent work in disentangled representation learning has shown that unsupervised representation learning approaches rely on fully supervised disentanglement metrics, which assume access to labels for ground-truth factors of variation. In many real-world cases ground-truth factors are expensive to collect, or difficult to model, such as for perception. Here we empirically show that a weakly-supervised downstream task based on odd-one-out observations is suitable for model selection by observing high correlation on a difficult downstream abstract visual reasoning task. We also show that a bespoke metric-learning VAE model which performs highly on this task also out-performs other standard unsupervised and a weakly-supervised disentanglement model across several metrics.},
archivePrefix = {arXiv},
arxivId = {2012.07966},
author = {Mohammadi, Salman and Uhrenholt, Anders Kirk and Jensen, Bj{\o}rn Sand},
eprint = {2012.07966},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohammadi, Uhrenholt, Jensen - 2020 - Odd-One-Out Representation Learning.pdf:pdf},
title = {{Odd-One-Out Representation Learning}},
url = {http://arxiv.org/abs/2012.07966},
year = {2020}
}
@article{Wortsman2020,
abstract = {We present the Supermasks in Superposition (SupSup) model, capable of sequentially learning thousands of tasks without catastrophic forgetting. Our approach uses a randomly initialized, fixed base network and for each task finds a subnetwork (supermask) that achieves good performance. If task identity is given at test time, the correct subnetwork can be retrieved with minimal memory usage. If not provided, SupSup can infer the task using gradient-based optimization to find a linear superposition of learned supermasks which minimizes the output entropy. In practice we find that a single gradient step is often sufficient to identify the correct mask, even among 2500 tasks. We also showcase two promising extensions. First, SupSup models can be trained entirely without task identity information, as they may detect when they are uncertain about new data and allocate an additional supermask for the new training distribution. Finally the entire, growing set of supermasks can be stored in a constant-sized reservoir by implicitly storing them as attractors in a fixed-sized Hopfield network.},
archivePrefix = {arXiv},
arxivId = {2006.14769},
author = {Wortsman, Mitchell and Ramanujan, Vivek and Liu, Rosanne and Kembhavi, Aniruddha and Rastegari, Mohammad and Yosinski, Jason and Farhadi, Ali},
eprint = {2006.14769},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wortsman et al. - 2020 - Supermasks in Superposition.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Supermasks in Superposition}},
year = {2020}
}
@article{Zhang2019a,
abstract = {Understanding deep neural networks has been a major research objective in recent years with notable theoretical progress. A focal point of those studies stems from the success of excessively large networks which defy the classical wisdom of uniform convergence and learnability. We study empirically the layer-wise functional structure of overparameterized deep models. We provide evidence for the heterogeneous characteristic of layers. To do so, we introduce the notion of robustness to post-training re-initialization and re-randomization. We show that the layers can be categorized as either "ambient" or "critical". Resetting the ambient layers to their initial values has no negative consequence, and in many cases they barely change throughout training. On the contrary, resetting the critical layers completely destroys the predictor and the performance drops to chanceh. Our study provides further evidence that mere parameter counting or norm accounting is too coarse in studying generalization of deep models, and flatness or robustness analysis of the models needs to respect the network architectures.},
archivePrefix = {arXiv},
arxivId = {1902.01996},
author = {Zhang, Chiyuan and Bengio, Samy and Singer, Yoram},
eprint = {1902.01996},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Bengio, Singer - 2019 - Are all layers created equal.pdf:pdf},
journal = {arXiv},
pages = {1--18},
title = {{Are all layers created equal?}},
year = {2019}
}
@article{Zhou2018,
abstract = {—Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
archivePrefix = {arXiv},
arxivId = {1812.08434},
author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
eprint = {1812.08434},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2018 - Graph Neural Networks A Review of Methods and Applications.pdf:pdf},
journal = {arXiv},
keywords = {Deep Learning,,Graph Neural Network},
pages = {1--22},
title = {{Graph Neural Networks: A Review of Methods and Applications}},
year = {2018}
}
@article{Kunin2020,
abstract = {Predicting the dynamics of neural network parameters during training is one of the key challenges in building a theoretical foundation for deep learning. A central obstacle is that the motion of a network in high-dimensional parameter space undergoes discrete finite steps along complex stochastic gradients derived from real-world datasets. We circumvent this obstacle through a unifying theoretical framework based on intrinsic symmetries embedded in a network's architecture that are present for any dataset. We show that any such symmetry imposes stringent geometric constraints on gradients and Hessians, leading to an associated conservation law in the continuous-time limit of stochastic gradient descent (SGD), akin to Noether's theorem in physics. We further show that finite learning rates used in practice can actually break these symmetry induced conservation laws. We apply tools from finite difference methods to derive modified gradient flow, a differential equation that better approximates the numerical trajectory taken by SGD at finite learning rates. We combine modified gradient flow with our framework of symmetries to derive exact integral expressions for the dynamics of certain parameter combinations. We empirically validate our analytic predictions for learning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting symmetry, our work demonstrates that we can analytically describe the learning dynamics of various parameter combinations at finite learning rates and batch sizes for state of the art architectures trained on any dataset.},
archivePrefix = {arXiv},
arxivId = {2012.04728},
author = {Kunin, Daniel and Sagastuy-Brena, Javier and Ganguli, Surya and Yamins, Daniel L. K. and Tanaka, Hidenori},
eprint = {2012.04728},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kunin et al. - 2020 - Neural Mechanics Symmetry and Broken Conservation Laws in Deep Learning Dynamics.pdf:pdf},
title = {{Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics}},
url = {http://arxiv.org/abs/2012.04728},
year = {2020}
}
@article{Anonymous2021,
abstract = {Thanks to the tractability of their likelihood, some deep generative models show promise for seemingly straightforward but important applications like anomaly detection, uncertainty estimation, and active learning. However, the likelihood values empirically attributed to anomalies conflict with the expectations these proposed applications suggest. In this paper, we take a closer look at the behavior of distribution densities and show that these quantities carry less meaningful information than previously thought, beyond estimation issues or the curse of dimensionality. We conclude that the use of these likelihoods for out-of-distribution detection relies on strong and implicit hypotheses, and highlight the necessity of explicitly formulating these assumptions for reliable anomaly detection.},
archivePrefix = {arXiv},
arxivId = {arXiv:2012.03808v1},
author = {Lan, Charline Le and Dinh, Laurent},
eprint = {arXiv:2012.03808v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anonymous - 2021 - Perfect density models cannot guarantee anomaly detection.pdf:pdf},
journal = {Submitted to International Conference on Learning Representations},
pages = {1--12},
title = {{Perfect density models cannot guarantee anomaly detection}},
url = {https://openreview.net/forum?id=MkrAyYVmt7b},
year = {2021}
}
@article{Maire2020,
abstract = {We create a framework for bootstrapping visual representation learning from a primitive visual grouping capability. We operationalize grouping via a contour detector that partitions an image into regions, followed by merging of those regions into a tree hierarchy. A small supervised dataset suffices for training this grouping primitive. Across a large unlabeled dataset, we apply this learned primitive to automatically predict hierarchical region structure. These predictions serve as guidance for self-supervised contrastive feature learning: we task a deep network with producing per-pixel embeddings whose pairwise distances respect the region hierarchy. Experiments demonstrate that our approach can serve as state-of-the-art generic pre-training, benefiting downstream tasks. We additionally explore applications to semantic region search and video-based object instance tracking.},
archivePrefix = {arXiv},
arxivId = {arXiv:2012.03044v1},
author = {Maire, Michael},
eprint = {arXiv:2012.03044v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maire - 2020 - Self-Supervised Visual Representation Learning from Hierarchical Grouping.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Self-Supervised Visual Representation Learning from Hierarchical Grouping}},
year = {2020}
}
@article{Stooke2020,
abstract = {In an effort to overcome limitations of reward-driven feature learning in deep reinforcement learning (RL) from images, we propose decoupling representation learning from policy learning. To this end, we introduce a new unsupervised learning (UL) task, called Augmented Temporal Contrast (ATC), which trains a convolutional encoder to associate pairs of observations separated by a short time difference, under image augmentations and using a contrastive loss. In online RL experiments, we show that training the encoder exclusively using ATC matches or outperforms end-to-end RL in most environments. Additionally, we benchmark several leading UL algorithms by pre-training encoders on expert demonstrations and using them, with weights frozen, in RL agents; we find that agents using ATC-trained encoders outperform all others. We also train multi-task encoders on data from multiple environments and show generalization to different downstream RL tasks. Finally, we ablate components of ATC, and introduce a new data augmentation to enable replay of (compressed) latent images from pre-trained encoders when RL requires augmentation. Our experiments span visually diverse RL benchmarks in DeepMind Control, DeepMind Lab, and Atari, and our complete code is available at https://github.com/astooke/rlpyt/tree/master/rlpyt/ul.},
archivePrefix = {arXiv},
arxivId = {2009.08319},
author = {Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
eprint = {2009.08319},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stooke et al. - 2020 - Decoupling Representation Learning from Reinforcement Learning.pdf:pdf},
title = {{Decoupling Representation Learning from Reinforcement Learning}},
url = {http://arxiv.org/abs/2009.08319},
year = {2020}
}
@article{Hudson2018,
abstract = {We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.},
archivePrefix = {arXiv},
arxivId = {1803.03067},
author = {Hudson, Drew A. and Manning, Christopher D.},
eprint = {1803.03067},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hudson, Manning - 2018 - Compositional attention networks for machine reasoning.pdf:pdf},
journal = {arXiv},
pages = {1--20},
title = {{Compositional attention networks for machine reasoning}},
year = {2018}
}
@article{Schmidhuber2009,
abstract = {I argue that data becomes temporarily interesting by itself to some self-improving, but computationally limited, subjective observer once he learns to predict or compress the data in a better way, thus making it subjectively simpler and more beautiful. Curiosity is the desire to create or discover more non-random, non-arbitrary, regular data that is novel and surprising not in the traditional sense of Boltzmann and Shannon but in the sense that it allows for compression progress because its regularity was not yet known. This drive maximizes interestingness, the first derivative of subjective beauty or compressibility, that is, the steepness of the learning curve. It motivates exploring infants, pure mathematicians, composers, artists, dancers, comedians, yourself, and (since 1990) artificial systems. {\textcopyright} 2009 Springer Berlin Heidelberg.},
archivePrefix = {arXiv},
arxivId = {0812.4360},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1007/978-3-642-02565-5_4},
eprint = {0812.4360},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmidhuber - 2009 - Driven by compression progress A simple principle explains essential aspects of subjective beauty, novelty, surpris.pdf:pdf},
isbn = {3642025641},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {April 2009},
pages = {48--76},
title = {{Driven by compression progress: A simple principle explains essential aspects of subjective beauty, novelty, surprise, interestingness, attention, curiosity, creativity, art, science, music, jokes}},
volume = {5499 LNAI},
year = {2009}
}
@article{Sutton2015,
abstract = {Learning, planning, and representing knowledge at multiple levels of temporal abstraction are key, longstanding challenges for AI. In this paper we consider how these challenges can be addressed within the mathematical framework of reinforcement learning and Markov decision processes (MDPs). We extend the usual notion of action in this framework to include options—closed-loop policies for taking action over a period of time. Examples of options include picking up an object, going to lunch, and traveling to a distant city, as well as primitive actions such as muscle twitches and joint torques. Overall, we show that options enable temporally abstract knowledge and action to be included in the reinforcement learning framework in a natural and general way. In particular, we show that options may be used interchangeably with primitive actions in planning methods such as dynamic programming and in learning methods such as Q-learning. Formally, a set of options defined over an MDP constitutes a semi-Markov decision process (SMDP), and the theory ofSMDPs provides the foundation for the theory of options. However, the most interesting issues concern the interplay between the underlying MDP and the SMDP and are thus beyond SMDP theory. We present results for three such cases: (1) we show that the results of planning with options can be used during execution to interrupt options and thereby perform even better than planned, (2) we introduce new intra-option methods that are able to learn about an option from fragments of its execution, and (3) we propose a notion of subgoal that can be used to improve the options themselves. All of these results have precursors in the existing literature; the contribution of this paper is to establish them in a simpler and more general setting with fewer changes to the existing reinforcement learning framework. In particular, we show that these results can be obtained without committing to (or ruling out) any particular approach to state abstraction, hierarchy, function approximation, or the macro- utility problem.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Sutton, Richard S.; and Precup, Doina; and Singh, Satinder},
eprint = {arXiv:1011.1669v3},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton, Precup, Singh - 2015 - Between MDPs and Semi-MDPs A Framework for Temporal Abstraction in RL.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Statewide Agricultural Land Use Baseline 2015},
keywords = {icle},
number = {1},
pages = {181--211},
pmid = {25246403},
title = {{Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in RL}},
volume = {1},
year = {2015}
}
@article{Momennejad2020,
abstract = {Memory and planning rely on learning the structure of relationships among experiences. Compact representations of these structures guide flexible behavior in humans and animals. A century after ‘latent learning' experiments summarized by Tolman, the larger puzzle of cognitive maps remains elusive: how does the brain learn and generalize relational structures? This review focuses on a reinforcement learning (RL) approach to learning compact representations of the structure of states. We review evidence showing that capturing structures as predictive representations updated via replay offers a neurally plausible account of human behavior and the neural representations of predictive cognitive maps. We highlight multi-scale successor representations, prioritized replay, and policy-dependence. These advances call for new directions in studying the entanglement of learning and memory with prediction and planning.},
author = {Momennejad, Ida},
doi = {10.1016/j.cobeha.2020.02.017},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Momennejad - 2020 - Learning Structures Predictive Representations, Replay, and Generalization.pdf:pdf},
issn = {23521546},
journal = {Current Opinion in Behavioral Sciences},
pages = {155--166},
publisher = {Elsevier Ltd},
title = {{Learning Structures: Predictive Representations, Replay, and Generalization}},
url = {https://doi.org/10.1016/j.cobeha.2020.02.017},
volume = {32},
year = {2020}
}
@article{Uria2020,
author = {Uria, Benigno and Ibarz, Borja and Banino, Andrea and Zambaldi, Vinicius and Kumaran, Dharshan},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Uria et al. - 2020 - The Spatial Memory Pipeline a model of egocentric to allocentric understanding in mammalian brains.pdf:pdf},
pages = {1--52},
title = {{The Spatial Memory Pipeline : a model of egocentric to allocentric understanding in mammalian brains}},
year = {2020}
}
@article{Knudsen2020,
author = {Knudsen, EB and Wallis, JD},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2020 - Hippocampal neurons construct a map of an abstract value space.pdf:pdf},
title = {{Hippocampal neurons construct a map of an abstract value space}},
year = {2020}
}
@article{Marschall2019,
abstract = {To which extent can successful machine learning inform our understanding of biological learning? One popular avenue of inquiry in recent years has been to directly map such algorithms into a realistic circuit implementation. Here we focus on learning in recurrent networks and investigate a range of learning algorithms. Our approach decomposes them into their computational building blocks and discusses their abstract potential as biological operations. This alternative strategy provides a "lazy" but principled way of evaluating ML ideas in terms of their biological plausibility. The phenomenal success of neurally inspired machine learning (ML) algorithms has captured the imagination of many neuroscientists hoping to understand the principles of learning in the brain. This led to renewed efforts to find biologically realistic approximations to the backpropagation algorithm, the key to efficient credit assignment in feedforward networks [1, 2, 3, 4, 5]. Relatively little work covers the-arguably more realistic-scenario of learning in recurrent networks and temporal credit assignment [6]. The canonical machine learning solution, backpropagation through time (BPTT, [7]), poses more severe challenges when attempting to map it to biology. In particular, BPTT is temporally nonlocal; that is, each weight update depends on network activity across multiple time points. This problem could be addressed by using online alternatives to BPTT such as Real-Time Recurrent Learning (RTRL, [8]). Unfortunately, RTRL has an O(n 3) memory requirement (for n neurons) and it is hard to imagine any biological structure for storing this many real-valued variables. The cubic complexity is a problem not only for biology, but also for machine learning and has precluded the use of RTRL in applications. Nonetheless, the practical need for efficient online learning has revived the RTRL idea, leading to several new algorithms [9, 10, 11, 12, 13], which all reduce memory complexity to O(n 2), but differ in the nature of their approximations [14]. Our goal here is to investigate to what extent these ideas could be implemented in a biological circuit. One could take each algorithm individually and try to model in detail a biophysical implementation, {\`{a}} la [1, 2, 3, 4, 5]. However, it's unlikely that any single ML solution maps one-to-one onto neural circuitry. Instead, a more useful exercise would be to identify core computational building blocks that are strictly necessary for solving temporal credit assignment, which are more likely to have a direct biological analogue. To this end, we put forward a principled framework for evaluating biological plausibility in terms of the mathematical operations required-hence our "lazy" analysis. We examine several online algorithms within this framework, identifying potential issues common across algorithms, for example the need to physically represent the Jacobian of the network dynamics. We propose some novel solutions to this and other issues and in the process articulate biological mechanisms that could facilitate these solutions. Finally, we empirically validate that these biologically realistic approximations still solve temporal credit assignment, in two simple synthetic tasks. Plausibility criteria for recurrent learning. Consider a recurrent network of n units, with voltages v (t) = WˆrWˆr (t−1) , wher{\^{e}} r (t) is the concatenation of recurrent and external inputs, with an additional constant input for the bias term, ˆ r (t−1) = [r (t−1) ; x (t) ; 1] ∈ R m (m = n + n in + 1) and trainable weights organized as W = [W rec , W in , b rec ] ∈ R n×m. For a closer match to neural circuits, the firing rates update in continuous time, via r (t) = (1 − $\alpha$)r (t−1) + $\alpha$$\phi$(v (t)), using a point-wise neural activation function $\phi$ : R n → R n (e.g. tanh) and the network's inverse time constant $\alpha$ ∈ (0, 1]. The network output y (t) = softmax(W out r (t) + b out) ∈ R nout is computed by output weights/bias W out ∈ R nout×n , b out ∈ R nout and compared with the training label y * (t) to produce an instantaneous loss L (t). BPTT and RTRL each provide a method for calculating the gradient of each instantaneous loss ∂L (t) /∂W ij , to be used for gradient descent. BPTT unrolls the network over time and performs backpropagation as if on a feedforward network: ∂L (t) ∂W ij = t ≤t c (t) t s=t +1 J (s) i $\alpha$$\phi$ (v (t) i)ˆ r (t −1) j , (1) 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.},
author = {Marschall, Owen and Cho, Kyunghyun and Savin, Cristina},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marschall, Cho, Savin - 2019 - Evaluating biological plausibility of learning algorithms the lazy way.pdf:pdf},
number = {1},
pages = {1--5},
title = {{Evaluating biological plausibility of learning algorithms the lazy way}},
volume = {10003},
year = {2019}
}
@techreport{Kingma,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differ-entiability conditions, even works in the intractable case. Our contributions is twofold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114v10},
author = {Kingma, Diederik P and Welling, Max},
eprint = {1312.6114v10},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Welling - Unknown - Auto-Encoding Variational Bayes(2).pdf:pdf},
title = {{Auto-Encoding Variational Bayes}},
year = {2014}
}
@techreport{Jang,
abstract = {Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax esti-mator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification.},
archivePrefix = {arXiv},
arxivId = {1611.01144v5},
author = {Jang, Eric and Brain, Google and Gu, Shixiang and Poole, Ben},
eprint = {1611.01144v5},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jang et al. - Unknown - CATEGORICAL REPARAMETERIZATION WITH GUMBEL-SOFTMAX.pdf:pdf},
title = {{CATEGORICAL REPARAMETERIZATION WITH GUMBEL-SOFTMAX}},
year = {2017}
}
@article{Brouillard2020,
abstract = {Discovering causal relationships in data is a challenging task that involves solving a combinatorial problem for which the solution is not always identifiable. A new line of work reformulates the combinatorial problem as a continuous constrained optimization one, enabling the use of different powerful optimization techniques. However, methods based on this idea do not yet make use of interventional data, which can significantly alleviate identifiability issues. In this work, we propose a neural network-based method for this task that can leverage interventional data. We illustrate the flexibility of the continuous-constrained framework by taking advantage of expressive neural architectures such as normalizing flows. We show that our approach compares favorably to the state of the art in a variety of settings, including perfect and imperfect interventions for which the targeted nodes may even be unknown.},
archivePrefix = {arXiv},
arxivId = {2007.01754},
author = {Brouillard, Philippe and Lachapelle, S{\'{e}}bastien and Lacoste, Alexandre and Lacoste-Julien, Simon and Drouin, Alexandre},
eprint = {2007.01754},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brouillard et al. - 2020 - Differentiable Causal Discovery from Interventional Data.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{Differentiable Causal Discovery from Interventional Data}},
year = {2020}
}
@article{Fallah2020,
author = {Fallah, Kion and Willats, Adam A and Liu, Ninghao and Rozell, Christopher J},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fallah et al. - 2020 - Learning sparse codes from compressed representations with biologically plausible local wiring constraints.pdf:pdf},
number = {NeurIPS},
title = {{Learning sparse codes from compressed representations with biologically plausible local wiring constraints}},
year = {2020}
}
@article{Ying2020,
author = {Ying, Jiaxi and Palomar, Daniel P and Analytics, Data and Bay, Clear Water and Kong, Hong},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ying et al. - 2020 - Nonconvex Sparse Graph Learning under Laplacian Constrained Graphical Model.pdf:pdf},
number = {NeurIPS},
pages = {1--13},
title = {{Nonconvex Sparse Graph Learning under Laplacian Constrained Graphical Model}},
year = {2020}
}
@article{Wang2020,
abstract = {A fundamental problem in the high-dimensional regression is to understand the tradeoff between type I and type II errors or, equivalently, false discovery rate (FDR) and power in variable selection. To address this important problem, we offer the first complete tradeoff diagram that distinguishes all pairs of FDR and power that can be asymptotically realized by the Lasso with some choice of its penalty parameter from the remaining pairs, in a regime of linear sparsity under random designs. The tradeoff between the FDR and power characterized by our diagram holds no matter how strong the signals are. In particular, our results improve on the earlier Lasso tradeoff diagram of [19] by recognizing two simple but fundamental constraints on the pairs of FDR and power. The improvement is more substantial when the regression problem is above the Donoho–Tanner phase transition. Finally, we present extensive simulation studies to confirm the sharpness of the complete Lasso tradeoff diagram.},
archivePrefix = {arXiv},
arxivId = {2007.11078},
author = {Wang, Hua and Yang, Yachong and Bu, Zhiqi and Su, Weijie J.},
eprint = {2007.11078},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - The Complete Lasso Tradeoff Diagram.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
title = {{The Complete Lasso Tradeoff Diagram}},
year = {2020}
}
@article{Volodin2020,
abstract = {Causal models could increase interpretability, robustness to distributional shift and sample efficiency of RL agents. In this vein, we address the question of learning a causal model of an RL environment. This problem is known to be difficult due to spurious correlations. We overcome this difficulty by rewarding an RL agent for designing and executing interventions to discover the true model. We compare rewarding the agent for disproving uncertain edges in the causal graph, rewarding the agent for activating a certain node, or rewarding the agent for increasing the causal graph loss. We show that our methods result in a better causal graph than one generated by following the random policy, or a policy trained on the environment's reward. We find that rewarding for the causal graph loss works the best.},
archivePrefix = {arXiv},
arxivId = {2002.05217},
author = {Volodin, Sergei and Wichers, Nevan and Nixon, Jeremy},
eprint = {2002.05217},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Volodin, Wichers, Nixon - 2020 - Resolving spurious correlations in causal models of environments via interventions.pdf:pdf},
journal = {arXiv},
title = {{Resolving spurious correlations in causal models of environments via interventions}},
year = {2020}
}
@article{Barcelo2020,
abstract = {In spite of several claims stating that some models are more interpretable than others -- e.g., "linear models are more interpretable than deep neural networks" -- we still lack a principled notion of interpretability to formally compare among different classes of models. We make a step towards such a notion by studying whether folklore interpretability claims have a correlate in terms of computational complexity theory. We focus on local post-hoc explainability queries that, intuitively, attempt to answer why individual inputs are classified in a certain way by a given model. In a nutshell, we say that a class $\mathcal{C}_1$ of models is more interpretable than another class $\mathcal{C}_2$, if the computational complexity of answering post-hoc queries for models in $\mathcal{C}_2$ is higher than for those in $\mathcal{C}_1$. We prove that this notion provides a good theoretical counterpart to current beliefs on the interpretability of models; in particular, we show that under our definition and assuming standard complexity-theoretical assumptions (such as P$\neq$NP), both linear and tree-based models are strictly more interpretable than neural networks. Our complexity analysis, however, does not provide a clear-cut difference between linear and tree-based models, as we obtain different results depending on the particular post-hoc explanations considered. Finally, by applying a finer complexity analysis based on parameterized complexity, we are able to prove a theoretical result suggesting that shallow neural networks are more interpretable than deeper ones.},
archivePrefix = {arXiv},
arxivId = {2010.12265},
author = {Barcel{\'{o}}, Pablo and Monet, Mika{\"{e}}l and P{\'{e}}rez, Jorge and Subercaseaux, Bernardo},
eprint = {2010.12265},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barcel{\'{o}} et al. - 2020 - Model Interpretability through the Lens of Computational Complexity.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Model Interpretability through the Lens of Computational Complexity}},
url = {http://arxiv.org/abs/2010.12265},
year = {2020}
}
@article{Yuan2018,
abstract = {Extreme learning machine (ELM) is a popular learning algorithm for single hidden layer feedforward networks (SLFNs). It was originally proposed with the inspiration from biological learning and has attracted massive attentions due to its adaptability to various tasks with a fast learning ability and efficient computation cost. As an effective sparse representation method, orthogonal matching pursuit (OMP) method can be embedded into ELM to overcome the singularity problem and improve the stability. Usually OMP recovers a sparse vector by minimizing a least squares (LS) loss, which is efficient for Gaussian distributed data, but may suffer performance deterioration in presence of non-Gaussian data. To address this problem, a robust matching pursuit method based on a novel kernel risk-sensitive loss (in short KRSLMP) is first proposed in this paper. The KRSLMP is then applied to ELM to solve the sparse output weight vector, and the new method named the KRSLMP-ELM is developed for SLFN learning. Experimental results on synthetic and real-world data sets confirm the effectiveness and superiority of the proposed method.},
author = {Yuan, Zejian and Wang, Xin and Cao, Jiuwen and Zhao, Haiquan and Chen, Badong},
doi = {10.1155/2018/4563040},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan et al. - 2018 - Robust Matching Pursuit Extreme Learning Machines.pdf:pdf},
issn = {10589244},
journal = {Scientific Programming},
pages = {11--13},
title = {{Robust Matching Pursuit Extreme Learning Machines}},
volume = {2018},
year = {2018}
}
@article{Yoo2019,
author = {Yoo, Seng Bum Michael and Tu, Jiaxin Cindy and Piantadosi, Steven T. and {Benjamin Yost Hayden}},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2019 - The Neural Basis of Predictive Pursuit Short title.pdf:pdf},
title = {{The Neural Basis of Predictive Pursuit Short title}},
year = {2019}
}
@article{Vincent2002,
abstract = {Matching Pursuit algorithms learn a function that is a weighted sum of basis functions, by sequentially appending functions to an initially empty basis, to approximate a target function in the least-squares sense. We show how matching pursuit can be extended to use non-squared error loss functions, and how it can be used to build kernel-based solutions to machine learning problems, while keeping control of the sparsity of the solution. We present a version of the algorithm that makes an optimal choice of both the next basis and the weights of all the previously chosen bases. Finally, links to boosting algorithms and RBF training procedures, as well as an extensive experimental comparison with SVMs for classification are given, showing comparable results with typically much sparser models.},
author = {Vincent, Pascal and Bengio, Yoshua},
doi = {10.1023/A:1013955821559},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vincent, Bengio - 2002 - Kernel matching pursuit.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Boosting,Kernel methods,Matching pursuit,Radial basis functions,Sparse approximation,Support vector machines},
number = {1-3},
pages = {165--187},
title = {{Kernel matching pursuit}},
volume = {48},
year = {2002}
}
@article{Sulam2020,
abstract = {Parsimonious representations are ubiquitous in modeling and processing information. Motivated by the recent Multi-Layer Convolutional Sparse Coding (ML-CSC) model, we herein generalize the traditional Basis Pursuit problem to a multi-layer setting, introducing similar sparse enforcing penalties at different representation layers in a symbiotic relation between synthesis and analysis sparse priors. We explore different iterative methods to solve this new problem in practice, and we propose a new Multi-Layer Iterative Soft Thresholding Algorithm (ML-ISTA), as well as a fast version (ML-FISTA). We show that these nested first order algorithms converge, in the sense that the function value of near-fixed points can get arbitrarily close to the solution of the original problem. We further show how these algorithms effectively implement particular recurrent convolutional neural networks (CNNs) that generalize feed-forward ones without introducing any parameters. We present and analyze different architectures resulting from unfolding the iterations of the proposed pursuit algorithms, including a new Learned ML-ISTA, providing a principled way to construct deep recurrent CNNs. Unlike other similar constructions, these architectures unfold a global pursuit holistically for the entire network. We demonstrate the emerging constructions in a supervised learning setting, consistently improving the performance of classical CNNs while maintaining the number of parameters constant.},
archivePrefix = {arXiv},
arxivId = {1806.00701},
author = {Sulam, Jeremias and Aberdam, Aviad and Beck, Amir and Elad, Michael},
doi = {10.1109/TPAMI.2019.2904255},
eprint = {1806.00701},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sulam et al. - 2020 - On Multi-Layer Basis Pursuit, Efficient Algorithms and Convolutional Neural Networks.pdf:pdf},
issn = {19393539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Multi-layer convolutional sparse coding,iterative shrinkage algorithms,network unfolding,recurrent neural networks},
number = {8},
pages = {1968--1980},
pmid = {30869611},
title = {{On Multi-Layer Basis Pursuit, Efficient Algorithms and Convolutional Neural Networks}},
volume = {42},
year = {2020}
}
@article{Combettes2019,
abstract = {Matching pursuit algorithms are an important class of algorithms in signal processing and machine learning. We present a blended matching pursuit algorithm, combining coordinate descent-like steps with stronger gradient descent steps, for minimizing a smooth convex function over a linear space spanned by a set of atoms. We derive sublinear to linear convergence rates according to the smoothness and sharpness orders of the function and demonstrate computational superiority of our approach. In particular, we derive linear rates for a large class of non-strongly convex functions, and we demonstrate in experiments that our algorithm enjoys very fast rates of convergence and wall-clock speed while maintaining a sparsity of iterates very comparable to that of the (much slower) orthogonal matching pursuit.},
archivePrefix = {arXiv},
arxivId = {1904.12335},
author = {Combettes, Cyrille W. and Pokutta, Sebastian},
eprint = {1904.12335},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Combettes, Pokutta - 2019 - Blended Matching Pursuit.pdf:pdf},
journal = {arXiv},
number = {1},
pages = {1--11},
title = {{Blended Matching Pursuit}},
year = {2019}
}
@techreport{Genewein,
abstract = {Probability trees are one of the simplest models of causal generative processes. They possess clean semantics and-unlike causal Bayesian networks-they can represent context-specific causal dependencies, which are necessary for e.g. causal induction. Yet, they have received little attention from the AI and ML community. Here we present concrete algorithms for causal reasoning in discrete probability trees that cover the entire causal hierarchy (association, intervention, and coun-terfactuals), and operate on arbitrary propositional and causal events. Our work expands the domain of causal reasoning to a very general class of discrete stochastic processes.},
archivePrefix = {arXiv},
arxivId = {2010.12237v2},
author = {Genewein, Tim and Mcgrath, Tom and Del{\'{e}}tang, Gr{\'{e}}goire and Mikulik, Vladimir and Martic, Miljan and Legg, Shane and Ortega, Pedro A},
eprint = {2010.12237v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Genewein et al. - Unknown - Algorithms for Causal Reasoning in Probability Trees.pdf:pdf},
isbn = {2010.12237v2},
title = {{Algorithms for Causal Reasoning in Probability Trees}},
url = {https://github.com/deepmind/deepmind-research/tree/master/causal_reasoning},
year = {2020}
}
@article{Javed2020,
author = {Javed, Khurram},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2020 - Learning Online-Aware Representations using Neural Networks.pdf:pdf},
title = {{Learning Online-Aware Representations using Neural Networks}},
year = {2020}
}
@article{Javed2019,
abstract = {A continual learning agent should be able to build on top of existing knowledge to learn on new data quickly while minimizing forgetting. Current intelligent systems based on neural network function approximators arguably do the opposite—they are highly prone to forgetting and rarely trained to facilitate future learning. One reason for this poor behavior is that they learn from a representation that is not explicitly trained for these two goals. In this paper, we propose MRCL, an objective to explicitly learn representations that accelerate future learning and are robust to forgetting under online updates in continual learning. The idea is to optimize the representation such that online updates minimize error on all samples with little forgetting. We show that it is possible to learn representations that are more effective for online updating and that sparsity naturally emerges in these representations. Moreover, our method is complementary to existing continual learning strategies, like MER, which can learn more effectively from representations learned by our objective. Finally, we demonstrate that a basic online updating strategy with our learned representation is competitive with rehearsal based methods for continual learning. We release an implementation of our method at https://github.com/khurramjaved96/mrcl.},
archivePrefix = {arXiv},
arxivId = {1905.12588},
author = {Javed, Khurram and White, Martha},
eprint = {1905.12588},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Javed, White - 2019 - Meta-Learning Representations for Continual Learning.pdf:pdf},
journal = {arXiv},
number = {NeurIPS},
pages = {1--15},
title = {{Meta-Learning Representations for Continual Learning}},
year = {2019}
}
@article{Tamkin2020,
abstract = {Many recent methods for unsupervised representation learning involve training models to be invariant to different "views," or transformed versions of an input. However, designing these views requires considerable human expertise and experimentation, hindering widespread adoption of unsupervised representation learning methods across domains and modalities. To address this, we propose viewmaker networks: generative models that learn to produce input-dependent views for contrastive learning. We train this network jointly with an encoder network to produce adversarial $\ell_p$ perturbations for an input, which yields challenging yet useful views without extensive human tuning. Our learned views, when applied to CIFAR-10, enable comparable transfer accuracy to the the well-studied augmentations used for the SimCLR model. Our views significantly outperforming baseline augmentations in speech (+9% absolute) and wearable sensor (+17% absolute) domains. We also show how viewmaker views can be combined with handcrafted views to improve robustness to common image corruptions. Our method demonstrates that learned views are a promising way to reduce the amount of expertise and effort needed for unsupervised learning, potentially extending its benefits to a much wider set of domains.},
archivePrefix = {arXiv},
arxivId = {2010.07432},
author = {Tamkin, Alex and Wu, Mike and Goodman, Noah},
eprint = {2010.07432},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamkin, Wu, Goodman - 2020 - Viewmaker Networks Learning Views for Unsupervised Representation Learning.pdf:pdf},
month = {oct},
title = {{Viewmaker Networks: Learning Views for Unsupervised Representation Learning}},
url = {http://arxiv.org/abs/2010.07432},
year = {2020}
}
@techreport{Mitrovic,
abstract = {Self-supervised learning has emerged as a strategy to reduce the reliance on costly supervised signal by pretraining representations only using unlabeled data. These methods combine heuristic proxy classification tasks with data augmentations and have achieved significant success, but our theoretical understanding of this success remains limited. In this paper we analyze self-supervised representation learning using a causal framework. We show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. Based on this, we propose a novel self-supervised objective, Representation Learning via Invariant Causal Mechanisms (RELIC), that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. Further, using causality we generalize contrastive learning, a particular kind of self-supervised method, and provide an alternative theoretical explanation for the success of these methods. Empirically, RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet, while also significantly outperforming these methods on Atari achieving above human-level performance on 51 out of 57 games.},
archivePrefix = {arXiv},
arxivId = {2010.07922v1},
author = {Mitrovic, Jovana and Mcwilliams, Brian and Walker, Jacob and Buesing, Lars and Blundell, Charles},
eprint = {2010.07922v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitrovic et al. - Unknown - REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS.pdf:pdf},
isbn = {2010.07922v1},
title = {{REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS}},
year = {2020}
}
@article{Dinh2015,
abstract = {We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the determinant of the Jacobian and inverse Jacobian is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
archivePrefix = {arXiv},
arxivId = {1410.8516},
author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
eprint = {1410.8516},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Krueger, Bengio - 2015 - NICE Non-linear independent components estimation.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Workshop Track Proceedings},
number = {2},
pages = {1--13},
title = {{NICE: Non-linear independent components estimation}},
volume = {1},
year = {2015}
}
@article{Ehsan2018,
abstract = {We introduce AI rationalization, an approach for generating explanations of autonomous system behavior as if a human had performed the behavior. We describe a rationalization technique that uses neural machine translation to translate internal state-action representations of an autonomous agent into natural language. We evaluate our technique in the Frogger game environment, training an autonomous game playing agent to rationalize its action choices using natural language. A natural language training corpus is collected from human players thinking out loud as they play the game. We motivate the use of rationalization as an approach to explanation generation and show the results of two experiments evaluating the effectiveness of rationalization. Results of these evaluations show that neural machine translation is able to accurately generate rationalizations that describe agent behavior, and that rationalizations are more satisfying to humans than other alternative methods of explanation.},
archivePrefix = {arXiv},
arxivId = {1702.07826},
author = {Ehsan, Upol and Harrison, Brent and Chan, Larry and Riedl, Mark O.},
doi = {10.1145/3278721.3278736},
eprint = {1702.07826},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ehsan et al. - 2018 - Rationalization A Neural Machine Translation Approach to Generating Natural Language Explanations.pdf:pdf},
isbn = {9781450360128},
journal = {AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
keywords = {ai rationalization,artificial intelligence,explainable ai,interpretability,machine learning,transparency,user perception},
pages = {81--87},
title = {{Rationalization: A Neural Machine Translation Approach to Generating Natural Language Explanations}},
year = {2018}
}
@techreport{Bachman,
abstract = {We investigate attention as the active pursuit of useful information. This contrasts with attention as a mechanism for the attenuation of irrelevant information. We also consider the role of short-term memory, whose use is critical to any model incapable of simultaneously perceiving all information on which its output depends. We present several simple synthetic tasks, which become considerably more interesting when we impose strong constraints on how a model can interact with its input, and on how long it can take to produce its output. We develop a model with a different structure from those seen in previous work, and we train it using stochastic variational inference with a learned proposal distribution.},
archivePrefix = {arXiv},
arxivId = {1510.08949v1},
author = {Bachman, Philip and Krueger, David and Precup, Doina},
eprint = {1510.08949v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bachman, Krueger, Precup - Unknown - Testing Visual Attention in Dynamic Environments.pdf:pdf},
title = {{Testing Visual Attention in Dynamic Environments}},
year = {2015}
}
@techreport{Hyvarinen2019,
abstract = {Nonlinear ICA is a fundamental problem for unsupervised representation learning, emphasizing the capacity to recover the underlying latent variables generating the data (i.e., identifiability). Recently, the very first iden-tifiability proofs for nonlinear ICA have been proposed, leveraging the temporal structure of the independent components. Here, we propose a general framework for nonlinear ICA, which, as a special case, can make use of temporal structure. It is based on augmenting the data by an auxiliary variable, such as the time index, the history of the time series , or any other available information. We propose to learn nonlinear ICA by discriminating between true augmented data, or data in which the auxiliary variable has been ran-domized. This enables the framework to be implemented algorithmically through logistic regression, possibly in a neural network. We provide a comprehensive proof of the identifi-ability of the model as well as the consistency of our estimation method. The approach not only provides a general theoretical framework combining and generalizing previously proposed nonlinear ICA models and algorithms, but also brings practical advantages.},
archivePrefix = {arXiv},
arxivId = {1805.08651v3},
author = {Hyv{\"{a}}rinen, Aapo and Sasaki, Hiroaki and Turner, Richard E},
eprint = {1805.08651v3},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hyv{\"{a}}rinen, Sasaki, Turner - 2019 - Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning.pdf:pdf},
title = {{Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning}},
year = {2019}
}
@techreport{Lipton,
abstract = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but inter-pretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for in-terpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim inter-pretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretabil-ity, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
archivePrefix = {arXiv},
arxivId = {1606.03490v3},
author = {Lipton, Zachary C},
eprint = {1606.03490v3},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lipton - Unknown - The Mythos of Model Interpretability.pdf:pdf},
title = {{The Mythos of Model Interpretability}},
year = {2017}
}
@article{Wong2020,
abstract = {We introduce computational causal inference as an interdisciplinary field across causal inference, algorithms design and numerical computing. The field aims to develop software specializing in causal inference that can analyze massive datasets with a variety of causal effects, in a performant, general, and robust way. The focus on software improves research agility, and enables causal inference to be easily integrated into large engineering systems. In particular, we use computational causal inference to deepen the relationship between causal inference, online experimentation, and algorithmic decision making. This paper describes the new field, the demand, opportunities for scalability, open challenges, and begins the discussion for how the community can unite to solve challenges for scaling causal inference and decision making.},
annote = {difference in means as main metric?},
archivePrefix = {arXiv},
arxivId = {2007.10979},
author = {Wong, Jeffrey C.},
eprint = {2007.10979},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wong - 2020 - Computational Causal Inference.pdf:pdf},
title = {{Computational Causal Inference}},
url = {http://arxiv.org/abs/2007.10979},
year = {2020}
}
@article{Bengio2012,
abstract = {We propose a theory that relates difficulty of learning in deep architectures to culture and language. It is articulated around the following hypotheses: (1) learning in an individual human brain is hampered by the presence of effective local minima; (2) this optimization difficulty is particularly important when it comes to learning higher-level abstractions, i.e., concepts that cover a vast and highly-nonlinear span of sensory configurations; (3) such high-level abstractions are best represented in brains by the composition of many levels of representation, i.e., by deep architectures; (4) a human brain can learn such high-level abstractions if guided by the signals produced by other humans, which act as hints or indirect supervision for these high-level abstractions; and (5), language and the recombination and optimization of mental concepts provide an efficient evolutionary recombination operator, and this gives rise to rapid search in the space of communicable ideas that help humans build up better high-level internal representations of their world. These hypotheses put together imply that human culture and the evolution of ideas have been crucial to counter an optimization difficulty: this optimization difficulty would otherwise make it very difficult for human brains to capture high-level knowledge of the world. The theory is grounded in experimental observations of the difficulties of training deep artificial neural networks. Plausible consequences of this theory for the efficiency of cultural evolutions are sketched.},
annote = {Culture as non-convexity escape mechanism

training signal: predict what the teacher does -> loss for representation

animal training term 'shaping' $\sim$ curriculum

dividing and recombination of both, max(eyes gene) max(... gene) max (... gene)},
archivePrefix = {arXiv},
arxivId = {1203.2990},
author = {Bengio, Yoshua},
eprint = {1203.2990},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio - 2012 - Evolving Culture vs Local Minima.pdf:pdf},
pages = {1--28},
title = {{Evolving Culture vs Local Minima}},
url = {http://arxiv.org/abs/1203.2990},
volume = {2006},
year = {2012}
}
@article{Sitzmann2020,
abstract = {Implicitly defined, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible benefits over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with fine detail, and fail to represent a signal's spatial and temporal derivatives, despite the fact that these are essential to many physical signals defined implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or Sirens, are ideally suited for representing complex natural signals and their derivatives. We analyze Siren activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how Sirens can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine Sirens with hypernetworks to learn priors over the space of Siren functions.},
annote = {sine activation function, map (x, y) -> pixel value},
archivePrefix = {arXiv},
arxivId = {2006.09661},
author = {Sitzmann, Vincent and Martel, Julien N. P. and Bergman, Alexander W. and Lindell, David B. and Wetzstein, Gordon},
eprint = {2006.09661},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sitzmann et al. - 2020 - Implicit Neural Representations with Periodic Activation Functions.pdf:pdf},
month = {jun},
title = {{Implicit Neural Representations with Periodic Activation Functions}},
url = {http://arxiv.org/abs/2006.09661},
year = {2020}
}
@techreport{Kocaoglu2017,
abstract = {We propose an adversarial training procedure for learning a causal implicit generative model for a given causal graph. We show that adversarial training can be used to learn a generative model with true observational and interventional distributions if the generator architecture is consistent with the given causal graph. We consider the application of generating faces based on given binary labels where the dependency structure between the labels is preserved with a causal graph. This problem can be seen as learning a causal implicit generative model for the image and labels. We devise a two-stage procedure for this problem. First we train a causal implicit generative model over binary labels using a neural network consistent with a causal graph as the generator. We empirically show that Wasserstein GAN can be used to output discrete labels. Later we propose two new conditional GAN architectures, which we call CausalGAN and CausalBEGAN. We show that the optimal generator of the CausalGAN, given the labels, samples from the image distributions conditioned on these labels. The conditional GAN combined with a trained causal implicit generative model for the labels is then an implicit causal generative network over the labels and the generated image. We show that the proposed architectures can be used to sample from observational and interventional image distributions, even for interventions which do not naturally occur in the dataset.},
archivePrefix = {arXiv},
arxivId = {1709.02023v2},
author = {Kocaoglu, Murat and Snyder, Christopher and Dimakis, Alexandros G and Vishwanath, Sriram},
eprint = {1709.02023v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocaoglu et al. - 2017 - CausalGAN Learning Causal Implicit Generative Models with Adversarial Training.pdf:pdf},
title = {{CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training}},
year = {2017}
}
@techreport{Xu,
abstract = {We introduce COT-GAN, an adversarial algorithm to train implicit generative models optimized for producing sequential data. The loss function of this algorithm is formulated using ideas from Causal Optimal Transport (COT), which combines classic optimal transport methods with an additional temporal causality constraint. Remarkably, we find that this causality condition provides a natural framework to parameterize the cost function that is learned by the discriminator as a robust (worst-case) distance, and an ideal mechanism for learning time dependent data distributions. Following Genevay et al. (2018), we also include an entropic penal-ization term which allows for the use of the Sinkhorn algorithm when computing the optimal transport cost. Our experiments show effectiveness and stability of COT-GAN when generating both low-and high-dimensional time series data. The success of the algorithm also relies on a new, improved version of the Sinkhorn divergence which demonstrates less bias in learning.},
annote = {modelling time series},
archivePrefix = {arXiv},
arxivId = {2006.08571v2},
author = {Xu, Tianlin and Wenliang, Li K and {Munn Google}, Michael and Acciaio, Beatrice},
eprint = {2006.08571v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - Unknown - COT-GAN GENERATING SEQUENTIAL DATA VIA CAUSAL OPTIMAL TRANSPORT.pdf:pdf},
title = {{COT-GAN: GENERATING SEQUENTIAL DATA VIA CAUSAL OPTIMAL TRANSPORT}},
year = {2020}
}
@techreport{Yoon,
abstract = {A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction-which allow finer control over network dynamics-are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the flexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we find that the proposed framework consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability.},
annote = {using a discriminator in latent space},
author = {Yoon, Jinsung and Jarrett, Daniel and {Van Der Schaar}, Mihaela},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yoon, Jarrett, Van Der Schaar - Unknown - Time-series Generative Adversarial Networks.pdf:pdf},
title = {{Time-series Generative Adversarial Networks}},
year = {2019}
}
@techreport{Odena2018,
abstract = {Recent work (Pennington et al., 2017) suggests that controlling the entire distribution of Jacobian singular values is an important design consideration in deep learning. Motivated by this, we study the distribution of singular values of the Jacobian of the generator in Generative Adversarial Networks (GANs). We find that this Jacobian generally becomes ill-conditioned at the beginning of training and that the average (with z ∼ p(z)) conditioning of the generator is highly predic-tive of two other ad-hoc metrics for measuring the "quality" of trained GANs: the Inception Score and the Frechet Inception Distance (FID). We test the hypothesis that this relationship is causal by proposing a "regularization" technique (called Jacobian Clamping) that softly penalizes the condition number of the generator Jacobian. Jacobian Clamping improves the mean Inception Score and the mean FID for GANs trained on several datasets and greatly reduces inter-run variance of the aforementioned scores, addressing (at least partially) one of the main criticisms of GANs.},
archivePrefix = {arXiv},
arxivId = {1802.08768v2},
author = {Odena, Augustus and Buckman, Jacob and Olsson, Catherine and Brown, Tom B and Olah, Christopher and Raffel, Colin and Goodfellow, Ian},
eprint = {1802.08768v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Odena et al. - 2018 - Is Generator Conditioning Causally Related to GAN Performance.pdf:pdf},
title = {{Is Generator Conditioning Causally Related to GAN Performance?}},
year = {2018}
}
@techreport{Kalainathan,
abstract = {Ecole doctorale n • 580 Sciences et technologies de l'information et de la communication (STIC) Sp{\'{e}}cialit{\'{e}}Sp´Sp{\'{e}}cialitSp{\'{e}}cialit´Sp{\'{e}}cialit{\'{e}} de doctorat : Informatique Th{\`{e}}seTh`Th{\`{e}}se pr{\'{e}}sent{\'{e}}epr´pr{\'{e}}sentpr{\'{e}}sent´pr{\'{e}}sent{\'{e}}e et soutenu{\`{e}} a Gif-Sur-Yvette, le 17 D ´ ecembre 2019, par DIVIYAN KALAINATHAN},
author = {Kalainathan, Diviyan},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalainathan - Unknown - Generative Neural networks to infer Causal Mechanisms Algorithms and applications.pdf:pdf},
title = {{Generative Neural networks to infer Causal Mechanisms: Algorithms and applications}},
url = {https://hal.inria.fr/tel-02435986},
year = {2020}
}
@techreport{Kamalaruban,
abstract = {One of the central challenges faced by a reinforcement learning (RL) agent is to effectively learn a (near-)optimal policy in environments with large state spaces having sparse and noisy feedback signals. In real-world applications, an expert with additional domain knowledge can help in speeding up the learning process via shaping the environment, i.e., making the environment more learner-friendly. A popular paradigm in literature is potential-based reward shaping, where the environment's reward function is augmented with additional local rewards using a potential function. However, the applicability of potential-based reward shaping is limited in settings where (i) the state space is very large, and it is challenging to compute an appropriate potential function, (ii) the feedback signals are noisy, and even with shaped rewards the agent could be trapped in local optima, and (iii) changing the rewards alone is not sufficient, and effective shaping requires changing the dynamics. We address these limitations of potential-based shaping methods and propose a novel framework of environment shaping using state abstraction. Our key idea is to compress the environment's large state space with noisy signals to an abstracted space, and to use this abstraction in creating smoother and more effective feedback signals for the agent. We study the theoretical underpinnings of our abstraction-based environment shaping, and show that the agent's policy learnt in the shaped environment preserves near-optimal behavior in the original environment.},
archivePrefix = {arXiv},
arxivId = {2006.13160v1},
author = {Kamalaruban, Parameswaran},
eprint = {2006.13160v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kamalaruban - Unknown - Environment Shaping in Reinforcement Learning using State Abstraction.pdf:pdf},
keywords = {EPFL Adish Singla MPI-SWS,EPFL Rati Devidze MPI-SWS Volkan Cevher LIONS,LIONS},
title = {{Environment Shaping in Reinforcement Learning using State Abstraction}},
year = {2020}
}
@article{Guo2020,
abstract = {This work considers the question of how convenient access to copious data impacts our ability to learn causal effects and relations. In what ways is learning causality in the era of big data different from-or the same as-the traditional one? To answer this question, this survey provides a comprehensive and structured review of both traditional and frontier methods in learning causality and relations along with the connections between causality and machine learning. This work points out on a case-by-case basis how big data facilitates, complicates, or motivates each approach.},
archivePrefix = {arXiv},
arxivId = {1809.09337v4},
author = {Guo, Ruocheng and Cheng, L U and Hahn, P Richard and Liu, Huan and Cheng, Lu and Li, Jundong},
doi = {10.1145/3397269},
eprint = {1809.09337v4},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2020 - A Survey of Learning Causality with Data Problems and Methods.pdf:pdf},
keywords = {ACM Reference Format:,CCS Concepts: • Computing methodologies → Artifici,Probability and statistics,• Mathematics of computing → Probability and stati},
title = {{A Survey of Learning Causality with Data: Problems and Methods}},
url = {https://doi.org/10.1145/3397269},
year = {2020}
}
@techreport{Corcoll,
abstract = {Exploration and credit assignment under sparse rewards are still challenging problems. We argue that these challenges arise in part due to the intrinsic rigidity of operating at the level of actions. Actions can precisely define how to perform an activity but are ill-suited to describe what activity to perform. Instead, causal effects are inherently composable and temporally abstract, making them ideal for descriptive tasks. By leveraging a hierarchy of causal effects, this study aims to expedite the learning of task-specific behavior and aid exploration. Borrowing counterfac-tual and normality measures from causal literature, we disentangle controllable effects from effects caused by other dynamics of the environment. We propose CEHRL 1 , a hierarchical method that models the distribution of controllable effects using a Variational Autoencoder. This distribution is used by a high-level policy to 1) explore the environment via random effect exploration so that novel effects are continuously discovered and learned; and to 2) learn task-specific behavior by prioritizing the effects that maximize a given reward function. In comparison to exploring with random actions, experimental results show that random effect exploration is a more efficient mechanism, and that by assigning credit to few effects rather than many actions, CEHRL learns tasks more rapidly.},
archivePrefix = {arXiv},
arxivId = {2010.01351v1},
author = {Corcoll, Oriol and Vicente, Raul},
eprint = {2010.01351v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Corcoll, Vicente - Unknown - DISENTANGLING CAUSAL EFFECTS FOR HIERARCHICAL REINFORCEMENT LEARNING.pdf:pdf},
title = {{DISENTANGLING CAUSAL EFFECTS FOR HIERARCHICAL REINFORCEMENT LEARNING}},
year = {2020}
}
@article{Evans2018,
abstract = {Artificial Neural Networks are powerful function approximators capable of modelling solutions to a wide variety of problems, both supervised and unsupervised. As their size and expressivity increases, so too does the variance of the model, yielding a nearly ubiquitous overfitting problem. Although mitigated by a variety of model regu-larisation methods, the common cure is to seek large amounts of training data'which is not necessarily easily obtained'that sufficiently approximates the data distribution of the domain we wish to test on. In contrast, logic programming methods such as Inductive Logic Programming offer an extremely data-efficient process by which models can be trained to reason on symbolic domains. However, these methods are unable to deal with the variety of domains neural networks can be applied to: they are not robust to noise in or mislabelling of inputs, and perhaps more importantly, cannot be applied to non-symbolic domains where the data is ambiguous, such as operating on raw pixels. In this paper, we propose a Differentiable Inductive Logic framework (?ILP), which can not only solve tasks which traditional ILP systems are suited for, but shows a robustness to noise and error in the training data which ILP cannot cope with. Furthermore, as it is trained by backpropagation against a likelihood objective, it can be hybridised by connecting it with neural networks over ambiguous data in order to be applied to domains which ILP cannot address, while providing data efficiency and generalisation beyond what neural networks on their own can achieve.},
archivePrefix = {arXiv},
arxivId = {1711.04574},
author = {Evans, Richard and Grefenstette, Edward},
doi = {10.1613/jair.5714},
eprint = {1711.04574},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Evans, Grefenstette - 2018 - Learning explanatory rules from noisy data.pdf:pdf},
isbn = {9780999241127},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {5598--5602},
title = {{Learning explanatory rules from noisy data}},
volume = {2018-July},
year = {2018}
}
@article{Sharan2017,
abstract = {What learning algorithms can be run directly on compressively-sensed data? In this work, we consider the question of accurately and efficiently computing low-rank matrix or tensor factorizations given data compressed via random projections. We examine the approach of first performing factorization in the compressed domain, and then reconstructing the original high-dimensional factors from the recovered (compressed) factors. In both the matrix and tensor settings, we establish conditions under which this natural approach will provably recover the original factors. While it is well-known that random projections preserve a number of geometric properties of a dataset, our work can be viewed as showing that they can also preserve certain solutions of non-convex, NP-Hard problems like non-negative matrix factorization. We support these theoretical results with experiments on synthetic data and demonstrate the practical applicability of compressed factorization on real-world gene expression and EEG time series datasets.},
archivePrefix = {arXiv},
arxivId = {1706.08146},
author = {Sharan, Vatsal and Tai, Kai Sheng and Bailis, Peter and Valiant, Gregory},
eprint = {1706.08146},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharan et al. - 2017 - Compressed Factorization Fast and Accurate Low-Rank Factorization of Compressively-Sensed Data.pdf:pdf},
journal = {36th International Conference on Machine Learning, ICML 2019},
month = {jun},
pages = {10013--10030},
publisher = {International Machine Learning Society (IMLS)},
title = {{Compressed Factorization: Fast and Accurate Low-Rank Factorization of Compressively-Sensed Data}},
url = {http://arxiv.org/abs/1706.08146},
volume = {2019-June},
year = {2017}
}
@article{Martins2016,
abstract = {We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities. After deriving its properties, we show how its Jacobian can be efficiently computed, enabling its use in a network trained with backpropagation. Then, we propose a new smooth and convex loss function which is the sparsemax analogue of the logistic loss. We reveal an unexpected connection between this new loss and the Huber classification loss. We obtain promising empirical results in multi-label classification problems and in attention-based neural networks for natural language inference. For the latter, we achieve a similar performance as the traditional softmax, but with a selective, more compact, attention focus.},
archivePrefix = {arXiv},
arxivId = {1602.02068},
author = {Martins, Andr{\'{e}} F. T. and Astudillo, Ram{\'{o}}n Fernandez},
eprint = {1602.02068},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martins, Astudillo - 2016 - From Softmax to Sparsemax A Sparse Model of Attention and Multi-Label Classification.pdf:pdf},
journal = {33rd International Conference on Machine Learning, ICML 2016},
month = {feb},
pages = {2432--2443},
publisher = {International Machine Learning Society (IMLS)},
title = {{From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification}},
url = {http://arxiv.org/abs/1602.02068},
volume = {4},
year = {2016}
}
@inproceedings{Kiumarsi2019,
abstract = {This paper presents a resilient model-free reinforcement learning solution to linear quadratic regulator control of cyber-physical systems under sensor attacks. To guarantee resiliency to sensor attacks, a sparse least-squares optimization is introduced to solve the Bellman equation. While the Bellman equation does not involve any dynamics, it implicitly solves a Lyapunov equation which depends on the system dynamics. Thus, if the data are corrupted and do not follow the dynamics, that causes an error in the Bellman equation. Therefore, assuming a strong system observability, i.e., s-sparse observability, the proposed sparse optimization assures that the data from compromised sensors that lead to a sizable error in the Bellman equation have no effect in reconstructing the state of the system, and, thus on evaluation of the policy. That is, only sensory outputs that result in a small error in the Bellman equation affect the policy evaluation. Once the optimal control policy is found, it can be applied to the system, until a surprise signal depending on the Bellman error is activated to indicate a change caused by a new attack or a change in the system dynamics.},
author = {Kiumarsi, Bahare and Basar, Tamer},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
doi = {10.1109/CDC40024.2019.9028861},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kiumarsi, Basar - 2019 - Secure Linear Quadratic Regulator Using Sparse Model-Free Reinforcement Learning.pdf:pdf},
isbn = {9781728113982},
issn = {07431546},
keywords = {Linear quadratic regulator,Reinforcement Learning,Resilient control},
month = {dec},
pages = {3641--3647},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Secure Linear Quadratic Regulator Using Sparse Model-Free Reinforcement Learning}},
volume = {2019-Decem},
year = {2019}
}
@techreport{Qin,
abstract = {Abductive and counterfactual reasoning, core abilities of everyday human cognition, require reasoning about what might have happened at time t, while conditioning on multiple contexts from the relative past and future. However, simultaneous incorporation of past and future contexts using generative language models (LMs) can be challenging, as they are trained either to condition only on the past context or to perform narrowly scoped text-infilling. In this paper, we propose DELOREAN, a new unsupervised decoding algorithm that can flexibly incorporate both the past and future contexts using only off-the-shelf, left-to-right language models and no supervision. The key intuition of our algorithm is incorporating the future through back-propagation, during which, we only update the internal representation of the output while fixing the model parameters. By alternating between forward and backward propagation, DELOREAN can decode the output representation that reflects both the left and right contexts. We demonstrate that our approach is general and applicable to two nonmonotonic reasoning tasks: abductive text generation and counterfactual story revision, where DELOREAN outperforms a range of unsupervised and some supervised methods, based on automatic and human evaluation. 1},
archivePrefix = {arXiv},
arxivId = {2010.05906v1},
author = {Qin, Lianhui and Shwartz, Vered and West, Peter and Bhagavatula, Chandra and Hwang, Jena D and {Le Bras}, Ronan and Bosselut, Antoine and Choi, Yejin and Allen, Paul G},
eprint = {2010.05906v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qin et al. - Unknown - Back to the Future Unsupervised Backprop-based Decoding for Counterfactual and Abductive Commonsense Reasoning.pdf:pdf},
title = {{Back to the Future: Unsupervised Backprop-based Decoding for Counterfactual and Abductive Commonsense Reasoning}},
url = {https://github.com/},
year = {2020}
}
@techreport{Weinstein,
annote = {Can efficiently compute the whole LASSO path. Select hyper?

'where signals are sparse' = denoising

Basis pursuit

LARS-TD, LSTD algorithms -- SPARSE RL!

Making FEATURE VECTOR sparse (which features we use), NOT the model.},
author = {Weinstein, Alejandro J},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinstein - Unknown - INFERENCE AND LEARNING IN HIGH-DIMENSIONAL SPACES.pdf:pdf},
title = {{INFERENCE AND LEARNING IN HIGH-DIMENSIONAL SPACES}},
year = {2013}
}
@techreport{Khetarpal2020,
abstract = {Reinforcement learning algorithms usually assume that all actions are always available to an agent. However, both people and animals understand the general link between the features of their environment and the actions that are feasible. Gibson (1977) coined the term "affordances" to describe the fact that certain states enable an agent to do certain actions, in the context of embodied agents. In this paper, we develop a theory of affor-dances for agents who learn and plan in Markov Decision Processes. Affordances play a dual role in this case. On one hand, they allow faster planning , by reducing the number of actions available in any given situation. On the other hand, they facilitate more efficient and precise learning of transition models from data, especially when such models require function approximation. We establish these properties through theoretical results as well as illustrative examples. We also propose an approach to learn affordances and use it to estimate transition models that are simpler and generalize better.},
archivePrefix = {arXiv},
arxivId = {2006.15085v1},
author = {Khetarpal, Khimya and Ahmed, Zafarali and Comanici, Gheorghe and Abel, David and Precup, Doina},
eprint = {2006.15085v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khetarpal et al. - 2020 - What can I do here A Theory of Affordances in Reinforcement Learning.pdf:pdf},
title = {{What can I do here? A Theory of Affordances in Reinforcement Learning}},
year = {2020}
}
@article{Chekroud2015,
abstract = {Major Depressive Disorder is a debilitating and increasingly prevalent psychiatric condition (Compton et al., 2006; Andersen et al., 2011). At present, its primary treatments are antidepressant medications and psychotherapy. Curiously, although the pharmacological effects of antidepressants manifest within hours, remission of clinical symptoms takes a number of weeks-if at all. Independently, support has grown for an idea-proposed as early as Helmholtz (von Helmholtz, 1924)-that the brain is a prediction machine, holding generative models1 for the purpose of inferring causes of sensory information (Dayan et al., 1995; Rao and Ballard, 1999; Knill and Pouget, 2004; Friston et al., 2006; Friston, 2010). If the brain does indeed represent a collection of beliefs about the causal structure of the world, then the depressed phenotype may emerge from a collection of depressive beliefs. These beliefs are modified gradually through successive combinations of expectations with observations. As a result, phenotypic remission ought to take some time as the brain's relevant statistical structures become less pessimistic.},
author = {Chekroud, Adam M.},
doi = {10.3389/fpsyg.2015.00153},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekroud - 2015 - Unifying treatments for depression an application of the Free Energy Principle.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
keywords = {Antidepressants,Antidepressants efficacy,Computational psychiatry,Free-energy principle,Generative models,Major depressive disorder,Predictive coding},
month = {feb},
number = {FEB},
pages = {153},
publisher = {Frontiers Media S.A.},
title = {{Unifying treatments for depression: an application of the Free Energy Principle}},
url = {http://journal.frontiersin.org/Article/10.3389/fpsyg.2015.00153/abstract},
volume = {6},
year = {2015}
}
@techreport{Johnson,
author = {Johnson, Michael Edward},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson - Unknown - Neural Annealing Toward a Neural Theory of Everything.pdf:pdf},
title = {{Neural Annealing: Toward a Neural Theory of Everything}},
year = {2020}
}
@techreport{Javed,
abstract = {Predictive models-learned from observational data not covering the complete data distribution-can rely on spurious correlations in the data for making predictions. These correlations make the models brittle and hinder generalization. One solution for achieving strong generalization is to incorporate causal structures in the models; such structures constrain learning by ignoring correlations that contradict them. However, learning these structures is a hard problem in itself. Moreover, it's not clear how to incorporate the machinery of causality with online continual learning. In this work, we take an indirect approach to discovering causal models. Instead of searching for the true causal model directly, we propose an online algorithm that continually detects and removes spurious features. Our algorithm works on the idea that the correlation of a spurious feature with a target is not constant overtime. As a result, the weight associated with that feature is constantly changing. We show that by continually removing such features, our method converges to solutions that have strong generalization. Moreover, our method combined with random search can also discover non-spurious features from raw sensory data. Finally, our work highlights that the information present in the temporal structure of the problem-destroyed by shuffling the data-is essential for detecting spurious features online.},
annote = {correlation of a spurious feature with target over time is not constant -- assumption

!! Read again [David]},
archivePrefix = {arXiv},
arxivId = {2006.07461v1},
author = {Javed, Khurram and White, Martha and {Bengio MILA}, Yoshua},
eprint = {2006.07461v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Javed, White, Bengio MILA - Unknown - Learning Causal Models Online.pdf:pdf},
title = {{Learning Causal Models Online}},
year = {2020}
}
@techreport{Deng,
abstract = {There has been a gap between artificial intelligence and human intelligence. In this paper, we identify three key elements forming human intelligence, and suggest that abstraction learning combines these elements and is thus a way to bridge the gap. Prior researches in artificial intelligence either specify abstraction by human experts, or take abstraction as qualitative explanation for the model. This paper aims to learn abstraction directly. We tackle three main challenges: representation, objective function, and learning algorithm. Specifically, we propose a partition structure that contains pre-allocated abstraction neurons; we formulate abstraction learning as a constrained optimization problem, which integrates abstraction properties; we develop a network evolution algorithm to solve this problem. This complete framework is named ONE (Optimization via Network Evolution). In our experiments on MNIST, ONE shows elementary human-like intelligence, including low energy consumption, knowledge sharing, and lifelong learning.},
annote = {evolution to search for discrete edges},
archivePrefix = {arXiv},
arxivId = {1809.03956v1},
author = {Deng, Fei and Ren, Jinsheng and Chen, Feng},
eprint = {1809.03956v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng, Ren, Chen - Unknown - Abstraction Learning.pdf:pdf},
title = {{Abstraction Learning}},
year = {2018}
}
@techreport{Sarmad,
abstract = {We present RL-GAN-Net, where a reinforcement learning (RL) agent provides fast and robust control of a genera-tive adversarial network (GAN). Our framework is applied to point cloud shape completion that converts noisy, partial point cloud data into a high-fidelity completed shape by controlling the GAN. While a GAN is unstable and hard to train, we circumvent the problem by (1) training the GAN on the latent space representation whose dimension is reduced compared to the raw point cloud input and (2) using an RL agent to find the correct input to the GAN to generate the latent space representation of the shape that best fits the current input of incomplete point cloud. The suggested pipeline robustly completes point cloud with large missing regions. To the best of our knowledge, this is the first attempt to train an RL agent to control the GAN, which effectively learns the highly nonlinear mapping from the input noise of the GAN to the latent space of point cloud. The RL agent replaces the need for complex optimization and consequently makes our technique real time. Additionally, we demonstrate that our pipelines can be used to enhance the classification accuracy of point cloud with missing data.},
archivePrefix = {arXiv},
arxivId = {1904.12304v1},
author = {Sarmad, Muhammad and Korea, South and Lee, Hyunjoo Jenny and Kim, Young Min},
eprint = {1904.12304v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarmad et al. - Unknown - RL-GAN-Net A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion.pdf:pdf},
title = {{RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion}},
year = {2019}
}
@techreport{DasGupta,
abstract = {In this paper, we investigate the properties of L p norm (p ≤ 1) within a projection framework. We start with the KKT equations of the non-linear optimization problem and then use its key properties to arrive at an algorithm for L p norm projection on the non-negative simplex. We compare with L 1 projection which needs prior knowledge of the true norm, as well as hard thresholding based sparsification proposed in recent compressed sensing literature. We show performance improvements compared to these techniques across different vision applications.},
author = {{Das Gupta}, Mithun},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das Gupta - Unknown - Non-Convex P-norm Projection for Robust Sparsity.pdf:pdf},
title = {{Non-Convex P-norm Projection for Robust Sparsity *}},
year = {2013}
}
@techreport{Mairal2009,
abstract = {Sparse coding-that is, modelling data vectors as sparse linear combinations of basis elements-is widely used in machine learning, neuroscience, signal processing, and statistics. This paper fo-cuses on learning the basis set, also called dictionary , to adapt it to specific data, an approach that has recently proven to be very effective for signal reconstruction and classification in the audio and image processing domains. This paper proposes a new online optimization algorithm for dictionary learning, based on stochastic approximations , which scales up gracefully to large datasets with millions of training samples. A proof of convergence is presented, along with experiments with natural images demonstrating that it leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets.},
author = {Mairal, Julien and {Bach FRANCISBACH}, Francis and Ponce, Jean and {Normale Sup{\'{e}}rieure}, Ecole and Sapiro, Guillermo},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mairal et al. - 2009 - Online Dictionary Learning for Sparse Coding.pdf:pdf},
title = {{Online Dictionary Learning for Sparse Coding}},
year = {2009}
}
@techreport{Polyak,
abstract = {We focus on finding sparse and least-1-norm solutions for uncon-strained nonlinear optimal control problems. Such optimization problems are non-convex and non-smooth, nevertheless recent versions of Newton method for under-determined equations can be applied successively for such problems.},
archivePrefix = {arXiv},
arxivId = {1908.10150v1},
author = {Polyak, Boris and Tremba, Andrey},
eprint = {1908.10150v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Polyak, Tremba - Unknown - Sparse solutions of optimal control via Newton method for under-determined systems.pdf:pdf},
keywords = {1-norm,Newton method,Optimal control,Sparse control,Under-determined equations},
title = {{Sparse solutions of optimal control via Newton method for under-determined systems}},
year = {2019}
}
@article{Nautrup2020,
abstract = {To make progress in science, we often build abstract representations of physical systems that meaningfully encode information about the systems. The representations learnt by most current machine learning techniques reflect statistical structure present in the training data; however, these methods do not allow us to specify explicit and operationally meaningful requirements on the representation. Here, we present a neural network architecture based on the notion that agents dealing with different aspects of a physical system should be able to communicate relevant information as efficiently as possible to one another. This produces representations that separate different parameters which are useful for making statements about the physical system in different experimental settings. We present examples involving both classical and quantum physics. For instance, our architecture finds a compact representation of an arbitrary two-qubit system that separates local parameters from parameters describing quantum correlations. We further show that this method can be combined with reinforcement learning to enable representation learning within interactive scenarios where agents need to explore experimental settings to identify relevant variables.},
annote = {task is to assemble information},
archivePrefix = {arXiv},
arxivId = {2001.00593},
author = {Nautrup, Hendrik Poulsen and Metger, Tony and Iten, Raban and Jerbi, Sofiene and Trenkwalder, Lea M. and Wilming, Henrik and Briegel, Hans J. and Renner, Renato},
eprint = {2001.00593},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nautrup et al. - 2020 - Operationally meaningful representations of physical systems in neural networks.pdf:pdf},
month = {jan},
title = {{Operationally meaningful representations of physical systems in neural networks}},
url = {http://arxiv.org/abs/2001.00593},
year = {2020}
}
@article{Babadi2014,
abstract = {In several sensory pathways, input stimuli project tosparsely active downstream populations that have more neurons than incoming axons. Here, we address the computational benefits of expansion and sparseness for clustered inputs, where different clusters represent behaviorally distinct stimuli and intracluster variability represents sensory or neuronal noise. Through analytical calculations and numerical simulations, we show that expansion implemented by feed-forward random synaptic weights amplifies variability in the incoming stimuli, and this noise enhancement increases with sparseness of the expanded representation. In addition, the low dimensionality of the input layer generates overlaps between the induced representations of different stimuli, limiting the benefit of expansion. Highly sparse expansive representations obtained through synapses that encode the clustered structure of the input reduce both intrastimulus variability and the excess overlaps between stimuli, enhancing the ability of downstream neurons to perform classification and recognition tasks. Implications for olfactory, cerebellar, and visual processing are discussed.},
author = {Babadi, Baktash and Sompolinsky, Haim},
doi = {10.1016/j.neuron.2014.07.035},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Babadi, Sompolinsky - 2014 - Sparseness and Expansion in Sensory Representations.pdf:pdf},
issn = {10974199},
journal = {Neuron},
month = {sep},
number = {5},
pages = {1213--1226},
publisher = {Cell Press},
title = {{Sparseness and Expansion in Sensory Representations}},
volume = {83},
year = {2014}
}
@techreport{Anderson1972,
author = {Anderson, P W},
booktitle = {New Series},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson - 1972 - More Is Different.pdf:pdf},
isbn = {177%3A4047%3C3},
number = {4047},
pages = {393--396},
title = {{More Is Different}},
volume = {177},
year = {1972}
}
@article{Runge2019,
abstract = {The heart of the scientific enterprise is a rational effort to understand the causes behind the phenomena we observe. In large-scale complex dynamical systems such as the Earth system, real experiments are rarely feasible. However, a rapidly increasing amount of observational and simulated data opens up the use of novel data-driven causal methods beyond the commonly adopted correlation techniques. Here, we give an overview of causal inference frameworks and identify promising generic application cases common in Earth system sciences and beyond. We discuss challenges and initiate the benchmark platform causeme.net to close the gap between method users and developers.},
annote = {Types of causal inference. PC for time series!},
author = {Runge, Jakob and Bathiany, Sebastian and Bollt, Erik and Camps-Valls, Gustau and Coumou, Dim and Deyle, Ethan and Glymour, Clark and Kretschmer, Marlene and Mahecha, Miguel D. and Mu{\~{n}}oz-Mar{\'{i}}, Jordi and van Nes, Egbert H. and Peters, Jonas and Quax, Rick and Reichstein, Markus and Scheffer, Marten and Sch{\"{o}}lkopf, Bernhard and Spirtes, Peter and Sugihara, George and Sun, Jie and Zhang, Kun and Zscheischler, Jakob},
doi = {10.1038/s41467-019-10105-3},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Runge et al. - 2019 - Inferring causation from time series in Earth system sciences.pdf:pdf},
isbn = {4146701910},
issn = {20411723},
journal = {Nature Communications},
number = {1},
pages = {1--13},
publisher = {Springer US},
title = {{Inferring causation from time series in Earth system sciences}},
url = {http://dx.doi.org/10.1038/s41467-019-10105-3},
volume = {10},
year = {2019}
}
@article{Bengio2017,
abstract = {A new prior is proposed for representation learning, which can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by the phenomenon of consciousness seen as the formation of a low-dimensional combination of a few concepts constituting a conscious thought, i.e., consciousness as awareness at a particular time instant. This provides a powerful constraint on the representation in that such low-dimensional thought vectors can correspond to statements about reality which are true, highly probable, or very useful for taking decisions. The fact that a few elements of the current state can be combined into such a predictive or useful statement is a strong constraint and deviates considerably from the maximum likelihood approaches to modelling data and how states unfold in the future based on an agent's actions. Instead of making predictions in the sensory (e.g. pixel) space, the consciousness prior allows the agent to make predictions in the abstract space, with only a few dimensions of that space being involved in each of these predictions. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in the form of facts and rules, although the conscious states may be richer than what can be expressed easily in the form of a sentence, a fact or a rule.},
archivePrefix = {arXiv},
arxivId = {1709.08568},
author = {Bengio, Yoshua},
eprint = {1709.08568},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio - 2017 - The Consciousness Prior(2).pdf:pdf},
pages = {1--7},
title = {{The Consciousness Prior}},
url = {http://arxiv.org/abs/1709.08568},
year = {2017}
}
@article{Hutter2003,
abstract = {Decision theory formally solves the problem of rational agents in uncertain worlds if the true environmental prior probability distribution is known. Solomonoff's the- ory of universal induction formally solves the problem of sequence prediction for unknown prior distribution. We combine both ideas and get a parameter-free the- ory of universal Artificial Intelligence. We give strong arguments that the resulting AIXI model is the most intelligent unbiased agent possible. We outline for a number of problem classes, including sequence prediction, strategic games, function mini- mization, reinforcement and supervised learning, how the AIXI model can formally solve them. The major drawback of the AIXI model is that it is uncomputable. To overcome this problem, we construct a modified algorithm AIXItl, which is still effectively more intelligent than any other time t and space l bounded agent. The computation time of AIXItl is of the order t{\textperiodcentered}2l. Other discussed topics are formal definitions of intelligence order relations, the horizon problem and relations of the AIXI theory to other AI approaches.},
author = {Hutter, Marcus},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutter - 2003 - A gentle introduction to the universal algorithmic agent AIXI.pdf:pdf},
journal = {Artificial General Intelligence},
keywords = {agents,algorithmic probability,artificial intelligence,function minimiza-,kolmogorov complexity,ment learning,rational,reinforce-,sequential decision theory,solomonoff induction,strategic games,universal sequence prediction,value function},
title = {{A gentle introduction to the universal algorithmic agent AIXI}},
year = {2003}
}
@article{Zambaldi2018,
abstract = {We introduce an approach for deep reinforcement learning (RL) that improves upon the efficiency, generalization capacity, and interpretability of conventional approaches through structured perception and relational reasoning. It uses self-attention to iteratively reason about the relations between entities in a scene and to guide a model-free policy. Our results show that in a novel navigation and planning task called Box-World, our agent finds interpretable solutions that improve upon baselines in terms of sample complexity, ability to generalize to more complex scenes than experienced during training, and overall performance. In the StarCraft II Learning Environment, our agent achieves state-of-the-art performance on six mini-games -- surpassing human grandmaster performance on four. By considering architectural inductive biases, our work opens new directions for overcoming important, but stubborn, challenges in deep RL.},
annote = {Path as a sequence of states, attention between states!

Box-World is similar to KeyChest

adding attention module

try attention decoder!3},
archivePrefix = {arXiv},
arxivId = {1806.01830},
author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and Shanahan, Murray and Langston, Victoria and Pascanu, Razvan and Botvinick, Matthew and Vinyals, Oriol and Battaglia, Peter},
eprint = {1806.01830},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zambaldi et al. - 2018 - Relational Deep Reinforcement Learning.pdf:pdf},
number = {2},
pages = {1--15},
title = {{Relational Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1806.01830},
year = {2018}
}
@article{Zhang2019,
abstract = {Intelligent agents can cope with sensory-rich environments by learning task-agnostic state abstractions. In this paper, we propose mechanisms to approximate causal states, which optimally compress the joint history of actions and observations in partially-observable Markov decision processes. Our proposed algorithm extracts causal state representations from RNNs that are trained to predict subsequent observations given the history. We demonstrate that these learned task-agnostic state abstractions can be used to efficiently learn policies for reinforcement learning problems with rich observation spaces. We evaluate agents using multiple partially observable navigation tasks with both discrete (GridWorld) and continuous (VizDoom, ALE) observation processes that cannot be solved by traditional memory-limited methods. Our experiments demonstrate systematic improvement of the DQN and tabular models using approximate causal state representations with respect to recurrent-DQN baselines trained with raw inputs.},
annote = {From Duplicate 2 (Learning Causal State Representations of Partially Observable Environments - Zhang, Amy; Lipton, Zachary C.; Pineda, Luis; Azizzadenesheli, Kamyar; Anandkumar, Anima; Itti, Laurent; Pineau, Joelle; Furlanello, Tommaso)

nice definitions and learning states.

Causal=RNN},
archivePrefix = {arXiv},
arxivId = {1906.10437},
author = {Zhang, Amy and Lipton, Zachary C. and Pineda, Luis and Azizzadenesheli, Kamyar and Anandkumar, Anima and Itti, Laurent and Pineau, Joelle and Furlanello, Tommaso},
eprint = {1906.10437},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Learning Causal State Representations of Partially Observable Environments.pdf:pdf;:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Learning causal state representations of partially observable environments.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {ii},
pages = {1--16},
title = {{Learning Causal State Representations of Partially Observable Environments}},
url = {http://arxiv.org/abs/1906.10437},
year = {2019}
}
@article{Kurutach2018,
abstract = {In recent years, deep generative models have been shown to 'imagine' convincing high-dimensional observations such as images, audio, and even video, learning directly from raw data. In this work, we ask how to imagine goal-directed visual plans -- a plausible sequence of observations that transition a dynamical system from its current configuration to a desired goal state, which can later be used as a reference trajectory for control. We focus on systems with high-dimensional observations, such as images, and propose an approach that naturally combines representation learning and planning. Our framework learns a generative model of sequential observations, where the generative process is induced by a transition in a low-dimensional planning model, and an additional noise. By maximizing the mutual information between the generated observations and the transition in the planning model, we obtain a low-dimensional representation that best explains the causal nature of the data. We structure the planning model to be compatible with efficient planning algorithms, and we propose several such models based on either discrete or continuous states. Finally, to generate a visual plan, we project the current and goal observations onto their respective states in the planning model, plan a trajectory, and then use the generative model to transform the trajectory to a sequence of observations. We demonstrate our method on imagining plausible visual plans of rope manipulation.},
annote = {From Duplicate 1 (Learning Plannable Representations with Causal InfoGAN - Kurutach, Thanard; Tamar, Aviv; Yang, Ge; Russell, Stuart; Abbeel, Pieter)

discriminate real from fake pairs

latent space model

From Duplicate 2 (Learning Plannable Representations with Causal InfoGAN - Kurutach, Thanard; Tamar, Aviv; Yang, Ge; Russell, Stuart; Abbeel, Pieter)

Causal planning in simple grid worlds. GAN to generate plans -- like concepts for planning.

CLUSTERING space of states -> can use as concepts

PLAN=(s1,...s_n) visual, goal=s_n
Causal=present|past},
archivePrefix = {arXiv},
arxivId = {1807.09341},
author = {Kurutach, Thanard and Tamar, Aviv and Yang, Ge and Russell, Stuart and Abbeel, Pieter},
eprint = {1807.09341},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurutach et al. - 2018 - Learning Plannable Representations with Causal InfoGAN.pdf:pdf;:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurutach et al. - Unknown - Learning Plannable Representations with Causal InfoGAN.pdf:pdf},
month = {jul},
title = {{Learning Plannable Representations with Causal InfoGAN}},
url = {http://github.com/thanard/causal-infogan. http://arxiv.org/abs/1807.09341},
year = {2018}
}
@article{Gelada2019,
abstract = {Many reinforcement learning (RL) tasks provide the agent with high-dimensional observations that can be simplified into low-dimensional continuous states. To formalize this process, we introduce the concept of a DeepMDP, a parameterized latent space model that is trained via the minimization of two tractable losses: prediction of rewards and prediction of the distribution over next latent states. We show that the optimization of these objectives guarantees (1) the quality of the latent space as a representation of the state space and (2) the quality of the DeepMDP as a model of the environment. We connect these results to prior work in the bisimulation literature, and explore the use of a variety of metrics. Our theoretical findings are substantiated by the experimental result that a trained DeepMDP recovers the latent structure underlying high-dimensional observations on a synthetic environment. Finally, we show that learning a DeepMDP as an auxiliary task in the Atari 2600 domain leads to large performance improvements over model-free RL.},
annote = {From Duplicate 1 (DeepMDP: Learning Continuous Latent Space Models for Representation Learning - Gelada, Carles; Kumar, Saurabh; Buckman, Jacob; Nachum, Ofir; Bellemare, Marc G.)

State abstractions -- too implicit? Good model of env? Theoretical guarantees...},
archivePrefix = {arXiv},
arxivId = {1906.02736},
author = {Gelada, Carles and Kumar, Saurabh and Buckman, Jacob and Nachum, Ofir and Bellemare, Marc G.},
eprint = {1906.02736},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelada et al. - 2019 - DeepMDP Learning Continuous Latent Space Models for Representation Learning.pdf:pdf;:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelada et al. - Unknown - DeepMDP Learning Continuous Latent Space Models for Representation Learning.pdf:pdf},
title = {{DeepMDP: Learning Continuous Latent Space Models for Representation Learning}},
url = {http://arxiv.org/abs/1906.02736},
year = {2019}
}
@article{Francois-Lavet2018,
abstract = {In the quest for efficient and robust reinforcement learning methods, both model-free and model-based approaches offer advantages. In this paper we propose a new way of explicitly bridging both approaches via a shared low-dimensional learned encoding of the environment, meant to capture summarizing abstractions. We show that the modularity brought by this approach leads to good generalization while being computationally efficient, with planning happening in a smaller latent state space. In addition, this approach recovers a sufficient low-dimensional representation of the environment, which opens up new strategies for interpretable AI, exploration and transfer learning.},
annote = {From Duplicate 1 (Combined Reinforcement Learning via Abstract Representations - Fran{\c{c}}ois-Lavet, Vincent; Bengio, Yoshua; Precup, Doina; Pineau, Joelle)

Latent space between model-based and model-free. Low-dim space resembling the environment structure -- low-dim MDP. Interpretability: vector in embedding space <-> action

From Duplicate 2 (Combined Reinforcement Learning via Abstract Representations - Francois-Lavet, Vincent; Bengio, Yoshua; Precup, Doina; Pineau, Joelle)

Abstract state between model-based and model-free agents; Heuristics for regul; Emerging sane latent spaces with regularization},
archivePrefix = {arXiv},
arxivId = {1809.04506},
author = {Francois-Lavet, Vincent and Bengio, Yoshua and Precup, Doina and Pineau, Joelle and Fran{\c{c}}ois-Lavet, Vincent and Bengio, Yoshua and Precup, Doina and Pineau, Joelle},
doi = {10.1609/aaai.v33i01.33013582},
eprint = {1809.04506},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fran{\c{c}}ois-Lavet et al. - 2018 - Combined Reinforcement Learning via Abstract Representations.pdf:pdf;:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Francois-Lavet et al. - 2019 - Combined Reinforcement Learning via Abstract Representations.pdf:pdf},
issn = {2159-5399},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {abstract rep,deep RL,deep reinforcement learning},
month = {sep},
pages = {3582--3589},
title = {{Combined Reinforcement Learning via Abstract Representations}},
url = {http://arxiv.org/abs/1809.04506},
volume = {33},
year = {2019}
}
@article{DesJardins1993,
author = {DesJardins, Marie},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Learning - 1993 - P AGODA A Model for.pdf:pdf},
journal = {AI Magazine},
number = {1},
pages = {75--76},
title = {{PAGODA: a model for autonomous learning in probabilistic domains}},
volume = {14},
year = {1993}
}
@article{Ave,
annote = {Similar to our approach: learning the effect of actions as conditional distributions. using logical formulas.

do-calculus (without calling it so)

Nodes can group into unacceptable features},
author = {DesJardins, Marie},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ave, Ca - Unknown - Representing and Reasoning With Probabilistic Knowledge A Bayesian Approach P ( Y ) n L P ( GB IC ) P ( Llu ( t.pdf:pdf},
title = {{Representing and Reasoning With Probabilistic Knowledge : A Bayesian Approach}},
year = {1993}
}
@article{Gonzalez-soto2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1908.07617v2},
author = {Gonzalez-soto, Mauricio},
eprint = {arXiv:1908.07617v2},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonzalez-soto - Unknown - Reinforcement Learning is not a Causal problem arXiv 1908 . 07617v2 cs . AI 9 Sep 2019.pdf:pdf},
title = {{Reinforcement Learning is not a Causal problem}},
year = {2019}
}
@article{Druzdzel,
abstract = {We compare measures of structural distance between both, Bayesian networks and equivalence classes of Bayesian networks. The main application of these mea-sures is in learning algorithms, where typically the interest is in how accurately a gold standard structure is retrieved by a learning algorithm. Structural distance measures can be especially useful when looking for causal structures. We discuss desirable properties of measures, review existing measures, and show some of our empirical findings concerning the performance of these metrics in practice.},
annote = {Distances between grphs},
author = {Druzdzel, Martijn de Jongh and Marek J.},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Druzdzel - Unknown - A Comparison of Structural Distance Measures for Causal Bayesian Network Models.pdf:pdf},
isbn = {978-83-60434-59-8},
keywords = {Bayesian networks,causal discovery,structural distance,structure learning},
pages = {443--456},
title = {{A Comparison of Structural Distance Measures for Causal Bayesian Network Models}},
year = {2009}
}
@techreport{Dasgupta2019,
abstract = {Discovering and exploiting the causal structure in the environment is a crucial challenge for intelligent agents. Here we explore whether modern deep reinforcement learning can be used to train agents to perform causal reasoning. We adopt a meta-learning approach, where the agent learns a policy for conducting experiments via causal interventions, in order to support a subsequent task which rewards making accurate causal inferences. We also found the agent could make sophisticated counterfactual predictions, as well as learn to draw causal inferences from purely observational data. Though powerful formalisms for causal reasoning have been developed, applying them in real-world domains can be difficult because fitting to large amounts of high dimensional data often requires making idealized assumptions. Our results suggest that causal reasoning in complex settings may benefit from powerful learning-based approaches. More generally, this work may offer new strategies for structured exploration in reinforcement learning, by providing agents with the ability to perform-and interpret-experiments.},
annote = {Causal reasoning can arise even in model-free agents

too simple envs?},
author = {Dasgupta, Ishita and Wang, Jane and Chiappa, Silvia and Mitrovic, Jovana and Ortega, Pedro and Raposo, David and Hughes, Edward and Battaglia, Peter and Botvinick, Matthew and Kurth-Nelson, Zeb},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - CAUSAL REASONING FROM META REINFORCEMENT LEARNING.pdf:pdf},
title = {{CAUSAL REASONING FROM META REINFORCEMENT LEARNING}},
year = {2019}
}
@article{Petros2020,
author = {Petros, Giannakopoulos and Aggelos, Pikrakis and Yannis, Cotronis},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petros, Aggelos, Yannis - 2020 - NEURAL DISCRETE ABSTRACTION OF HIGH-DIMENSIONAL SPACES A CASE STUDY IN REINFORCEMENT LEARNING Petros G.pdf:pdf},
isbn = {9789082797053},
pages = {1517--1521},
title = {{NEURAL DISCRETE ABSTRACTION OF HIGH-DIMENSIONAL SPACES : A CASE STUDY IN REINFORCEMENT LEARNING Petros Giannakopoulos Yannis Cotronis National and Kapodistrian University of Athens University of Piraeus}},
year = {2020}
}
@article{Pearl2020,
author = {Pearl, Judea},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearl - 2020 - Causality models, reasoning and inference.pdf:pdf},
issn = {0008350X},
pmid = {11768929},
title = {{Causality: models, reasoning and inference}},
year = {2020}
}
@article{Gomez2006,
author = {G{\'{o}}mez, R and Bootzin, R and Nadel, L},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}mez, Bootzin, Nadel - 2006 - N Aps P Romote a Bstraction in L Anguage -L Earning I Nfants.pdf:pdf},
pages = {358},
title = {{HALMA: humanlike abstraction learning meets affordance in rapid problem solving}},
year = {2006}
}
@article{Schrittwieser2019,
abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},
archivePrefix = {arXiv},
arxivId = {1911.08265},
author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
eprint = {1911.08265},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schrittwieser et al. - 2019 - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.pdf:pdf},
journal = {arXiv},
month = {nov},
publisher = {arXiv},
title = {{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}},
url = {http://arxiv.org/abs/1911.08265},
year = {2019}
}
@article{Kreutz-delgado2003,
abstract = {Algorithms for data-driven learning of domain-specific overcomplete dictionaries are developed to obtain maximum likelihood and maximum a posteriori dictionary estimates based on the use of Bayesian models with concave/Schur-concave (CSC) negative log priors. Such priors are appropriate for obtaining sparse representations of environmental signals within an appropriately chosen (environmentally matched) dictionary. The elements of the dictionary can be interpreted as concepts, features, or words capable of succinct expression of events encountered in the environment (the source of the measured signals). This is a generalization of vector quantization in that one is interested in a description involving a few dictionary entries (the proverbial "25 words or less"), but not necessarily as succinct as one entry. To learn an environmentally adapted dictionary capable of concise expression of signals generated by the environment, we develop algorithms that iterate between a representative set of sparse representations found by variants of FOCUSS and an update of the dictionary using these sparse representations. Experiments were performed using synthetic data and natural images. For complete dictionaries, we demonstrate that our algorithms have improved performance over other independent component analysis (ICA) methods, measured in terms of signal-to-noise ratios of separated sources. In the overcomplete case, we show that the true underlying dictionary and sparse sources can be accurately recovered. In tests with natural images, learned overcomplete dictionaries are shown to have higher coding efficiency than complete dictionaries; that is, images encoded with an overcomplete dictionary have both higher compression (fewer bits per pixel) and higher accuracy (lower mean square error).},
archivePrefix = {arXiv},
arxivId = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2944020/pdf/nihms234072.pdf},
author = {Kreutz-delgado, Kenneth and Murray, Joseph F and Sejnowski, Terrence J},
eprint = {/www.ncbi.nlm.nih.gov/pmc/articles/PMC2944020/pdf/nihms234072.pdf},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kreutz-delgado, Murray, Sejnowski - 2003 - Dictionary Learning ALgorithms for Sparse Representation.pdf:pdf},
isbn = {0899-7667},
issn = {0899-7667},
number = {2},
pmid = {12590811},
primaryClass = {http:},
title = {{Dictionary Learning ALgorithms for Sparse Representation}},
volume = {15},
year = {2003}
}
@article{Oisy2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1905.01591v1},
author = {Louizos, Christos and Welling, Max and Kingma, Diederik},
eprint = {arXiv:1905.01591v1},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oisy - 2019 - L Earning G Raph N Eural N Etworks.pdf:pdf},
number = {1},
pages = {1--5},
title = {{Learning sparse neural networks through l0 regularization}},
year = {2019}
}
@article{Abramson2020,
abstract = {A common vision from science fiction is that robots will one day inhabit our physical spaces, sense the world as we do, assist our physical labours, and communicate with us through natural language. Here we study how to design artificial agents that can interact naturally with humans using the simplification of a virtual environment. This setting nevertheless integrates a number of the central challenges of artificial intelligence (AI) research: complex visual perception and goal-directed physical control, grounded language comprehension and production, and multi-agent social interaction. To build agents that can robustly interact with humans, we would ideally train them while they interact with humans. However, this is presently impractical. Therefore, we approximate the role of the human with another learned agent, and use ideas from inverse reinforcement learning to reduce the disparities between human-human and agent-agent interactive behaviour. Rigorously evaluating our agents poses a great challenge, so we develop a variety of behavioural tests, including evaluation by humans who watch videos of agents or interact directly with them. These evaluations convincingly demonstrate that interactive training and auxiliary losses improve agent behaviour beyond what is achieved by supervised learning of actions alone. Further, we demonstrate that agent capabilities generalise beyond literal experiences in the dataset. Finally, we train evaluation models whose ratings of agents agree well with human judgement, thus permitting the evaluation of new agent models without additional effort. Taken together, our results in this virtual environment provide evidence that large-scale human behavioural imitation is a promising tool to create intelligent, interactive agents, and the challenge of reliably evaluating such agents is possible to surmount.},
archivePrefix = {arXiv},
arxivId = {2012.05672},
author = {Abramson, Josh and Ahuja, Arun and Brussee, Arthur and Carnevale, Federico and Cassin, Mary and Clark, Stephen and Dudzik, Andrew and Georgiev, Petko and Guy, Aurelia and Harley, Tim and Hill, Felix and Hung, Alden and Kenton, Zachary and Landon, Jessica and Lillicrap, Timothy and Mathewson, Kory and Muldal, Alistair and Santoro, Adam and Savinov, Nikolay and Varma, Vikrant and Wayne, Greg and Wong, Nathaniel and Yan, Chen and Zhu, Rui},
eprint = {2012.05672},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramson et al. - 2020 - Imitating Interactive Intelligence.pdf:pdf},
pages = {1--96},
title = {{Imitating Interactive Intelligence}},
url = {http://arxiv.org/abs/2012.05672},
year = {2020}
}
@article{Veerapaneni2019,
abstract = {This paper tests the hypothesis that modeling a scene in terms of entities and their local interactions, as opposed to modeling the scene globally, provides a significant benefit in generalizing to physical tasks in a combinatorial space the learner has not encountered before. We present object-centric perception, prediction, and planning (OP3), which to the best of our knowledge is the first entity-centric probabilistic dynamic latent variable framework for model-based reinforcement learning that acquires entity representations from raw visual observations without supervision and uses them to predict and plan. OP3 enforces entity-abstraction – symmetric processing of each entity representation with the same locally-scoped function – which enables it to scale to model different numbers and configurations of objects from those in training. Our approach to solving the key technical challenge of grounding these entity representations to actual objects in the environment is to frame this variable binding problem as an inference problem, and we develop an interactive inference algorithm that uses temporal continuity and interactive feedback to bind information about object properties to the entity variables. On block-stacking tasks, OP3 generalizes to novel block configurations and more objects than observed during training, outperforming an oracle model that assumes access to object supervision and achieving two to three times better accuracy than a state-of-the-art video prediction model that does not exhibit entity abstraction.},
archivePrefix = {arXiv},
arxivId = {1910.12827},
author = {Veerapaneni, Rishi and Co-Reyes, John D. and Chang, Michael and Janner, Michael and Finn, Chelsea and Wu, Jiajun and Tenenbaum, Joshua B. and Levine, Sergey},
eprint = {1910.12827},
file = {:home/ubuntu-mate/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Veerapaneni et al. - 2019 - Entity abstraction in visual model-based reinforcement learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Compositionality,Model-based reinforcement learning,Objects},
number = {CoRL},
pages = {1--18},
title = {{Entity abstraction in visual model-based reinforcement learning}},
year = {2019}
}
